---
title: AEWS 10ì£¼ì°¨ ì •ë¦¬
date: 2025-04-12 20:30:00 +0900
categories: [EKS]
tags: [AEWS]
---
## **âš™ï¸ ì‹¤ìŠµ í™˜ê²½ êµ¬ì„± - ì  í‚¨ìŠ¤**

### **1. ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„± í›„ ì´ë™**

```bash
mkdir cicd-labs
cd cicd-labs
```

### **2. ë„ì»¤ ì»´í¬ì¦ˆ íŒŒì¼ ìƒì„±**

```bash
cat <<EOT > docker-compose.yaml
services:

  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - kind
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home

volumes:
  jenkins_home:

networks:
  kind:
    external: true
EOT
```

### **3. ì  í‚¨ìŠ¤ ë°°í¬**

```bash
docker compose up -d  
```

âœ…Â **ì¶œë ¥**

```bash
[+] Running 2/2
 âœ” Volume "cicd-labs_jenkins_home"  Created                                                                                0.0s 
 âœ” Container jenkins                Started 
```

### **4. ë„ì»¤ ì»´í¬ì¦ˆ ì»¨í…Œì´ë„ˆ ìƒíƒœ ì¡°íšŒ**

```bash
docker compose ps
```

âœ…Â **ì¶œë ¥**

```bash
NAME      IMAGE             COMMAND                  SERVICE   CREATED          STATUS         PORTS
jenkins   jenkins/jenkins   "/usr/bin/tini -- /uâ€¦"   jenkins   10 seconds ago   Up 9 seconds   0.0.0.0:8080->8080/tcp, [::]:8080->8080/tcp, 0.0.0.0:50000->50000/tcp, [::]:50000->50000/tcp
```

### **5. ê¸°ë³¸ ì •ë³´ í™•ì¸**

```bash
for i in jenkins ; do echo ">> container : $i <<"; docker compose exec $i sh -c "whoami && pwd"; echo; done
```

âœ…Â **ì¶œë ¥**

```bash
>> container : jenkins <<
jenkins
/
```

### **6. ë„ì»¤ë¥¼ ì´ìš©í•˜ì—¬ ì  í‚¨ìŠ¤ ì»¨í…Œì´ë„ˆë¡œ ì ‘ì†**

```bash
docker compose exec jenkins bash

jenkins@01fee1ac3d51:/$ exit
exit
```

### **7. ì  í‚¨ìŠ¤ ì´ˆê¸° ì•”í˜¸ í™•ì¸**

```bash
docker compose exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword
```

âœ…Â **ì¶œë ¥**

```bash
72eb90cdffce42118d6c28cc5c4f063a
```

### **8. ì  í‚¨ìŠ¤ ì›¹ ì ‘ì†**

**(1) `http://127.0.0.1:8080` ì ‘ì† í›„, ì´ˆê¸° ì•”í˜¸ ì…ë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/af7e67b9-aa38-4abb-bb8e-237735d9456f/image.png)

**(2) Install suggested plugins ì˜µì…˜ ì„ íƒ**
![](https://velog.velcdn.com/images/tlsalswls123/post/707939c9-ef89-44f3-aa65-d6b1c6980730/image.png)

**(3) Admin User ê³„ì • ìƒì„± - `admin` / `qwe123`ìœ¼ë¡œ ì„¤ì •**
![](https://velog.velcdn.com/images/tlsalswls123/post/f7a0cec5-902e-4ab1-966c-18f521925d81/image.png)

**(4) ì  í‚¨ìŠ¤ URL ì„¤ì • - `http://127.0.0.1:8080/`**
![](https://velog.velcdn.com/images/tlsalswls123/post/bd8bb149-6416-48ba-ae06-3df98b0f803b/image.png)

**(5) ì  í‚¨ìŠ¤ ì´ˆê¸° ì§„ì… í™”ë©´**
![](https://velog.velcdn.com/images/tlsalswls123/post/4d8d393b-1a8e-4ed3-85bf-f8044bd9e54f/image.png)

**(6) ì  í‚¨ìŠ¤ ê´€ë¦¬ì—ì„œ Vault í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜**
![](https://velog.velcdn.com/images/tlsalswls123/post/115f50fb-f147-4b75-89e7-295de1e82799/image.png)

---

## **ğŸ³ ì‹¤ìŠµ í™˜ê²½ êµ¬ì„± - K8S(kind)**

### **1. cicd-labs ë””ë ‰í„°ë¦¬ì—ì„œ ì•„ë˜ íŒŒì¼ ì‘ì„±**

```bash
cat > kind-3node.yaml <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  apiServerAddress: "127.0.0.1" # $MyIPë¡œ ì„¤ì •í•˜ì…”ë„ ë©ë‹ˆë‹¤.
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
  - containerPort: 30004
    hostPort: 30004
  - containerPort: 30005
    hostPort: 30005
  - containerPort: 30006
    hostPort: 30006
- role: worker
- role: worker
EOF
```

### **2. í´ëŸ¬ìŠ¤í„° ë°°í¬**

```bash
kind create cluster --config kind-3node.yaml --name myk8s --image kindest/node:v1.32.2
```

âœ…Â **ì¶œë ¥**

```bash
Creating cluster "myk8s" ...
 âœ“ Ensuring node image (kindest/node:v1.32.2) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦ ğŸ“¦ ğŸ“¦  
 âœ“ Writing configuration ğŸ“œ 
 âœ“ Starting control-plane ğŸ•¹ï¸ 
 âœ“ Installing CNI ğŸ”Œ 
 âœ“ Installing StorageClass ğŸ’¾ 
 âœ“ Joining worker nodes ğŸšœ 
Set kubectl context to "kind-myk8s"
You can now use your cluster with:

kubectl cluster-info --context kind-myk8s

Have a nice day! ğŸ‘‹
```

### **3. kind ìƒì„¸ ì •ë³´ í™•ì¸**

```bash
docker inspect kind | jq
```

âœ…Â **ì¶œë ¥**

```bash
[
  {
    "Name": "kind",
    "Id": "dbf072d0a217f53e0b62f42cee01bcecc1b2f6ea216475178db001f2e38681f5",
    "Created": "2025-01-26T16:18:22.33980443+09:00",
    "Scope": "local",
    "Driver": "bridge",
    "EnableIPv4": true,
    "EnableIPv6": true,
    "IPAM": {
      "Driver": "default",
      "Options": {},
      "Config": [
        {
          "Subnet": "172.18.0.0/16",
          "Gateway": "172.18.0.1"
        },
        {
          "Subnet": "fc00:f853:ccd:e793::/64",
          "Gateway": "fc00:f853:ccd:e793::1"
        }
      ]
    },
    "Internal": false,
    "Attachable": false,
    "Ingress": false,
    "ConfigFrom": {
      "Network": ""
    },
    "ConfigOnly": false,
    "Containers": {
      "01fee1ac3d51d8f4c4378c53b6f3a70cded0c9a396bd4a79d53928fbc6721205": {
        "Name": "jenkins",
        "EndpointID": "ae52706c8e8daeab92282bb420ee330ad56930c00df0c416234b41f22eb9e6f1",
        "MacAddress": "12:af:53:29:a0:79",
        "IPv4Address": "172.18.0.2/16",
        "IPv6Address": "fc00:f853:ccd:e793::2/64"
      },
      "042a42ff8494a7808acc048296edb5b56f774e6952f26b32e3ad8849e8609ba7": {
        "Name": "myk8s-worker",
        "EndpointID": "cb2eaddcec377ef1c6d8830f52543b74db764d531dd46f88bda4342acc24c974",
        "MacAddress": "5a:fc:0b:04:57:a8",
        "IPv4Address": "172.18.0.5/16",
        "IPv6Address": "fc00:f853:ccd:e793::5/64"
      },
      "32e83d82c8dffd8e6fcbd63553f0746b0922d00746f00237833b07289bc90351": {
        "Name": "myk8s-control-plane",
        "EndpointID": "4238a09cf1f512561228ae26a402760f0e0122b672b85ade532e5c25fe7d8d0d",
        "MacAddress": "96:c4:e1:40:51:45",
        "IPv4Address": "172.18.0.4/16",
        "IPv6Address": "fc00:f853:ccd:e793::4/64"
      },
      "7e7f2094bcb6741db5a989c933f2b3bd3018162bea16866482f22be6b0ac79fd": {
        "Name": "myk8s-worker2",
        "EndpointID": "ae38ac7b95ee524c15506cc2bbdda2748d867b039804701ede4d7db38c03446c",
        "MacAddress": "9e:66:99:7c:98:ff",
        "IPv4Address": "172.18.0.3/16",
        "IPv6Address": "fc00:f853:ccd:e793::3/64"
      }
    },
    "Options": {
      "com.docker.network.bridge.enable_ip_masquerade": "true",
      "com.docker.network.driver.mtu": "1500"
    },
    "Labels": {}
  }
]

```

### **4. k8s api ì£¼ì†Œ í™•ì¸**

```bash
kubectl cluster-info
```

âœ…Â **ì¶œë ¥**

```bash
Kubernetes control plane is running at https://127.0.0.1:33907
CoreDNS is running at https://127.0.0.1:33907/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```

### **5. ë…¸ë“œ ì •ë³´ í™•ì¸**

```bash
kubectl get node -o wide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                  STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION   CONTAINER-RUNTIME
myk8s-control-plane   Ready    control-plane   2m41s   v1.32.2   172.18.0.4    <none>        Debian GNU/Linux 12 (bookworm)   6.13.8-arch1-1   containerd://2.0.3
myk8s-worker          Ready    <none>          2m31s   v1.32.2   172.18.0.5    <none>        Debian GNU/Linux 12 (bookworm)   6.13.8-arch1-1   containerd://2.0.3
myk8s-worker2         Ready    <none>          2m31s   v1.32.2   172.18.0.3    <none>        Debian GNU/Linux 12 (bookworm)   6.13.8-arch1-1   containerd://2.0.3
```

### **6. íŒŒë“œ ì •ë³´ í™•ì¸**

```bash
kubectl get pod -A -o wide
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE            NAME                                          READY   STATUS    RESTARTS   AGE     IP           NODE                  NOMINATED NODE   READINESS GATES
kube-system          coredns-668d6bf9bc-c86ph                      1/1     Running   0          3m15s   10.244.0.4   myk8s-control-plane   <none>           <none>
kube-system          coredns-668d6bf9bc-w6wlq                      1/1     Running   0          3m15s   10.244.0.3   myk8s-control-plane   <none>           <none>
kube-system          etcd-myk8s-control-plane                      1/1     Running   0          3m21s   172.18.0.4   myk8s-control-plane   <none>           <none>
kube-system          kindnet-dmqn7                                 1/1     Running   0          3m15s   172.18.0.4   myk8s-control-plane   <none>           <none>
kube-system          kindnet-jq854                                 1/1     Running   0          3m14s   172.18.0.5   myk8s-worker          <none>           <none>
kube-system          kindnet-wr5lw                                 1/1     Running   0          3m14s   172.18.0.3   myk8s-worker2         <none>           <none>
kube-system          kube-apiserver-myk8s-control-plane            1/1     Running   0          3m22s   172.18.0.4   myk8s-control-plane   <none>           <none>
kube-system          kube-controller-manager-myk8s-control-plane   1/1     Running   0          3m22s   172.18.0.4   myk8s-control-plane   <none>           <none>
kube-system          kube-proxy-8z75j                              1/1     Running   0          3m15s   172.18.0.4   myk8s-control-plane   <none>           <none>
kube-system          kube-proxy-9f76d                              1/1     Running   0          3m14s   172.18.0.3   myk8s-worker2         <none>           <none>
kube-system          kube-proxy-9tbwd                              1/1     Running   0          3m14s   172.18.0.5   myk8s-worker          <none>           <none>
kube-system          kube-scheduler-myk8s-control-plane            1/1     Running   0          3m21s   172.18.0.4   myk8s-control-plane   <none>           <none>
local-path-storage   local-path-provisioner-7dc846544d-g4974       1/1     Running   0          3m15s   10.244.0.2   myk8s-control-plane   <none>           <none>
```

### **7. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸**

```bash
kubectl get namespaces
```

âœ…Â **ì¶œë ¥**

```bash
NAME                 STATUS   AGE
default              Active   4m18s
kube-node-lease      Active   4m17s
kube-public          Active   4m18s
kube-system          Active   4m18s
local-path-storage   Active   4m14s
```

### **8. ì»¨íŠ¸ë¡¤í”Œë ˆì¸/ì›Œì»¤ ë…¸ë“œ(ì»¨í…Œì´ë„ˆ) í™•ì¸**

```bash
docker ps
```

âœ…Â **ì¶œë ¥**

```bash
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                                                                          NAMES
7e7f2094bcb6   kindest/node:v1.32.2   "/usr/local/bin/entrâ€¦"   5 minutes ago    Up 5 minutes                                                                                                   myk8s-worker2
042a42ff8494   kindest/node:v1.32.2   "/usr/local/bin/entrâ€¦"   5 minutes ago    Up 5 minutes                                                                                                   myk8s-worker
32e83d82c8df   kindest/node:v1.32.2   "/usr/local/bin/entrâ€¦"   5 minutes ago    Up 5 minutes    0.0.0.0:30000-30006->30000-30006/tcp, 127.0.0.1:33907->6443/tcp                                myk8s-control-plane
01fee1ac3d51   jenkins/jenkins        "/usr/bin/tini -- /uâ€¦"   20 minutes ago   Up 20 minutes   0.0.0.0:8080->8080/tcp, [::]:8080->8080/tcp, 0.0.0.0:50000->50000/tcp, [::]:50000->50000/tcp   jenkins
```

### **9. kube config íŒŒì¼ í™•ì¸**

```bash
cat ~/.kube/config
```

âœ…Â **ì¶œë ¥**

```bash
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJUWg4OEtlSkZuMUV3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TlRBME1URXhORFE0TWpkYUZ3MHpOVEEwTURreE5EVXpNamRhTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUNsS3dWWSt6dy9BQUtqekQvbGc4T3AxWjBQeVBORTBIeVNXTWJtd3ZqN3d6eUpKOCtmMmhJdm9TUkkKWkxnRG1ZUVFhbkdkT0E5UUplY0NKbDV5dk9RSkcrTE12UHU5ZlNqT1UvSE5oVE91aE40RFQrMjJtMUh6aDdTVwpTam5JN1JJbm55dHBJckJ0RFVxMGhxaXFJaHZrcU5xSThPUTNta3F0cDEzQnRlMUtpemNMdjA0bUFNSGJ2MG5sCnF1UUVoelRPN0poK05DcFhlZVkxVDN5RDhpM1I4WEZOL3o3YWh6OVoyd3VyZGpXeHlGbXBOWU4zVGp4YTlMdy8Kc3MxamNVVjNXVEtNVEx6YzJacnNjQ1FPZHBVU1JMQnJqYzdqQ2RHMEJOSUhpcDJoMGZ4b3M1T204WEpZcGtsVAp2dkQwWUswUlB6ZGg2WkEzREZwZU1KL2Q5N28vQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJTcVQ0ZVgwa3lHcEJXdjZMN3JETlJRQTRIdG5qQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQmdEL1Fvck9kcApJL3hwMVBTL0p5emNRTzlyV0VKOExTMld0T3grWkowa2ZCRGF0ZDIwUGwxTDBLcDlTRWM3TUpBbFk2RXlIRG95CnpqUFdLS2JQNFZPK2RkMVo2TkJBVDN6NFNObndQSVdEVS9uWjIvM0FESVVpU2tVMFpxR3FIQTI3WDE2MlVDMGIKT2VnaTl4YnE4Qk1teGJ1L2lCeUZROXNVOWpLTG15eUhPS3JqR25hMUJTbVVKZ1ZxVEEvVEFYRTUrTXpjeitzMgpoaXJOUjVEMUFIa2ZrVEE5L25DYytmRXFTSHdaTWpiUTNjcmJuTW1wUzZzbnVWS0lDZWw5VHRiQVZHbVphNWRrCmpRdGJyUld1Wjd5MjM5cTFaZks3T3ZBbUtnWERTK3JteWhQWUtGNVh4QmV6eFlHUVVhUzJJZFlZWEtDdlFER2QKR2c0SVZHSkhaZ3AxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://127.0.0.1:33907
  name: kind-myk8s
contexts:
- context:
    cluster: kind-myk8s
    user: kind-myk8s
  name: kind-myk8s
current-context: kind-myk8s
kind: Config
preferences: {}
users:
- name: kind-myk8s
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURLVENDQWhHZ0F3SUJBZ0lJUUJxd0FRRkNtSTh3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TlRBME1URXhORFE0TWpkYUZ3MHlOakEwTVRFeE5EVXpNamRhTUR3eApIekFkQmdOVkJBb1RGbXQxWW1WaFpHMDZZMngxYzNSbGNpMWhaRzFwYm5NeEdUQVhCZ05WQkFNVEVHdDFZbVZ5CmJtVjBaWE10WVdSdGFXNHdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCRHdBd2dnRUtBb0lCQVFDa1VSWDIKWHB4eXA3VDU2cTBxcmo1SURGcTI4L3hzZHFoeGNPN1Y4YnZhVkJHWEFFVzkrZHYzOURoLzVQSm05dzZLYm5MQwpxSTI0VENwNy9aMk04SU9XNVZveE5uTVp6K2tYYm5LSWhFQU9xb3BoSi9ybVVBemwwOUxkNGsvWTVFR1ZGWmpJClRhTXpIb1gzS1N3WUNMODJBd09BMTh3MGZnMDkrRWRkcW1HclZqMFMyVmNtWEFhYXFUYjFXd3dXdHQrTGFtZ2IKRGhjL2hFY0tESWxtaWZGNkJjbXlqRFlMVS9EUnJxbG5hMlR0bzFNWEJuUEMxM0FvL29pR254T0NXd3RlbXcwOQpTNFo1eGVGNVYvV0hETFlqaGVDYndYc2paUW9Fa1ZsVjBCdnJtZjYyVmlqa1pSZ29LY3lSWVBsQWhIYmpsaGxvCkhsakt6cG5yYWk0R0ZaMk5BZ01CQUFHalZqQlVNQTRHQTFVZER3RUIvd1FFQXdJRm9EQVRCZ05WSFNVRUREQUsKQmdnckJnRUZCUWNEQWpBTUJnTlZIUk1CQWY4RUFqQUFNQjhHQTFVZEl3UVlNQmFBRktwUGg1ZlNUSWFrRmEvbwp2dXNNMUZBRGdlMmVNQTBHQ1NxR1NJYjNEUUVCQ3dVQUE0SUJBUUFla29ocS9ycUVGa1psOU5vM1EwZjh0S0RQClF5aGk4cFRUNHFsRUJtNFNxNlMvdDVFSE1yT0VWcm5RM1FaNlZuS0F1cWVubVh5bzc3UC8rSHorYnNXeUlvMFQKMnFVRUZxdnJKbEFMYzhWWVNlSDJtaHB2MXBBd05LU1ltYnQwb0pMUUEwMUNrRlpLM1ZDUXdvaEozOG5VWERSNQpWNk5OTU5MT3J6ZHFvbXgySWJzQ2hJY2NwQTVqNnBJcmppaFZUV25EaUFtZjlBUS90YjhlSWZXM0JlNGxDMzE1CjRZTmFkenl4QUp2RFl1L1FPdjYxNXQ1ZmF1Y0xSN1dTYTVNUjJXdXk4NXYvSlRNc28wNlhBeUNVVDM0SFFQWkIKMHpPa080WmVzZFlVTkVmUnZFYS9OWmdING8wMVRGUEVwZE9kVEZmemsvQ1FSVzBXbHFYQ2NzQnZScVU1Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    client-key-data: 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
```

## **ğŸš€ ì‹¤ìŠµ í™˜ê²½ êµ¬ì„± - Argo CD**

### **1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±**

```bash
kubectl create ns argocd
# ê²°ê³¼
namespace/argocd created
```

### **2. íŒŒë¼ë¯¸í„° íŒŒì¼ ì‘ì„±**

```bash
cat <<EOF > argocd-values.yaml
dex:
  enabled: false

server:
  service:
    type: NodePort
    nodePortHttps: 30002
  extraArgs:
    - --insecure  # HTTPS ëŒ€ì‹  HTTP ì‚¬ìš©
EOF
```

### **3. Argo CD ì„¤ì¹˜**

```bash
helm repo add argo https://argoproj.github.io/argo-helm
helm install argocd argo/argo-cd --version 7.8.13 -f argocd-values.yaml --namespace argocd
```

âœ…Â **ì¶œë ¥**

```bash
NAME: argocd
LAST DEPLOYED: Sat Apr 12 00:03:52 2025
NAMESPACE: argocd
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
In order to access the server UI you have the following options:

1. kubectl port-forward service/argocd-server -n argocd 8080:443

    and then open the browser on http://localhost:8080 and accept the certificate

2. enable ingress in the values file `server.ingress.enabled` and either
      - Add the annotation for ssl passthrough: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-1-ssl-passthrough
      - Set the `configs.params."server.insecure"` in the values file and terminate SSL at your ingress: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-2-multiple-ingress-objects-and-hosts

After reaching the UI the first time you can login with username: admin and the random password generated during the installation. You can find the password by running:

kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

(You should delete the initial secret afterwards as suggested by the Getting Started Guide: https://argo-cd.readthedocs.io/en/stable/getting_started/#4-login-using-the-cli)
```

### **4. Argo CD ë¦¬ì†ŒìŠ¤ ì¡°íšŒ**

```bash
kubectl get pod,svc,ep,secret,cm -n argocd
```

âœ…Â **ì¶œë ¥**

```bash
NAME                                                   READY   STATUS    RESTARTS   AGE
pod/argocd-application-controller-0                    1/1     Running   0          4m35s
pod/argocd-applicationset-controller-cccb64dc8-j646p   1/1     Running   0          4m35s
pod/argocd-notifications-controller-7cd4d88cd4-77m4m   1/1     Running   0          4m35s
pod/argocd-redis-6c5698fc46-45nwd                      1/1     Running   0          4m35s
pod/argocd-repo-server-5f6c4f4cf4-nnxxd                1/1     Running   0          4m35s
pod/argocd-server-7cb958f5fb-gcfk6                     1/1     Running   0          4m35s

NAME                                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
service/argocd-applicationset-controller   ClusterIP   10.96.193.91    <none>        7000/TCP                     4m35s
service/argocd-redis                       ClusterIP   10.96.153.239   <none>        6379/TCP                     4m35s
service/argocd-repo-server                 ClusterIP   10.96.70.110    <none>        8081/TCP                     4m35s
service/argocd-server                      NodePort    10.96.57.41     <none>        80:30080/TCP,443:30002/TCP   4m35s

NAME                                         ENDPOINTS                         AGE
endpoints/argocd-applicationset-controller   10.244.1.4:7000                   4m35s
endpoints/argocd-redis                       10.244.2.2:6379                   4m35s
endpoints/argocd-repo-server                 10.244.1.5:8081                   4m35s
endpoints/argocd-server                      10.244.2.3:8080,10.244.2.3:8080   4m35s

NAME                                  TYPE                 DATA   AGE
secret/argocd-initial-admin-secret    Opaque               1      4m11s
secret/argocd-notifications-secret    Opaque               0      4m35s
secret/argocd-redis                   Opaque               1      4m38s
secret/argocd-secret                  Opaque               3      4m35s
secret/sh.helm.release.v1.argocd.v1   helm.sh/release.v1   1      5m2s

NAME                                      DATA   AGE
configmap/argocd-cm                       9      4m35s
configmap/argocd-cmd-params-cm            32     4m35s
configmap/argocd-gpg-keys-cm              0      4m35s
configmap/argocd-notifications-cm         1      4m35s
configmap/argocd-rbac-cm                  4      4m35s
configmap/argocd-redis-health-configmap   2      4m35s
configmap/argocd-ssh-known-hosts-cm       1      4m35s
configmap/argocd-tls-certs-cm             0      4m35s
configmap/kube-root-ca.crt                1      6m16s
```

### **5. Argo CD ê´€ë ¨ CRD í™•ì¸**

```bash
kubectl get crd | grep argo
```

âœ…Â **ì¶œë ¥**

```bash
applications.argoproj.io      2025-04-11T15:04:20Z
applicationsets.argoproj.io   2025-04-11T15:04:20Z
appprojects.argoproj.io       2025-04-11T15:04:20Z
```

### **6. appproject ì„¤ì • í™•ì¸**

```bash
kubectl get appproject -n argocd -o yaml
```

âœ…Â **ì¶œë ¥**

```bash
apiVersion: v1
items:
- apiVersion: argoproj.io/v1alpha1
  kind: AppProject
  metadata:
    creationTimestamp: "2025-04-11T15:04:44Z"
    generation: 1
    name: default
    namespace: argocd
    resourceVersion: "1742"
    uid: 5e203a0e-a8fc-4786-9c35-8f39a20747e6
  spec:
    clusterResourceWhitelist:
    - group: '*'
      kind: '*'
    destinations:
    - namespace: '*'
      server: '*'
    sourceRepos:
    - '*'
  status: {}
kind: List
metadata:
  resourceVersion: ""
```

### **7. ìµœì´ˆ ì ‘ì† ì•”í˜¸ í™•ì¸**

```bash
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d ;echo
```

âœ…Â **ì¶œë ¥**

```bash
EKd6o4KbnaCIjo1r
```

### **8. Argo CD ì›¹ ì ‘ì†**

**(1) `http://127.0.0.1:30002` ì ‘ì† - `admin` /** `EKd6o4KbnaCIjo1r` (**ìµœì´ˆ ì ‘ì† ì•”í˜¸)**
![](https://velog.velcdn.com/images/tlsalswls123/post/3623560d-7c0e-4f7e-8f65-6e9b4970765d/image.png)

**(2) Argo CD ì´ˆê¸° ì§„ì… í™”ë©´**
![](https://velog.velcdn.com/images/tlsalswls123/post/15e52803-f122-4b4c-b739-33479cc46108/image.png)

---

## **ğŸ›¡ï¸ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ Vault ì„¤ì¹˜**

### **1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±**

```bash
kubectl create namespace vault

# ê²°ê³¼
namespace/vault created
```

### **2. Helm ë ˆí¬ì§€í† ë¦¬ ì¶”ê°€**

```bash
helm repo add hashicorp https://helm.releases.hashicorp.com

# ê²°ê³¼
"hashicorp" has been added to your repositories
```

### **3. Helm ì°¨íŠ¸ ì„¤ì •**

```bash
cat <<EOF > override-values.yaml
global:
  enabled: true
  tlsDisable: true  # Disable TLS for demo purposes

server:
  image:
    repository: "hashicorp/vault"
    tag: "1.19.0"

  standalone:
    enabled: true
    replicas: 1  # ë‹¨ì¼ ë…¸ë“œ ì‹¤í–‰

    config: |
      ui = true
      disable_mlock = true
      cluster_name = "vault-local"

      listener "tcp" {
        address = "[::]:8200"
        cluster_address = "[::]:8201"
        tls_disable = 1
      }

      storage "raft" { # Raft êµ¬ì„± ê¶Œì¥
        path = "/vault/data"
        node_id = "vault-dev-node-1"
      }
  service:
    enabled: true
    type: NodePort
    port: 8200
    targetPort: 8200
    nodePort: 30000   # Kindì—ì„œ ì—´ì–´ë‘” í¬íŠ¸ ì¤‘ í•˜ë‚˜ ì‚¬ìš©

injector:
  enabled: true

ui:
  enabled: true
  serviceType: "NodePort"
EOF
```

### **4. Helm ë°°í¬**

```bash
helm upgrade vault hashicorp/vault -n vault -f override-values.yaml --install
```

âœ…Â **ì¶œë ¥**

```bash
Release "vault" does not exist. Installing it now.
NAME: vault
LAST DEPLOYED: Sat Apr 12 09:36:54 2025
NAMESPACE: vault
STATUS: deployed
REVISION: 1
NOTES:
Thank you for installing HashiCorp Vault!

Now that you have deployed Vault, you should look over the docs on using
Vault with Kubernetes available here:

https://developer.hashicorp.com/vault/docs

Your release is named vault. To learn more about the release, try:

  $ helm status vault
  $ helm get manifest vault
```

### **5. ì´ˆê¸°í™” ì‹¤íŒ¨ - seal configuration missing**
![](https://velog.velcdn.com/images/tlsalswls123/post/d224f4cc-e788-4887-89a5-2e4899f0ab78/image.png)

### **6. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë³€ê²½ - vault**

```bash
kubens vault

# ê²°ê³¼
âœ” Active namespace is "vault"
```

### **7. ë°°í¬ ë¦¬ì†ŒìŠ¤ í™•ì¸**

```bash
k get pods,svc,pvc
```

âœ…Â **ì¶œë ¥**

```bash
NAME                                        READY   STATUS    RESTARTS   AGE
pod/vault-0                                 0/1     Running   0          8m41s
pod/vault-agent-injector-56459c7545-mlvpk   1/1     Running   0          8m41s

NAME                               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE
service/vault                      NodePort    10.96.131.159   <none>        8200:30000/TCP,8201:31414/TCP   8m42s
service/vault-agent-injector-svc   ClusterIP   10.96.138.201   <none>        443/TCP                         8m42s
service/vault-internal             ClusterIP   None            <none>        8200/TCP,8201/TCP               8m42s
service/vault-ui                   NodePort    10.96.88.15     <none>        8200:30367/TCP                  8m42s

NAME                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/data-vault-0   Bound    pvc-786c0621-e83c-4249-b11d-97ff827dea76   10Gi       RWO            standard       <unset>                 8m41s
```

### **8. Vault Status ëª…ë ¹ìœ¼ë¡œ Sealed ì—¬ë¶€ í™•ì¸**

```bash
kubectl exec -ti vault-0 -- vault status
```

âœ…Â **ì¶œë ¥**

```bash
Key                     Value
---                     -----
Seal Type               shamir
Initialized             false
Sealed                  true
Total Shares            0
Threshold               0
Unseal Progress         0/0
Unseal Nonce            n/a
Version                 1.19.0
Build Date              2025-03-04T12:36:40Z
Storage Type            raft
Removed From Cluster    false
HA Enabled              true
command terminated with exit code 2
```

### **9. Vault ì…¸ ì§„ì… í›„ ìƒíƒœ í™•ì¸**

```bash
kubectl exec -ti vault-0 -- sh          
/ $ vault status
```

âœ…Â **ì¶œë ¥**

```bash
Key                     Value
---                     -----
Seal Type               shamir
Initialized             false
Sealed                  true
Total Shares            0
Threshold               0
Unseal Progress         0/0
Unseal Nonce            n/a
Version                 1.19.0
Build Date              2025-03-04T12:36:40Z
Storage Type            raft
Removed From Cluster    false
HA Enabled              true
```

### **10. Vault ì´ˆê¸°í™”**

```bash
/ $ vault operator init
```

âœ…Â **ì¶œë ¥**

```bash
Unseal Key 1: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
Unseal Key 2: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
Unseal Key 3: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
Unseal Key 4: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
Unseal Key 5: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Initial Root Token: hvs.pR8v5IYFj6AFVuRgA6x1qiB4

Vault initialized with 5 key shares and a key threshold of 3. Please securely
distribute the key shares printed above. When the Vault is re-sealed,
restarted, or stopped, you must supply at least 3 of these keys to unseal it
before it can start servicing requests.

Vault does not store the generated root key. Without at least 3 keys to
reconstruct the root key, Vault will remain permanently sealed!

It is possible to generate new unseal keys, provided you have a quorum of
existing unseal keys shares. See "vault operator rekey" for more information.
```

- `Unseal Key` 5ê°œì™€ `Root Token` 1ê°œ ìƒì„±
- `Threshold`ëŠ” 3 (3ê°œì˜ í‚¤ ì…ë ¥ ì‹œ Unseal ê°€ëŠ¥)
- ì¶œë ¥ ë‚´ìš©ì„ `test.txt` ì— ë°±ì—…

### **11. Vault ì ê¸ˆ í•´ì œ (Unseal)**

```bash
/ $ vault operator unseal
Unseal Key (will be hidden): 
Key                     Value
---                     -----
Seal Type               shamir
Initialized             true
Sealed                  false
Total Shares            5
Threshold               3
Version                 1.19.0
Build Date              2025-03-04T12:36:40Z
Storage Type            raft
Cluster Name            vault-local
Cluster ID              d2f14a0a-7599-5013-56ee-a8fd901d7347
Removed From Cluster    false
HA Enabled              true
HA Cluster              n/a
HA Mode                 standby
Active Node Address     <none>
Raft Committed Index    32
Raft Applied Index      32
```

- 3ê°œì˜ Unseal Key ìˆœì°¨ ì…ë ¥
- `Sealed: false` ìƒíƒœë¡œ ì „í™˜ë¨

### **12. Vault ì¬ì„¤ì¹˜ë¥¼ ìœ„í•œ ì´ˆê¸°í™” ì‘ì—…**

**(1) Helmìœ¼ë¡œ Vault ì œê±°**

```bash
helm uninstall vault

# ê²°ê³¼
release "vault" uninstalled
```

**(2) PVC í™•ì¸ ë° ì‚­ì œ**

```bash
k get pvc
k delete pvc data-vault-0
```

âœ…Â **ì¶œë ¥**

```bash
NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
data-vault-0   Bound    pvc-786c0621-e83c-4249-b11d-97ff827dea76   10Gi       RWO            standard       <unset>                 26m

# ê²°ê³¼
persistentvolumeclaim "data-vault-0" deleted
```

- Unseal ì •ë³´ëŠ” PVCì— ì €ì¥ë˜ë¯€ë¡œ, ì™„ì „ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ ì‚­ì œ í•„ìš”

### **13. Vault ì¬ì„¤ì¹˜**

```bash
helm upgrade vault hashicorp/vault -n vault -f override-values.yaml --install
```

âœ…Â **ì¶œë ¥**

```bash
Release "vault" does not exist. Installing it now.
NAME: vault
LAST DEPLOYED: Sat Apr 12 10:07:46 2025
NAMESPACE: vault
STATUS: deployed
REVISION: 1
NOTES:
Thank you for installing HashiCorp Vault!

Now that you have deployed Vault, you should look over the docs on using
Vault with Kubernetes available here:

https://developer.hashicorp.com/vault/docs

Your release is named vault. To learn more about the release, try:

  $ helm status vault
  $ helm get manifest vault
```

### **14. Vault ì´ˆê¸°í™” & ìë™ Unseal ìŠ¤í¬ë¦½íŠ¸**

```bash
cat <<EOF > init-unseal.sh
#!/bin/bash

# Vault Pod ì´ë¦„
VAULT_POD="vault-0"

# Vault ëª…ë ¹ ì‹¤í–‰
VAULT_CMD="kubectl exec -ti \$VAULT_POD -- vault"

# ì¶œë ¥ ì €ì¥ íŒŒì¼
VAULT_KEYS_FILE="./vault-keys.txt"
UNSEAL_KEY_FILE="./vault-unseal-key.txt"
ROOT_TOKEN_FILE="./vault-root-token.txt"

# Vault ì´ˆê¸°í™” (Unseal Key 1ê°œë§Œ ìƒì„±ë˜ë„ë¡ ì„¤ì •)
\$VAULT_CMD operator init -key-shares=1 -key-threshold=1 | sed \$'s/\\x1b\\[[0-9;]*m//g' | tr -d '\r' > "\$VAULT_KEYS_FILE"

# Unseal Key / Root Token ì¶”ì¶œ
grep 'Unseal Key 1:' "\$VAULT_KEYS_FILE" | awk -F': ' '{print \$2}' > "\$UNSEAL_KEY_FILE"
grep 'Initial Root Token:' "\$VAULT_KEYS_FILE" | awk -F': ' '{print \$2}' > "\$ROOT_TOKEN_FILE"

# Unseal ìˆ˜í–‰
UNSEAL_KEY=\$(cat "\$UNSEAL_KEY_FILE")
\$VAULT_CMD operator unseal "\$UNSEAL_KEY"

# ê²°ê³¼ ì¶œë ¥
echo "[ğŸ”“] Vault Unsealed!"
echo "[ğŸ”] Root Token: \$(cat \$ROOT_TOKEN_FILE)"
EOF
```

### **15. ê¶Œí•œ ë¶€ì—¬ ë° ì‹¤í–‰**

```bash
chmod +x init-unseal.sh
./init-unseal.sh
```

âœ…Â **ì¶œë ¥**

```bash
Key                     Value
---                     -----
Seal Type               shamir
Initialized             true
Sealed                  false
Total Shares            1
Threshold               1
Version                 1.19.0
Build Date              2025-03-04T12:36:40Z
Storage Type            raft
Cluster Name            vault-local
Cluster ID              77026db4-001f-f2dc-a6ef-5f8ddae4593e
Removed From Cluster    false
HA Enabled              true
HA Cluster              n/a
HA Mode                 standby
Active Node Address     <none>
Raft Committed Index    32
Raft Applied Index      32
[ğŸ”“] Vault Unsealed!
[ğŸ”] Root Token: xxx.xxxxxxxxxxxxxxxxxxxxxxxx
```

### **16. Vault ì´ˆê¸°í™” ê²°ê³¼ íŒŒì¼**

**(1) `vault-keys.txt`**

```bash
Unseal Key 1: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Initial Root Token: xxx.xxxxxxxxxxxxxxxxxxxxxxxx

Vault initialized with 1 key shares and a key threshold of 1. Please securely
distribute the key shares printed above. When the Vault is re-sealed,
restarted, or stopped, you must supply at least 1 of these keys to unseal it
before it can start servicing requests.

Vault does not store the generated root key. Without at least 1 keys to
reconstruct the root key, Vault will remain permanently sealed!

It is possible to generate new unseal keys, provided you have a quorum of
existing unseal keys shares. See "vault operator rekey" for more information.
```

**(2) `vault-root-token.txt`**

```bash
xxx.xxxxxxxxxxxxxxxxxxxxxxxx
```

**(3) `vault-unseal-key.txt`**

```bash
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### **17. Vault í˜„ì¬ ìƒíƒœ í™•ì¸**

```bash
kubectl exec -ti vault-0 -- vault status
```

âœ…Â **ì¶œë ¥**

```bash
Key                     Value
---                     -----
Seal Type               shamir
Initialized             true
Sealed                  false
Total Shares            1
Threshold               1
Version                 1.19.0
Build Date              2025-03-04T12:36:40Z
Storage Type            raft
Cluster Name            vault-local
Cluster ID              79933d95-99a1-819d-4d5d-0b0a385371fa
Removed From Cluster    false
HA Enabled              true
HA Cluster              https://vault-0.vault-internal:8201
HA Mode                 active
Active Since            2025-04-12T04:05:44.351612642Z
Raft Committed Index    37
Raft Applied Index      37
```

- `Initialized`: true â†’ Vaultê°€ ì´ˆê¸°í™”ë¨
- `Sealed`: false â†’ í˜„ì¬ Unsealëœ ìƒíƒœ
- `Total Shares`: 1 / `Threshold`: 1 â†’ 1ê°œì˜ í‚¤ë¡œ Unseal ê°€ëŠ¥

### **18. Vault ì›¹ ì ‘ì†**

- **ì ‘ì†ì£¼ì†Œ**: `http://localhost:30000`
- **ì¸ì¦ë°©ì‹**: Token | **ì…ë ¥í• ê°’**: `vault-root-token.txt`ì— ì €ì¥ëœ ë£¨íŠ¸ í† í°
![](https://velog.velcdn.com/images/tlsalswls123/post/82022697-e98c-4f25-8f07-835b4b331d5f/image.png)
![](https://velog.velcdn.com/images/tlsalswls123/post/924fda34-7deb-4740-8761-59194a170984/image.png)

### **19. CLI ì„¤ì • - Arch Linux**

**(1) Vault ì„¤ì¹˜**

```bash
yay -S vault
```

**(2) NodePortë¡œ ê³µê°œí•œ 30000 Portë¡œ ì„¤ì •**

```bash
export VAULT_ADDR='http://localhost:30000'
```

**(3) vault ìƒíƒœí™•ì¸**

```bash
vault status
```

âœ…Â **ì¶œë ¥**

```bash
Key                     Value
---                     -----
Seal Type               shamir
Initialized             true
Sealed                  false
Total Shares            1
Threshold               1
Version                 1.19.0
Build Date              2025-03-04T12:36:40Z
Storage Type            raft
Cluster Name            vault-local
Cluster ID              79933d95-99a1-819d-4d5d-0b0a385371fa
Removed From Cluster    false
HA Enabled              true
HA Cluster              https://vault-0.vault-internal:8201
HA Mode                 active
Active Since            2025-04-12T04:05:44.351612642Z
Raft Committed Index    39
Raft Applied Index      39
```

**(4) Root Tokenìœ¼ë¡œ ë¡œê·¸ì¸**

```bash
vault login
```

âœ…Â **ì¶œë ¥**

```bash
Token (will be hidden): 
Success! You are now authenticated. The token information displayed below
is already stored in the token helper. You do NOT need to run "vault login"
again. Future Vault requests will automatically use this token.

Key                  Value
---                  -----
token                xxx.xxxxxxxxxxxxxxxxxxxxxxxx
token_accessor       xxxxxxxxxxxxxxxxxx
token_duration       âˆ
token_renewable      false
token_policies       ["root"]
identity_policies    []
policies             ["root"]
```

---

## **ğŸ“‚ KV ì‹œí¬ë¦¿ ì—”ì§„ í™œì„±í™” ë° ìƒ˜í”Œ êµ¬ì„±**

### **1. KV v2 í˜•íƒœë¡œ ì—”ì§„ í™œì„±í™”**

```bash
vault secrets enable -path=secret kv-v2
```

âœ…Â **ì¶œë ¥**

```bash
Success! Enabled the kv-v2 secrets engine at: secret/
```

**secret/ ì´ë¼ëŠ” ê²½ë¡œì˜ ì—”ì§„ í™œì„±í™”ë¨**
![](https://velog.velcdn.com/images/tlsalswls123/post/d129912b-f355-45cb-a5fd-3f7862dcad22/image.png)
![](https://velog.velcdn.com/images/tlsalswls123/post/dc8ae954-e595-4159-9102-43bce141e582/image.png)

### **2. ìƒ˜í”Œ ì‹œí¬ë¦¿ ì €ì¥**

```bash
vault kv put secret/sampleapp/config \
  username="demo" \
  password="p@ssw0rd"
```

âœ…Â **ì¶œë ¥**

```bash
======== Secret Path ========
secret/data/sampleapp/config

======= Metadata =======
Key                Value
---                -----
created_time       2025-04-12T04:25:34.411259907Z
custom_metadata    <nil>
deletion_time      n/a
destroyed          false
version            1
```

### **3. ì…ë ¥ëœ ë°ì´í„° í™•ì¸**

```bash
vault kv get secret/sampleapp/config
```

âœ…Â **ì¶œë ¥**

```bash
======== Secret Path ========
secret/data/sampleapp/config

======= Metadata =======
Key                Value
---                -----
created_time       2025-04-12T04:25:34.411259907Z
custom_metadata    <nil>
deletion_time      n/a
destroyed          false
version            1

====== Data ======
Key         Value
---         -----
password    p@ssw0rd
username    demo
```
![](https://velog.velcdn.com/images/tlsalswls123/post/707ce784-8836-45e1-9620-caec30b897ef/image.png)

---

## **ğŸš— Vault SideCar ì—°ë™**

### **1. AppRole ì¸ì¦ ë°©ì‹ í™œì„±í™”**

```bash
vault auth enable approle || echo "AppRole already enabled"

# ê²°ê³¼
Success! Enabled approle auth method at: approle/
```

### **2. Vault ì¸ì¦ ë°©ì‹ ëª©ë¡ í™•ì¸**

```bash
vault auth list
```

âœ…Â **ì¶œë ¥**

```bash
Path        Type       Accessor                 Description                Version
----        ----       --------                 -----------                -------
approle/    approle    auth_approle_92272f5e    n/a                        n/a
token/      token      auth_token_0e38c7c5      token based cred
```

### **3. ì •ì±… ìƒì„±**

```bash
vault policy write sampleapp-policy - <<EOF
path "secret/data/sampleapp/*" {
  capabilities = ["read"]
}
EOF

# ê²°ê³¼
Success! Uploaded policy: sampleapp-policy
```

### **4. AppRole Role ìƒì„±**

```bash
vault write auth/approle/role/sampleapp-role \
  token_policies="sampleapp-policy" \
  secret_id_ttl="1h" \
  token_ttl="1h" \
  token_max_ttl="4h"
  
# ê²°ê³¼
Success! Data written to: auth/approle/role/sample
```

### **5. Role ID ë° Secret ID ì¶”ì¶œ ë° ì €ì¥**

```bash
ROLE_ID=$(vault read -field=role_id auth/approle/role/sampleapp-role/role-id)
SECRET_ID=$(vault write -f -field=secret_id auth/approle/role/sampleapp-role/secret-id)

echo "ROLE_ID: $ROLE_ID"
echo "SECRET_ID: $SECRET_ID"
```

âœ…Â **ì¶œë ¥**

```bash
ROLE_ID: bdff9f53-ec1e-eb9b-db47-268b29f3e9b7
SECRET_ID: cbcf1705-4c45-50fa-010e-bf7dbdc58134
```

### **6. íŒŒì¼ë¡œ ì €ì¥**

```bash
mkdir -p approle-creds
echo "$ROLE_ID" > approle-creds/role_id.txt
echo "$SECRET_ID" > approle-creds/secret_id.txt
```

### **7. ì¿ ë²„ë„¤í‹°ìŠ¤ Secretìœ¼ë¡œ ì €ì¥**

```bash
kubectl create secret generic vault-approle -n vault \
  --from-literal=role_id="${ROLE_ID}" \
  --from-literal=secret_id="${SECRET_ID}" \
  --save-config \
  --dry-run=client -o yaml | kubectl apply -f -
  
# ê²°ê³¼
secret/vault-approle created
```

**k9s - `x ë‹¨ì¶•í‚¤` ì‹¤í–‰ ì‹œ, base64ë¡œ ë””ì½”ë”©ëœ ì •ë³´ íšë“**
![](https://velog.velcdn.com/images/tlsalswls123/post/083d8acd-2155-4326-a2b3-76a6d8a40e13/image.png)

### **8. Vault Agent Sidecar ì—°ë™**

**(1) Vault Agent ì„¤ì • íŒŒì¼ ì‘ì„± ë° ìƒì„± (`vault-agent-config.hcl`)**

```bash
cat <<EOF | kubectl create configmap vault-agent-config -n vault --from-file=agent-config.hcl=/dev/stdin --dry-run=client -o yaml | kubectl apply -f -
vault {
  address = "http://vault.vault.svc:8200"
}

auto_auth {
  method "approle" {
    config = {
      role_id_file_path = "/etc/vault/approle/role_id"
      secret_id_file_path = "/etc/vault/approle/secret_id"
      remove_secret_id_file_after_reading = false
    }
  }

  sink "file" {
    config = {
      path = "/etc/vault-agent-token/token"
    }
  }
}

template_config {
  static_secret_render_interval = "20s"
}

template {
  destination = "/etc/secrets/index.html"
  contents = <<EOH
  <html>
  <body>
    <p>username: {{ with secret "secret/data/sampleapp/config" }}{{ .Data.data.username }}{{ end }}</p>
    <p>password: {{ with secret "secret/data/sampleapp/config" }}{{ .Data.data.password }}{{ end }}</p>
  </body>
  </html>
EOH
}
EOF

# ê²°ê³¼
configmap/vault-agent-config created
```

**(2) ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ + Sidecar ë°°í¬(ìˆ˜ë™ë°©ì‹)**

Nginx + Vault Agent ìƒì„±

```bash
kubectl apply -n vault -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-vault-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-vault-demo
  template:
    metadata:
      labels:
        app: nginx-vault-demo
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: html-volume
          mountPath: /usr/share/nginx/html
      - name: vault-agent-sidecar
        image: hashicorp/vault:latest
        args:
          - "agent"
          - "-config=/etc/vault/agent-config.hcl"
        volumeMounts:
        - name: vault-agent-config
          mountPath: /etc/vault
        - name: vault-approle
          mountPath: /etc/vault/approle
        - name: vault-token
          mountPath: /etc/vault-agent-token
        - name: html-volume
          mountPath: /etc/secrets
      volumes:
      - name: vault-agent-config
        configMap:
          name: vault-agent-config
      - name: vault-approle
        secret:
          secretName: vault-approle
      - name: vault-token
        emptyDir: {}
      - name: html-volume
        emptyDir: {}
EOF

# ê²°ê³¼
deployment.apps/nginx-vault-demo created
```

**(3) SVC ìƒì„±**

```bash
kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nginx-vault-demo
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30001 # Kindì—ì„œ ì„¤ì •í•œ Port
EOF

# ê²°ê³¼
service/nginx-service created
```

**(4) ìƒì„±ëœ ì»¨í…Œì´ë„ˆ í™•ì¸**

```bash
kubectl get pod -l app=nginx-vault-demo
```

âœ…Â **ì¶œë ¥**

```bash
NAME                                READY   STATUS    RESTARTS   AGE
nginx-vault-demo-7776649597-cn69g   2/2     Running   0          94s
```
![](https://velog.velcdn.com/images/tlsalswls123/post/e5aeea41-02f0-49a9-ab64-b2bbec3c8ad7/image.png)

**(5) vault-agent-sidecar ì…¸ë¡œ ì§„ì…**
![](https://velog.velcdn.com/images/tlsalswls123/post/d7d1020c-b4f5-433d-b0fc-1f3ded6a5a42/image.png)

**(6) nginx ì…¸ë¡œ ì§„ì…**
![](https://velog.velcdn.com/images/tlsalswls123/post/fb66abaa-455d-416e-8659-36f86e9c7139/image.png)

**(7) `localhost:30001` ì§„ì…**
![](https://velog.velcdn.com/images/tlsalswls123/post/fb1a282c-d110-4e7a-a90a-8d0ee35f9b40/image.png)

**(8) create new version + í´ë¦­**
![](https://velog.velcdn.com/images/tlsalswls123/post/4cbc7efe-60c8-4650-90e5-dabfa05ac8ea/image.png)

**(9) new-p@ssw0rdë¡œ ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ í›„, save ë²„íŠ¼ í´ë¦­**
![](https://velog.velcdn.com/images/tlsalswls123/post/f0216735-2647-4504-bb76-18c0b6cf01f6/image.png)

**(10) version2 ìƒì„± ì™„ë£Œ**
![](https://velog.velcdn.com/images/tlsalswls123/post/9fb57ef6-40d8-4320-8b8a-a867aaca947a/image.png)

**(11) version2 ë°˜ì˜ í™•ì¸**
![](https://velog.velcdn.com/images/tlsalswls123/post/60406813-4aaa-4ac1-955a-09dece0e8d8b/image.png)

```bash
root@nginx-vault-demo-7776649597-cn69g:/usr/share/nginx/html# curl localhost
```

âœ…Â **ì¶œë ¥**

```bash
  <html>
  <body>
    <p>username: demo</p>
    <p>password: new-p@ssw0rd</p>
  </body>
  </html>
```

**(12) Mutating Admission Webhook ì„¤ì • ëª©ë¡ ì¡°íšŒ**

```bash
kubectl get mutatingwebhookconfigurations.admissionregistration.k8s.io
```

âœ…Â **ì¶œë ¥**

```bash
NAME                       WEBHOOKS   AGE
vault-agent-injector-cfg   1          65
```

---

## **ğŸ” Jenkins + Vault (AppRole) - CI**

### **1. ì  í‚¨ìŠ¤ì—ì„œ Vault í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜**

**(1) Manage Jenkins â†’ Plugins â†’ Available pluginsì—ì„œ `Vault` ê²€ìƒ‰**
![](https://velog.velcdn.com/images/tlsalswls123/post/3684ac8c-8407-42ca-9699-ed4daba6b333/image.png)

**(2) HashiCorp Vault Plugin ì„¤ì¹˜ í›„ ì  í‚¨ìŠ¤ ì¬ì‹œì‘**
![](https://velog.velcdn.com/images/tlsalswls123/post/c9210cff-3d6b-4d34-b5a5-81869d26c92e/image.png)

### **2. Role ID ë° Secret ID ì¶”ì¶œ**

```bash
ROLE_ID=$(vault read -field=role_id auth/approle/role/sampleapp-role/role-id)
SECRET_ID=$(vault write -f -field=secret_id auth/approle/role/sampleapp-role/secret-id)

echo "ROLE_ID: $ROLE_ID"
echo "SECRET_ID: $SECRET_ID"
```

âœ…Â **ì¶œë ¥**

```bash
ROLE_ID: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx     
SECRET_ID: cbcf1705-4c45-50fa-010e-bf7dbdc58134
```

### **3.  Vault í”ŒëŸ¬ê·¸ì¸ ì„¤ì •**

**(1) Vault URL ì…ë ¥ í›„ [Add] ë²„íŠ¼ í´ë¦­**
![](https://velog.velcdn.com/images/tlsalswls123/post/6df1ba73-9cc3-41bc-b148-f7ed2627983c/image.png)

**(2) Vault Credentials**

- ì¢…ë¥˜: **Vault AppRole Credential**
- Role ID & Secret ID ì…ë ¥
- IDëŠ” ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ì´ë¦„ìœ¼ë¡œ ì§€ì • (ex. `vault-approle-creds`)

![](https://velog.velcdn.com/images/tlsalswls123/post/cd47a855-068e-4636-870d-bded6516b77d/image.png)

**(3) ì„¤ì • ì™„ë£Œ**
![](https://velog.velcdn.com/images/tlsalswls123/post/417c585f-8957-495f-a107-dd2e93408c31/image.png)

### **4. ì  í‚¨ìŠ¤ íŒŒì´í”„ë¼ì¸ ìƒì„±**

**(1) New Item â†’ Pipeline ì„ íƒ**

**(2) `jenkins-vault-kv` ì…ë ¥ í›„ ìƒì„±**
![](https://velog.velcdn.com/images/tlsalswls123/post/3fbd106d-0b69-44be-b601-a34f55115a07/image.png)

**(3) Jenkinsfile ì‘ì„±**

```bash
ifconfig | grep -n 192
79:        inet 192.168.219.103  netmask 255.255.255.0  broadcast 192.168.219.255
```

```bash
pipeline {
  agent any

  environment {
    VAULT_ADDR = 'http://192.168.219.103:30000' // ì‹¤ì œ Vault ì£¼ì†Œë¡œ ë³€ê²½!!!
  }

  stages {
    stage('Read Vault Secret') {
      steps {
        withVault([
          vaultSecrets: [
            [
              path: 'secret/sampleapp/config',
              engineVersion: 2,
              secretValues: [
                [envVar: 'USERNAME', vaultKey: 'username'],
                [envVar: 'PASSWORD', vaultKey: 'password']
              ]
            ]
          ],
          configuration: [
            vaultUrl: "${VAULT_ADDR}",
            vaultCredentialId: 'vault-approle-creds'
          ]
        ]) {
          sh '''
            echo "Username from Vault: $USERNAME"
            echo "Password from Vault: $PASSWORD"
          '''
          script {
            echo "Username (env): ${env.USERNAME}"
            echo "Password (env): ${env.PASSWORD}"
          }
        }
      }
    }
  }
}
```

**(4) ì €ì¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/1d22616f-2315-4022-85fb-046bd6b36520/image.png)

**(5) Vault URL ì£¼ì†Œ â†’ IP ì£¼ì†Œë¡œ ë³€ê²½**: ë¹Œë“œ ì—ëŸ¬ ì›ì¸
![](https://velog.velcdn.com/images/tlsalswls123/post/c5b9c1bd-dde8-424a-88cb-05eb9b583456/image.png)

**(6) ì  í‚¨ìŠ¤ ì‹¤í–‰ ê²°ê³¼**
![](https://velog.velcdn.com/images/tlsalswls123/post/4e2a0c4d-f03c-4777-a1b2-5846aab25f5c/image.png)

---

## **ğŸ” ArgoCD + Vault Plugin (Kubernetes Auth/AppRole) - CD**

### **1. AppRole ê¸°ë°˜ Vault ì¸ì¦ ì •ë³´ ë“±ë¡**

```bash
kubectl apply -f - <<EOF
kind: Secret
apiVersion: v1
metadata:
  name: argocd-vault-plugin-credentials
  namespace: argocd
type: Opaque
stringData:
  VAULT_ADDR: "http://vault.vault:8200"
  AVP_TYPE: "vault"
  AVP_AUTH_TYPE: "approle"
  AVP_ROLE_ID: bdff9f53-ec1e-eb9b-db47-268b29f3e9b7 # Role_ID
  AVP_SECRET_ID: cbcf1705-4c45-50fa-010e-bf7dbdc58134 # Secret_ID
EOF

# ê²°ê³¼
secret/argocd-vault-plugin-credentials created
```

**`argocd-vault-plugin-credentials` í™•ì¸**
![](https://velog.velcdn.com/images/tlsalswls123/post/46c030ee-9dcb-449a-b61a-03c97e7d53b3/image.png)

### **2. argocdë¡œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë³€ê²½**

```bash
kubens argocd
# ê²°ê³¼
âœ” Active namespace is "argocd"
```

### **3. ArgoCD Vault í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ ë° êµ¬ì„±**

**(1) í”ŒëŸ¬ê·¸ì¸ ë©”ë‹ˆí˜ìŠ¤íŠ¸ ì¤€ë¹„**

```bash
git clone https://github.com/hyungwook0221/argocd-vault-plugin.git
cd argocd-vault-plugin/manifests/cmp-sidecar

# ê²°ê³¼
Cloning into 'argocd-vault-plugin'...
remote: Enumerating objects: 2610, done.
remote: Counting objects: 100% (256/256), done.
remote: Compressing objects: 100% (128/128), done.
remote: Total 2610 (delta 191), reused 128 (delta 128), pack-reused 2354 (from 2)
Receiving objects: 100% (2610/2610), 1.72 MiB | 10.33 MiB/s, done.
Resolving deltas: 100% (1539/1539), done.
```

**(2) ìƒì„±ë  ë©”ë‹ˆí˜ìŠ¤íŠ¸ í™•ì¸**

```bash
kubectl kustomize .
```

âœ…Â **ì¶œë ¥**

```bash
apiVersion: v1
data:
  avp-helm.yaml: "---\napiVersion: argoproj.io/v1alpha1\nkind: ConfigManagementPlugin\nmetadata:\n
    \ name: argocd-vault-plugin-helm\nspec:\n  allowConcurrency: true\n\n  # Note:
    this command is run _before_ any Helm templating is done, therefore the logic
    is to check\n  # if this looks like a Helm chart\n  discover:\n    find:\n      command:\n
    \       - sh\n        - \"-c\"\n        - \"find . -name 'Chart.yaml' && find
    . -name 'values.yaml'\"\n  generate:\n    # **IMPORTANT**: passing `${ARGOCD_ENV_HELM_ARGS}`
    effectively allows users to run arbitrary code in the Argo CD \n    # repo-server
    (or, if using a sidecar, in the plugin sidecar). Only use this when the users
    are completely trusted. If\n    # possible, determine which Helm arguments are
    needed by your users and explicitly pass only those arguments.\n    command:\n
    \     - sh\n      - \"-c\"\n      - |\n        helm template $ARGOCD_APP_NAME
    -n $ARGOCD_APP_NAMESPACE ${ARGOCD_ENV_HELM_ARGS} . |\n        argocd-vault-plugin
    generate -\n  lockRepo: false\n"
  avp-kustomize.yaml: |
    ---
    apiVersion: argoproj.io/v1alpha1
    kind: ConfigManagementPlugin
    metadata:
      name: argocd-vault-plugin-kustomize
    spec:
      allowConcurrency: true

      # Note: this command is run _before_ anything is done, therefore the logic is to check
      # if this looks like a Kustomize bundle
      discover:
        find:
          command:
            - find
            - "."
            - -name
            - kustomization.yaml
      generate:
        command:
          - sh
          - "-c"
          - "kustomize build . | argocd-vault-plugin generate -"
      lockRepo: false
  avp.yaml: |
    apiVersion: argoproj.io/v1alpha1
    kind: ConfigManagementPlugin
    metadata:
      name: argocd-vault-plugin
    spec:
      allowConcurrency: true
      discover:
        find:
          command:
            - sh
            - "-c"
            - "find . -name '*.yaml' | xargs -I {} grep \"<path\\|avp\\.kubernetes\\.io\" {} | grep ."
      generate:
        command:
          - argocd-vault-plugin
          - generate
          - "."
      lockRepo: false
kind: ConfigMap
metadata:
  name: cmp-plugin
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: argocd-repo-server
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: argocd-repo-server
  template:
    metadata:
      labels:
        app.kubernetes.io/name: argocd-repo-server
    spec:
      automountServiceAccountToken: true
      containers:
      - command:
        - /var/run/argocd/argocd-cmp-server
        envFrom:
        - secretRef:
            name: argocd-vault-plugin-credentials
        image: quay.io/argoproj/argocd:v2.7.9
        name: avp-helm
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
        volumeMounts:
        - mountPath: /var/run/argocd
          name: var-files
        - mountPath: /home/argocd/cmp-server/plugins
          name: plugins
        - mountPath: /tmp
          name: tmp
        - mountPath: /home/argocd/cmp-server/config/plugin.yaml
          name: cmp-plugin
          subPath: avp-helm.yaml
        - mountPath: /usr/local/bin/argocd-vault-plugin
          name: custom-tools
          subPath: argocd-vault-plugin
      - command:
        - /var/run/argocd/argocd-cmp-server
        image: quay.io/argoproj/argocd:v2.7.9
        name: avp-kustomize
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
        volumeMounts:
        - mountPath: /var/run/argocd
          name: var-files
        - mountPath: /home/argocd/cmp-server/plugins
          name: plugins
        - mountPath: /tmp
          name: tmp
        - mountPath: /home/argocd/cmp-server/config/plugin.yaml
          name: cmp-plugin
          subPath: avp-kustomize.yaml
        - mountPath: /usr/local/bin/argocd-vault-plugin
          name: custom-tools
          subPath: argocd-vault-plugin
      - command:
        - /var/run/argocd/argocd-cmp-server
        image: quay.io/argoproj/argocd:v2.7.9
        name: avp
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
        volumeMounts:
        - mountPath: /var/run/argocd
          name: var-files
        - mountPath: /home/argocd/cmp-server/plugins
          name: plugins
        - mountPath: /tmp
          name: tmp
        - mountPath: /home/argocd/cmp-server/config/plugin.yaml
          name: cmp-plugin
          subPath: avp.yaml
        - mountPath: /usr/local/bin/argocd-vault-plugin
          name: custom-tools
          subPath: argocd-vault-plugin
      - image: quay.io/argoproj/argocd:v2.8.13
        name: repo-server
      initContainers:
      - args:
        - curl -L https://github.com/argoproj-labs/argocd-vault-plugin/releases/download/v$(AVP_VERSION)/argocd-vault-plugin_$(AVP_VERSION)_linux_amd64
          -o argocd-vault-plugin && chmod +x argocd-vault-plugin && mv argocd-vault-plugin
          /custom-tools/
        command:
        - sh
        - -c
        env:
        - name: AVP_VERSION
          value: 1.18.0
        image: registry.access.redhat.com/ubi8
        name: download-tools
        volumeMounts:
        - mountPath: /custom-tools
          name: custom-tools
      volumes:
      - configMap:
          name: cmp-plugin
        name: cmp-plugin
      - emptyDir: {}
        name: custom-tools
```

**(3) -k ì˜µì…˜ìœ¼ë¡œ kusomize ì‹¤í–‰**

```bash
kubectl apply -n argocd -k .

# ê²°ê³¼
configmap/cmp-plugin created
Warning: resource deployments/argocd-repo-server is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
deployment.apps/argocd-repo-server configured
```
![](https://velog.velcdn.com/images/tlsalswls123/post/f9bbdcfd-4c76-4d5d-a0ba-e059bbba0e67/image.png)
![](https://velog.velcdn.com/images/tlsalswls123/post/dac5e3df-eee5-43d0-a11d-0fdc3cc60c4c/image.png)

### **4. Helm ê¸°ë°˜ Application ë°°í¬ with Vault Plugin**

- GitHubì— ì €ì¥ëœ Helm Repoì„ ë°°í¬í•˜ë©°, Helm ë©”ë‹ˆí˜ìŠ¤íŠ¸ ë‚´ì— ë³€ìˆ˜ë¡œ ì¹˜í™˜ëœ ê°’(username/password)ì„ CD ë‹¨ê³„ì—ì„œ Vault í†µí•´ì„œ ì½ê³  ë Œë”ë§í•˜ì—¬ ë°°í¬

```bash
kubectl apply -n argocd -f - <<EOF
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: demo
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    namespace: argocd
    server: https://kubernetes.default.svc
  project: default
  source:
    path: infra/helm
    repoURL: https://github.com/hyungwook0221/spring-boot-debug-app
    targetRevision: main
    plugin:
      name: argocd-vault-plugin-helm
      env:
        - name: HELM_ARGS
          value: -f new-values.yaml
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
EOF

# ê²°ê³¼
application.argoproj.io/demo created
```
![](https://velog.velcdn.com/images/tlsalswls123/post/f0572441-d654-457b-8113-07ff8adbac06/image.png)


