---
title: Cilium 3ì£¼ì°¨ ì •ë¦¬
date: 2025-08-01 16:30:00 +0900
categories: [Cilium]
tags: [Cilium]
---
## **ğŸ”§ ì‹¤ìŠµ í™˜ê²½ êµ¬ì„±**
![](https://velog.velcdn.com/images/tlsalswls123/post/535a0a2e-ea37-49e2-b22a-d50c89a7f0f1/image.png)
- **í´ëŸ¬ìŠ¤í„° ë…¸ë“œ**
    - ì»¨íŠ¸ë¡¤ í”Œë ˆì¸: `192.168.10.100` (ë©”ëª¨ë¦¬ 2GB â†’ 2.5GB ìƒí–¥)
    - ì›Œì»¤ ë…¸ë“œ: `192.168.10.101` (1ëŒ€)
    - ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­: `192.168.10.0/24`
    - ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì— taint ì œê±° â†’ íŒŒë“œ ë°°í¬ ê°€ëŠ¥
    - `kubeadm-init-ctr-config.yaml` ì‚¬ìš© ì‹œ ë²„ì „ ë³€ìˆ˜ `K8S_VERSION_PLACEHOLDER`ë¡œ ì¬ì‚¬ìš©ì„± í™•ë³´
- **ë¼ìš°í„°**
    - ì£¼ì†Œ: `192.168.10.200`
    - ì‚¬ë‚´ë§(10.10.0.0/16)ê³¼ ì¿ ë²„ë„¤í‹°ìŠ¤ ë„¤íŠ¸ì›Œí¬(192.168.10.0/24) ê°„ í†µì‹  ì¤‘ê³„
    - static route ì„¤ì •:
        
        `to: 10.10.0.0/16 â†’ via: 192.168.10.200`
        
    - IP forwarding í™œì„±í™”
    - dummy ì¸í„°í˜ì´ìŠ¤ 2ê°œ ìƒì„±
        - `loop1`: 10.10.1.200
        - `loop2`: 10.10.2.200

## **ğŸš€ ì‹¤ìŠµ í™˜ê²½ ë°°í¬**

### **1. Vagrantfile ë‹¤ìš´ë¡œë“œ ë° ê°€ìƒë¨¸ì‹  êµ¬ì„±**

```bash
curl -O https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/3w/Vagrantfile

vagrant up
```

âœ…Â **ì¶œë ¥**

```bash
Bringing machine 'k8s-ctr' up with 'virtualbox' provider...
Bringing machine 'k8s-w1' up with 'virtualbox' provider...
Bringing machine 'router' up with 'virtualbox' provider...
==> k8s-ctr: Preparing master VM for linked clones...
    k8s-ctr: This is a one time operation. Once the master VM is prepared,
    k8s-ctr: it will be used as a base for linked clones, making the creation
    k8s-ctr: of new VMs take milliseconds on a modern system.
==> k8s-ctr: Importing base box 'bento/ubuntu-24.04'...
==> k8s-ctr: Cloning VM...
==> k8s-ctr: Matching MAC address for NAT networking...
==> k8s-ctr: Checking if box 'bento/ubuntu-24.04' version '202502.21.0' is up to date...
==> k8s-ctr: Setting the name of the VM: k8s-ctr
==> k8s-ctr: Clearing any previously set network interfaces...
==> k8s-ctr: Preparing network interfaces based on configuration...
    k8s-ctr: Adapter 1: nat
    k8s-ctr: Adapter 2: hostonly
==> k8s-ctr: Forwarding ports...
    k8s-ctr: 22 (guest) => 60000 (host) (adapter 1)
==> k8s-ctr: Running 'pre-boot' VM customizations...
==> k8s-ctr: Booting VM...
==> k8s-ctr: Waiting for machine to boot. This may take a few minutes...
    k8s-ctr: SSH address: 127.0.0.1:60000
    k8s-ctr: SSH username: vagrant
    k8s-ctr: SSH auth method: private key
    k8s-ctr: 
    k8s-ctr: Vagrant insecure key detected. Vagrant will automatically replace
    k8s-ctr: this with a newly generated keypair for better security.
    k8s-ctr: 
    k8s-ctr: Inserting generated public key within guest...
    k8s-ctr: Removing insecure key from the guest if it's present...
    k8s-ctr: Key inserted! Disconnecting and reconnecting using new SSH key...
==> k8s-ctr: Machine booted and ready!
==> k8s-ctr: Checking for guest additions in VM...
==> k8s-ctr: Setting hostname...
==> k8s-ctr: Configuring and enabling network interfaces...
==> k8s-ctr: Running provisioner: shell...
    k8s-ctr: Running: /tmp/vagrant-shell20250730-27828-acul9.sh
    k8s-ctr: >>>> Initial Config Start <<<<
    k8s-ctr: [TASK 1] Setting Profile & Bashrc
    k8s-ctr: [TASK 2] Disable AppArmor
    k8s-ctr: [TASK 3] Disable and turn off SWAP
    k8s-ctr: [TASK 4] Install Packages
    k8s-ctr: [TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)
    k8s-ctr: [TASK 6] Install Packages & Helm
    k8s-ctr: >>>> Initial Config End <<<<
==> k8s-ctr: Running provisioner: shell...
    k8s-ctr: Running: /tmp/vagrant-shell20250730-27828-zl78rn.sh
    k8s-ctr: >>>> K8S Controlplane config Start <<<<
    k8s-ctr: [TASK 1] Initial Kubernetes
    k8s-ctr: [TASK 2] Setting kube config file
    k8s-ctr: [TASK 3] Source the completion
    k8s-ctr: [TASK 4] Alias kubectl to k
    k8s-ctr: [TASK 5] Install Kubectx & Kubens
    k8s-ctr: [TASK 6] Install Kubeps & Setting PS1
    k8s-ctr: [TASK 7] Install Cilium CNI
    k8s-ctr: [TASK 8] Install Cilium / Hubble CLI
    k8s-ctr: cilium
    k8s-ctr: hubble
    k8s-ctr: [TASK 9] Remove node taint
    k8s-ctr: node/k8s-ctr untainted
    k8s-ctr: [TASK 10] local DNS with hosts file
    k8s-ctr: [TASK 11] Install Prometheus & Grafana
    k8s-ctr: [TASK 12] Dynamically provisioning persistent local storage with Kubernetes
    k8s-ctr: >>>> K8S Controlplane Config End <<<<
==> k8s-ctr: Running provisioner: shell...
    k8s-ctr: Running: /tmp/vagrant-shell20250730-27828-7fwjno.sh
    k8s-ctr: >>>> Route Add Config Start <<<<
    k8s-ctr: >>>> Route Add Config End <<<<
==> k8s-w1: Cloning VM...
==> k8s-w1: Matching MAC address for NAT networking...
==> k8s-w1: Checking if box 'bento/ubuntu-24.04' version '202502.21.0' is up to date...
==> k8s-w1: Setting the name of the VM: k8s-w1
==> k8s-w1: Clearing any previously set network interfaces...
==> k8s-w1: Preparing network interfaces based on configuration...
    k8s-w1: Adapter 1: nat
    k8s-w1: Adapter 2: hostonly
==> k8s-w1: Forwarding ports...
    k8s-w1: 22 (guest) => 60001 (host) (adapter 1)
==> k8s-w1: Running 'pre-boot' VM customizations...
==> k8s-w1: Booting VM...
==> k8s-w1: Waiting for machine to boot. This may take a few minutes...
    k8s-w1: SSH address: 127.0.0.1:60001
    k8s-w1: SSH username: vagrant
    k8s-w1: SSH auth method: private key
    k8s-w1: 
    k8s-w1: Vagrant insecure key detected. Vagrant will automatically replace
    k8s-w1: this with a newly generated keypair for better security.
    k8s-w1: 
    k8s-w1: Inserting generated public key within guest...
    k8s-w1: Removing insecure key from the guest if it's present...
    k8s-w1: Key inserted! Disconnecting and reconnecting using new SSH key...
==> k8s-w1: Machine booted and ready!
==> k8s-w1: Checking for guest additions in VM...
==> k8s-w1: Setting hostname...
==> k8s-w1: Configuring and enabling network interfaces...
==> k8s-w1: Running provisioner: shell...
    k8s-w1: Running: /tmp/vagrant-shell20250730-27828-km5kmk.sh
    k8s-w1: >>>> Initial Config Start <<<<
    k8s-w1: [TASK 1] Setting Profile & Bashrc
    k8s-w1: [TASK 2] Disable AppArmor
    k8s-w1: [TASK 3] Disable and turn off SWAP
    k8s-w1: [TASK 4] Install Packages
    k8s-w1: [TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)
    k8s-w1: [TASK 6] Install Packages & Helm
    k8s-w1: >>>> Initial Config End <<<<
==> k8s-w1: Running provisioner: shell...
    k8s-w1: Running: /tmp/vagrant-shell20250730-27828-fmg78c.sh
    k8s-w1: >>>> K8S Node config Start <<<<
    k8s-w1: [TASK 1] K8S Controlplane Join
    k8s-w1: >>>> K8S Node config End <<<<
==> k8s-w1: Running provisioner: shell...
    k8s-w1: Running: /tmp/vagrant-shell20250730-27828-ila0lv.sh
    k8s-w1: >>>> Route Add Config Start <<<<
    k8s-w1: >>>> Route Add Config End <<<<
==> router: Cloning VM...
==> router: Matching MAC address for NAT networking...
==> router: Checking if box 'bento/ubuntu-24.04' version '202502.21.0' is up to date...
==> router: Setting the name of the VM: router
==> router: Clearing any previously set network interfaces...
==> router: Preparing network interfaces based on configuration...
    router: Adapter 1: nat
    router: Adapter 2: hostonly
==> router: Forwarding ports...
    router: 22 (guest) => 60009 (host) (adapter 1)
==> router: Running 'pre-boot' VM customizations...
==> router: Booting VM...
==> router: Waiting for machine to boot. This may take a few minutes...
    router: SSH address: 127.0.0.1:60009
    router: SSH username: vagrant
    router: SSH auth method: private key
    router: Warning: Connection reset. Retrying...
    router: 
    router: Vagrant insecure key detected. Vagrant will automatically replace
    router: this with a newly generated keypair for better security.
    router: 
    router: Inserting generated public key within guest...
    router: Removing insecure key from the guest if it's present...
    router: Key inserted! Disconnecting and reconnecting using new SSH key...
==> router: Machine booted and ready!
==> router: Checking for guest additions in VM...
==> router: Setting hostname...
==> router: Configuring and enabling network interfaces...
==> router: Running provisioner: shell...
    router: Running: /tmp/vagrant-shell20250730-27828-2x1jkp.sh
    router: >>>> Initial Config Start <<<<
    router: [TASK 1] Setting Profile & Bashrc
    router: [TASK 2] Disable AppArmor
    router: [TASK 3] Add Kernel setting - IP Forwarding
    router: [TASK 4] Setting Dummy Interface
    router: [TASK 5] Install Packages
    router: [TASK 6] Install Apache
    router: >>>> Initial Config End <<<<
```

### **2. ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œ ì ‘ì†**

```bash
vagrant ssh k8s-ctr
```

âœ…Â **ì¶œë ¥**

```bash
Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-53-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Wed Jul 30 02:46:22 PM KST 2025

  System load:           0.28
  Usage of /:            29.2% of 30.34GB
  Memory usage:          51%
  Swap usage:            0%
  Processes:             217
  Users logged in:       0
  IPv4 address for eth0: 10.0.2.15
  IPv6 address for eth0: fd17:625c:f037:2:a00:27ff:fe6b:69c9

This system is built by the Bento project by Chef Software
More information can be found at https://github.com/chef/bento

Use of this system is acceptance of the OS vendor EULA and License Agreements.
(âˆ|HomeLab:N/A) root@k8s-ctr:~# 
```

### **3. ì›Œì»¤ ë…¸ë“œ SSH í†µì‹  í™•ì¸**

ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì—ì„œ ì›Œì»¤ ë…¸ë“œì— SSH ì ‘ì† í™•ì¸

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w1 hostname
```

âœ…Â **ì¶œë ¥**

```bash
Warning: Permanently added 'k8s-w1' (ED25519) to the list of known hosts.
k8s-w1
```

### **4. í´ëŸ¬ìŠ¤í„° ë„¤íŠ¸ì›Œí¬ CIDR í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl cluster-info dump | grep -m 2 -E "cluster-cidr|service-cluster-ip-range"
```

âœ…Â **ì¶œë ¥**

```bash
                            "--service-cluster-ip-range=10.96.0.0/16",
                            "--cluster-cidr=10.244.0.0/16",
```

### **5. ë…¸ë“œ ìƒíƒœ ë° ë‚´ë¶€ IP í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get node -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME      STATUS   ROLES           AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
k8s-ctr   Ready    control-plane   7m38s   v1.33.2   192.168.10.100   <none>        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27
k8s-w1    Ready    <none>          5m38s   v1.33.2   192.168.10.101   <none>        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27
```

- ë‚´ë¶€ IP í™•ì¸ ê°€ëŠ¥ (`192.168.10.100`, `192.168.10.101`)

### **6. ì¿ ë²„ë„¤í‹°ìŠ¤ IPAM ë° íŒŒë“œ ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸**

**(1) ë…¸ë“œë³„ Pod CIDR í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'
```

âœ…Â **ì¶œë ¥**

```bash
k8s-ctr	10.244.0.0/24
k8s-w1	10.244.1.0/24
```

- `kube-controller-manager`ê°€ ê° ë…¸ë“œì— í• ë‹¹í•œ Pod CIDR í™•ì¸

**(2) Ciliumì´ ì‚¬ìš©í•˜ëŠ” Pod CIDR í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode -o json | grep podCIDRs -A2
```

âœ…Â **ì¶œë ¥**

```bash
                    "podCIDRs": [
                        "10.244.0.0/24"
                    ],
--
                    "podCIDRs": [
                        "10.244.1.0/24"
                    ],
```

- `CiliumNode` ë¦¬ì†ŒìŠ¤ë¥¼ í†µí•´ ê° ë…¸ë“œê°€ ì¸ì‹í•˜ê³  ìˆëŠ” Pod CIDR í™•ì¸

**(3) IPAM ëª¨ë“œ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium config view | grep ^ipam
```

âœ…Â **ì¶œë ¥**

```bash
ipam                                              kubernetes
ipam-cilium-node-update-rate                      15s
```

- `kubernetes` ëª¨ë“œì¼ ê²½ìš° Kubernetesê°€ IPë¥¼ í• ë‹¹í•˜ê³ , Ciliumì€ ê·¸ê²ƒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•¨

**(4) Cilium ì—”ë“œí¬ì¸íŠ¸ IP í™•ì¸**

`ciliumendpoints` ë¦¬ì†ŒìŠ¤ë¥¼ ì¡°íšŒí•˜ì—¬ íŒŒë“œì— ë¶€ì—¬ëœ ì‹¤ì œ IP í™•ì¸

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumendpoints -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
cilium-monitoring    grafana-5c69859d9-wdb82                   22795               ready            10.244.0.104   
cilium-monitoring    prometheus-6fc896bc5d-bxnd5               1213                ready            10.244.0.65    
kube-system          coredns-674b8bbfcf-9pxvx                  28565               ready            10.244.0.199   
kube-system          coredns-674b8bbfcf-khjhq                  28565               ready            10.244.0.59    
kube-system          hubble-relay-5dcd46f5c-5r79v              17061               ready            10.244.0.122   
kube-system          hubble-ui-76d4965bb6-xmdp8                2452                ready            10.244.0.80    
local-path-storage   local-path-provisioner-74f9666bc9-scg4s   56893               ready            10.244.0.253
```

- `10.244.0.x` â†’ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œ
- `10.244.1.x` â†’ ì›Œì»¤ ë…¸ë“œ

---

## **ğŸ¶ k9s ì„¤ì¹˜ ë° ì‹¤í–‰ ì •ë¦¬**

### **1. k9s ì„¤ì¹˜**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb -O /tmp/k9s_linux_amd64.deb
apt install /tmp/k9s_linux_amd64.deb
```

âœ…Â **ì¶œë ¥**

```bash
--2025-07-30 14:55:17--  https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb
Resolving github.com (github.com)... 20.200.245.247
Connecting to github.com (github.com)|20.200.245.247|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github.com/derailed/k9s/releases/download/v0.50.9/k9s_linux_amd64.deb [following]
--2025-07-30 14:55:17--  https://github.com/derailed/k9s/releases/download/v0.50.9/k9s_linux_amd64.deb
Reusing existing connection to github.com:443.
HTTP request sent, awaiting response... 302 Found
Location: https://release-assets.githubusercontent.com/github-production-release-asset/167596393/68b2cb87-c3c4-4c08-8ebe-b8aaa51894f5?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T06%3A41%3A09Z&rscd=attachment%3B+filename%3Dk9s_linux_amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T05%3A40%3A14Z&ske=2025-07-30T06%3A41%3A09Z&sks=b&skv=2018-11-09&sig=JeO%2BpcQvqHA9Cn%2F9LNC%2FVbGkvi%2BA2WVntygiGkgYwwk%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg1NTIyMywibmJmIjoxNzUzODU0OTIzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.lj7UoO3dvLsG-a_0jHncvKP_C05qv3_v8-1Ne7RIpK0&response-content-disposition=attachment%3B%20filename%3Dk9s_linux_amd64.deb&response-content-type=application%2Foctet-stream [following]
--2025-07-30 14:55:18--  https://release-assets.githubusercontent.com/github-production-release-asset/167596393/68b2cb87-c3c4-4c08-8ebe-b8aaa51894f5?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T06%3A41%3A09Z&rscd=attachment%3B+filename%3Dk9s_linux_amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T05%3A40%3A14Z&ske=2025-07-30T06%3A41%3A09Z&sks=b&skv=2018-11-09&sig=JeO%2BpcQvqHA9Cn%2F9LNC%2FVbGkvi%2BA2WVntygiGkgYwwk%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg1NTIyMywibmJmIjoxNzUzODU0OTIzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.lj7UoO3dvLsG-a_0jHncvKP_C05qv3_v8-1Ne7RIpK0&response-content-disposition=attachment%3B%20filename%3Dk9s_linux_amd64.deb&response-content-type=application%2Foctet-stream
Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...
Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 38258230 (36M) [application/octet-stream]
Saving to: â€˜/tmp/k9s_linux_amd64.debâ€™

/tmp/k9s_linux_amd64.de 100%[==============================>]  36.49M  17.9MB/s    in 2.0s    

2025-07-30 14:55:20 (17.9 MB/s) - â€˜/tmp/k9s_linux_amd64.debâ€™ saved [38258230/38258230]

Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
Note, selecting 'k9s' instead of '/tmp/k9s_linux_amd64.deb'
The following NEW packages will be installed:
  k9s
0 upgraded, 1 newly installed, 0 to remove and 175 not upgraded.
Need to get 0 B/38.3 MB of archives.
After this operation, 124 MB of additional disk space will be used.
Get:1 /tmp/k9s_linux_amd64.deb k9s amd64 0.50.9 [38.3 MB]
Selecting previously unselected package k9s.
(Reading database ... 51864 files and directories currently installed.)
Preparing to unpack /tmp/k9s_linux_amd64.deb ...
Unpacking k9s (0.50.9) ...
Setting up k9s (0.50.9) ...
Scanning processes...                                                                          
Scanning linux images...                                                                       

Running kernel seems to be up-to-date.

No services need to be restarted.

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.
```

### **2. k9s ì‹¤í–‰**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k9s
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/407f47b3-9ddd-4d92-be0c-dc8bcb4ac496/image.png)

---

## **ğŸŒ Cilium IPAM ì‹¤ìŠµ**
- [https://docs.cilium.io/en/stable/network/concepts/ipam/](https://docs.cilium.io/en/stable/network/concepts/ipam/)

### **1. IPAM ê°œë… ë° Cilium ëª¨ë“œ**

**Kubernetes Host Scope**

- ë…¸ë“œë³„ë¡œ ê³ ì •ëœ `PodCIDR`ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë“œ
- KubeControllerManagerê°€ IP ë²”ìœ„ë¥¼ í• ë‹¹ ë° ê´€ë¦¬
- ê° ë…¸ë“œì— ë¯¸ë¦¬ ì •ì˜ëœ CIDR ë¸”ë¡ì´ í• ë‹¹ë¨

**Cilium Cluster Scope**

- Ciliumì´ ìì²´ì ìœ¼ë¡œ IP í’€ì„ ê´€ë¦¬í•˜ë©° ë™ì ìœ¼ë¡œ í• ë‹¹
- ë³„ë„ IPAM ì„¤ì •ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨ë“œ
- ì™¸ë¶€ IPAM(AWS ENI, Azure IPAM ë“±)ê³¼ì˜ ì—°ë™ë„ ê°€ëŠ¥

### **2. ë©€í‹° CIDR ë° Multi-pool ì œì•½ì‚¬í•­**

**í´ëŸ¬ìŠ¤í„° ë‚´ ë³µìˆ˜ CIDR êµ¬ì„±**

- Ciliumì€ í´ëŸ¬ìŠ¤í„° ë‚´ ì—¬ëŸ¬ CIDR ë¸”ë¡ì„ ì§€ì›
- **ì œì•½ì‚¬í•­**: `vxlan`, `geneve` ê°™ì€ í„°ë„ ê¸°ë°˜ ë¼ìš°íŒ… ëª¨ë“œì—ì„œëŠ” Multi-pool ë¯¸ì§€ì›
- **í™•ì¥ì„±**: íŠ¹ì • ë…¸ë“œì˜ Pod ìˆ˜ìš”ê°€ ì¦ê°€í•˜ì—¬ CIDRì´ ë¶€ì¡±í•œ ê²½ìš°, í•´ë‹¹ ë…¸ë“œì—ë§Œ ì¶”ê°€ CIDRì„ í• ë‹¹í•˜ì—¬ ìœ ì—°í•œ í™•ì¥ ê°€ëŠ¥

**Kubernetes Host Scope**
![](https://velog.velcdn.com/images/tlsalswls123/post/2ad63828-b21f-4063-9230-c14b3b369037/image.png)

### **3. ë…¸ë“œë³„ Pod CIDR í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'
```

âœ…Â **ì¶œë ¥**

```bash
k8s-ctr	10.244.0.0/24
k8s-w1	10.244.1.0/24
```

- Kubernetes Host Scope ê¸°ë°˜ IPAM í™˜ê²½ì—ì„œ ê° ë…¸ë“œì— `/24` CIDR ë¸”ë¡ì´ ìë™ í• ë‹¹ë¨

### **4. kube-controller-manager ì„¤ì • í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kc describe pod -n kube-system kube-controller-manager-k8s-ctr
```

âœ…Â **ì¶œë ¥**

```bash
Name:                 kube-controller-manager-k8s-ctr
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Node:                 k8s-ctr/192.168.10.100
Start Time:           Wed, 30 Jul 2025 14:41:28 +0900
Labels:               component=kube-controller-manager
                      tier=control-plane
Annotations:          kubernetes.io/config.hash: 2da908bf08a691927af74a336851f6e1
                      kubernetes.io/config.mirror: 2da908bf08a691927af74a336851f6e1
                      kubernetes.io/config.seen: 2025-07-30T14:41:20.396308103+09:00
                      kubernetes.io/config.source: file
Status:               Running
SeccompProfile:       RuntimeDefault
IP:                   192.168.10.100
IPs:
  IP:           192.168.10.100
Controlled By:  Node/k8s-ctr
Containers:
  kube-controller-manager:
    Container ID:  containerd://fb984494600e1c9a3755783595ee377a07d82efade606d941f2c162a604eed32
    Image:         registry.k8s.io/kube-controller-manager:v1.33.2
    Image ID:      registry.k8s.io/kube-controller-manager@sha256:2236e72a4be5dcc9c04600353ff8849db1557f5364947c520ff05471ae719081
    Port:          <none>
    Host Port:     <none>
    Command:
      kube-controller-manager
      --allocate-node-cidrs=true
      --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      --bind-address=127.0.0.1
      --client-ca-file=/etc/kubernetes/pki/ca.crt
      --cluster-cidr=10.244.0.0/16
      --cluster-name=kubernetes
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      --controllers=*,bootstrapsigner,tokencleaner
      --kubeconfig=/etc/kubernetes/controller-manager.conf
      --leader-elect=true
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      --root-ca-file=/etc/kubernetes/pki/ca.crt
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      --service-cluster-ip-range=10.96.0.0/16
      --use-service-account-credentials=true
    State:          Running
      Started:      Wed, 30 Jul 2025 14:41:24 +0900
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:        200m
    Liveness:     http-get https://127.0.0.1:10257/healthz delay=10s timeout=15s period=10s #success=1 #failure=8
    Startup:      http-get https://127.0.0.1:10257/healthz delay=10s timeout=15s period=10s #success=1 #failure=24
    Environment:  <none>
    Mounts:
      /etc/ca-certificates from etc-ca-certificates (ro)
      /etc/kubernetes/controller-manager.conf from kubeconfig (ro)
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/ssl/certs from ca-certs (ro)
      /usr/libexec/kubernetes/kubelet-plugins/volume/exec from flexvolume-dir (rw)
      /usr/local/share/ca-certificates from usr-local-share-ca-certificates (ro)
      /usr/share/ca-certificates from usr-share-ca-certificates (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True 
  Initialized                 True 
  Ready                       True 
  ContainersReady             True 
  PodScheduled                True 
Volumes:
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  etc-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ca-certificates
    HostPathType:  DirectoryOrCreate
  flexvolume-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/libexec/kubernetes/kubelet-plugins/volume/exec
    HostPathType:  DirectoryOrCreate
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki
    HostPathType:  DirectoryOrCreate
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/controller-manager.conf
    HostPathType:  FileOrCreate
  usr-local-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/share/ca-certificates
    HostPathType:  DirectoryOrCreate
  usr-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/share/ca-certificates
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute op=Exists
Events:            <none>
```

- `-allocate-node-cidrs=true`: ë…¸ë“œë³„ CIDR ìë™ í• ë‹¹ í™œì„±í™”
- `-cluster-cidr=10.244.0.0/16`: ì „ì²´ í´ëŸ¬ìŠ¤í„° Pod IP ë²”ìœ„ ì„¤ì •
- `-service-cluster-ip-range=10.96.0.0/16`: ì„œë¹„ìŠ¤ IP ë²”ìœ„

### **5. Ciliumì´ ì¸ì‹í•œ Pod CIDR í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode -o json | grep podCIDRs -A2
```

âœ…Â **ì¶œë ¥**

```bash
                    "podCIDRs": [
                        "10.244.0.0/24"
                    ],
--
                    "podCIDRs": [
                        "10.244.1.0/24"
                    ],
```

- ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œ: `10.244.0.0/24`
- ì›Œì»¤ ë…¸ë“œ: `10.244.1.0/24`

### **6. Cilium Endpoint IP í• ë‹¹ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumendpoints.cilium.io -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
cilium-monitoring    grafana-5c69859d9-wdb82                   22795               ready            10.244.0.104   
cilium-monitoring    prometheus-6fc896bc5d-bxnd5               1213                ready            10.244.0.65    
kube-system          coredns-674b8bbfcf-9pxvx                  28565               ready            10.244.0.199   
kube-system          coredns-674b8bbfcf-khjhq                  28565               ready            10.244.0.59    
kube-system          hubble-relay-5dcd46f5c-5r79v              17061               ready            10.244.0.122   
kube-system          hubble-ui-76d4965bb6-xmdp8                2452                ready            10.244.0.80    
local-path-storage   local-path-provisioner-74f9666bc9-scg4s   56893               ready            10.244.0.253
```

- ëª¨ë“  Podê°€ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œì˜ CIDR ë²”ìœ„(`10.244.0.0/24`) ë‚´ì—ì„œ IP í• ë‹¹ë°›ìŒ
- IP í• ë‹¹ì´ ì •ìƒì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ê³  ëª¨ë“  Endpointê°€ `ready` ìƒíƒœ

---

## **ğŸ¦ˆ ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ë° í™•ì¸ & Termshark**

### **1. ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ (webpod)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
EOF

# ê²°ê³¼
deployment.apps/webpod created
service/webpod created
```

### **2. curl í…ŒìŠ¤íŠ¸ìš© íŒŒë“œ ë°°í¬ (curl-pod)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# ê²°ê³¼
pod/curl-pod created
```

- `nodeName: k8s-ctr`: ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œì— ëª…ì‹œì ìœ¼ë¡œ ê³ ì • ë°°ì¹˜

### **3. ë¦¬ì†ŒìŠ¤ ë°°í¬ ìƒíƒœ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get deploy,svc,ep webpod -owide
```

âœ…Â **ì¶œë ¥**

```bash
Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR
deployment.apps/webpod   2/2     2            2           97s   webpod       traefik/whoami   app=webpod

NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/webpod   ClusterIP   10.96.152.212   <none>        80/TCP    97s   app=webpod

NAME               ENDPOINTS                      AGE
endpoints/webpod   10.244.0.1:80,10.244.1.96:80   96s
```

- **Deployment**: 2ê°œ Podê°€ ì •ìƒ ìƒì„± ë° ì‹¤í–‰ ì¤‘
- **Service**: ClusterIP íƒ€ì…ìœ¼ë¡œ `10.96.152.212` í• ë‹¹
- **Endpoints**
    - `10.244.0.1:80` (ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œì˜ Pod)
    - `10.244.1.96:80` (ì›Œì»¤ ë…¸ë“œì˜ Pod)

### **4. Cilium Endpoint ì •ë³´ ì¡°íšŒ**

**(1) EndpointSlice í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get endpointslices -l app=webpod
```

âœ…Â **ì¶œë ¥**

```bash
NAME           ADDRESSTYPE   PORTS   ENDPOINTS                AGE
webpod-2wrvt   IPv4          80      10.244.0.1,10.244.1.96   118s
```

**(2) Cilium Endpoint ìƒì„¸ ì •ë³´**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium-dbg endpoint list
```

âœ…Â **ì¶œë ¥**

```bash

ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                         IPv6   IPv4           STATUS   
           ENFORCEMENT        ENFORCEMENT                                                                                                                            
147        Disabled           Disabled          28565      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system                 10.244.0.199   ready   
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=coredns                                                                   
                                                           k8s:io.kubernetes.pod.namespace=kube-system                                                                       
                                                           k8s:k8s-app=kube-dns                                                                                              
318        Disabled           Disabled          5580       k8s:app=curl                                                                               10.244.0.27    ready   
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                            
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                                   
                                                           k8s:io.kubernetes.pod.namespace=default                                                                           
853        Disabled           Disabled          2452       k8s:app.kubernetes.io/name=hubble-ui                                                       10.244.0.80    ready   
                                                           k8s:app.kubernetes.io/part-of=cilium                                                                              
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system                                        
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=hubble-ui                                                                 
                                                           k8s:io.kubernetes.pod.namespace=kube-system                                                                       
                                                           k8s:k8s-app=hubble-ui                                                                                             
1009       Disabled           Disabled          12497      k8s:app=webpod                                                                             10.244.0.1     ready   
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                            
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                                   
                                                           k8s:io.kubernetes.pod.namespace=default                                                                           
1043       Disabled           Disabled          56893      k8s:app=local-path-provisioner                                                             10.244.0.253   ready   
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=local-path-storage                                 
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=local-path-provisioner-service-account                                    
                                                           k8s:io.kubernetes.pod.namespace=local-path-storage                                                                
1452       Disabled           Disabled          28565      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system                 10.244.0.59    ready   
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=coredns                                                                   
                                                           k8s:io.kubernetes.pod.namespace=kube-system                                                                       
                                                           k8s:k8s-app=kube-dns                                                                                              
1680       Disabled           Disabled          1213       k8s:app=prometheus                                                                         10.244.0.65    ready   
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=cilium-monitoring                                  
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=prometheus-k8s                                                            
                                                           k8s:io.kubernetes.pod.namespace=cilium-monitoring                                                                 
1694       Disabled           Disabled          17061      k8s:app.kubernetes.io/name=hubble-relay                                                    10.244.0.122   ready   
                                                           k8s:app.kubernetes.io/part-of=cilium                                                                              
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system                                        
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=hubble-relay                                                              
                                                           k8s:io.kubernetes.pod.namespace=kube-system                                                                       
                                                           k8s:k8s-app=hubble-relay                                                                                          
2772       Disabled           Disabled          22795      k8s:app=grafana                                                                            10.244.0.104   ready   
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=cilium-monitoring                                  
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                          
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                                   
                                                           k8s:io.kubernetes.pod.namespace=cilium-monitoring                                                                 
3358       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane                                                                 ready   
                                                           k8s:node.kubernetes.io/exclude-from-external-load-balancers                                                       
                                                           reserved:host  
```

### **5. ì„œë¹„ìŠ¤ í†µì‹  í…ŒìŠ¤íŠ¸**

**(1) ë‹¨ì¼ ìš”ì²­ í…ŒìŠ¤íŠ¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- curl webpod | grep Hostname
```

âœ…Â **ì¶œë ¥**

```bash
Hostname: webpod-697b545f57-bpzn9
```

**(2) ì—°ì† ìš”ì²­ì„ í†µí•œ ë¡œë“œ ë°¸ëŸ°ì‹± í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'
```

âœ…Â **ì¶œë ¥**

```bash
Hostname: webpod-697b545f57-xb8fd
Hostname: webpod-697b545f57-xb8fd
Hostname: webpod-697b545f57-bpzn9
Hostname: webpod-697b545f57-bpzn9
Hostname: webpod-697b545f57-bpzn9
Hostname: webpod-697b545f57-bpzn9
Hostname: webpod-697b545f57-bpzn9
Hostname: webpod-697b545f57-xb8fd
...
```

- ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ Pod(`bpzn9`, `xb8fd`) ê°„ì— íŠ¸ë˜í”½ì´ ë¶„ì‚°ë¨
- DNS ê¸°ë°˜ ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ê°€ ì •ìƒ ë™ì‘ (`webpod` ì„œë¹„ìŠ¤ëª…ìœ¼ë¡œ ì ‘ê·¼)

### **6. Hubble íë¦„ ì¶”ì  ì‹¤ìŠµ**

**(1) Hubble UI ì›¹ ì ‘ì† ì£¼ì†Œ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# NODEIP=$(ip -4 addr show eth1 | grep -oP '(?<=inet\s)\d+(\.\d+){3}')
echo -e "http://$NODEIP:30003"
```

âœ…Â **ì¶œë ¥**

```bash
http://192.168.10.100:30003
```
![](https://velog.velcdn.com/images/tlsalswls123/post/9d178b4d-e789-4c28-8528-80d77db1581b/image.png)

**(2) ì§€ì†ì ì¸ curl ìš”ì²­ ìˆ˜í–‰**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'
```

![](https://velog.velcdn.com/images/tlsalswls123/post/6adb5a74-d9f5-4db1-9da1-f7fe49906ded/image.png)
- **curlì´ default ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ìˆëŠ” webpod ì„œë¹„ìŠ¤ëª…ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ”ê±¸ í™•ì¸í•  ìˆ˜ ìˆë‹¤.**

**(3) Hubble Relay í¬íŠ¸ í¬ì›Œë”©**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium hubble port-forward&
```

âœ…Â **ì¶œë ¥**

```bash
[1] 10026
â„¹ï¸  Hubble Relay is available at 127.0.0.1:4245
```

- gRPC APIë¥¼ í†µí•´ ë¡œì»¬í˜¸ìŠ¤íŠ¸ì˜ `4245` í¬íŠ¸ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥

**(4) ì‹¤ì‹œê°„ ë„¤íŠ¸ì›Œí¬ íë¦„ ëª¨ë‹ˆí„°ë§**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --protocol tcp --pod curl-pod
```

âœ…Â **ì¶œë ¥**

```bash
Jul 30 06:30:30.990: default/curl-pod:53176 (ID:5580) <- default/webpod-697b545f57-xb8fd:80 (ID:12497) to-network FORWARDED (TCP Flags: ACK, FIN)
Jul 30 06:30:30.990: default/curl-pod:53176 (ID:5580) -> default/webpod-697b545f57-xb8fd:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK)
Jul 30 06:30:32.254: default/curl-pod (ID:5580) <> 10.96.152.212:80 (world) pre-xlate-fwd TRACED (TCP)
Jul 30 06:30:32.254: default/curl-pod (ID:5580) <> default/webpod-697b545f57-bpzn9:80 (ID:12497) post-xlate-fwd TRANSLATED (TCP)
Jul 30 06:30:32.254: default/curl-pod:58930 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: SYN)
Jul 30 06:30:32.254: default/curl-pod:58930 (ID:5580) <- default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: SYN, ACK)
Jul 30 06:30:32.254: default/curl-pod:58930 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK)
Jul 30 06:30:32.254: default/curl-pod:58930 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:32.254: default/curl-pod:58930 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:32.254: default/curl-pod:58930 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:32.255: default/curl-pod:58930 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
Jul 30 06:30:32.255: default/curl-pod:58930 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:32.256: default/curl-pod:58930 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:32.256: default/curl-pod:58930 (ID:5580) <- default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
Jul 30 06:30:32.257: default/curl-pod:58930 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
Jul 30 06:30:32.257: default/curl-pod:58930 (ID:5580) <- default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
Jul 30 06:30:32.257: default/curl-pod:58930 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK)
Jul 30 06:30:33.263: default/curl-pod (ID:5580) <> 10.96.152.212:80 (world) pre-xlate-fwd TRACED (TCP)
Jul 30 06:30:33.263: default/curl-pod (ID:5580) <> default/webpod-697b545f57-bpzn9:80 (ID:12497) post-xlate-fwd TRANSLATED (TCP)
Jul 30 06:30:33.263: default/curl-pod:58942 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: SYN)
Jul 30 06:30:33.263: default/curl-pod:58942 (ID:5580) <- default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: SYN, ACK)
Jul 30 06:30:33.263: default/curl-pod:58942 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK)
Jul 30 06:30:33.264: default/curl-pod:58942 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:33.264: default/curl-pod:58942 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
Jul 30 06:30:33.264: default/curl-pod:58942 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:33.264: default/curl-pod:58942 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:33.265: default/curl-pod:58942 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:33.265: default/curl-pod:58942 (ID:5580) <> default/webpod-697b545f57-bpzn9 (ID:12497) pre-xlate-rev TRACED (TCP)
Jul 30 06:30:33.265: default/curl-pod:58942 (ID:5580) <- default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
Jul 30 06:30:33.265: default/curl-pod:58942 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
Jul 30 06:30:33.265: default/curl-pod:58942 (ID:5580) <- default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
Jul 30 06:30:33.265: default/curl-pod:58942 (ID:5580) -> default/webpod-697b545f57-bpzn9:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK)
Jul 30 06:30:34.018: default/curl-pod:53190 (ID:5580) -> default/webpod-697b545f57-xb8fd:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: SYN)
Jul 30 06:30:34.018: default/curl-pod:53190 (ID:5580) <- default/webpod-697b545f57-xb8fd:80 (ID:12497) to-network FORWARDED (TCP Flags: SYN, ACK)
Jul 30 06:30:34.018: default/curl-pod:53190 (ID:5580) -> default/webpod-697b545f57-xb8fd:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK)
Jul 30 06:30:34.018: default/curl-pod:53190 (ID:5580) -> default/webpod-697b545f57-xb8fd:80 (ID:12497) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
```

- `10.96.152.212:80`: ClusterIP ì„œë¹„ìŠ¤ ì£¼ì†Œ (world ë¼ë²¨)
- `pre-xlate-fwd`: NAT ë³€í™˜ ì „ ì¶”ì  - ì†Œì¼“ ë¡œë“œë°¸ëŸ°ì„œì— ì˜í•œ ì„œë¹„ìŠ¤ IP ì ‘ê·¼
- `post-xlate-fwd`: NAT ë³€í™˜ í›„ - ì‹¤ì œ Pod IPë¡œ ë³€í™˜ë¨

**TCP ì—°ê²° ìƒëª…ì£¼ê¸°**

```bash
TCP Flags: SYN        # ì—°ê²° ì‹œì‘
TCP Flags: SYN, ACK   # ì—°ê²° ìˆ˜ë½
TCP Flags: ACK        # ì—°ê²° í™•ì¸
TCP Flags: ACK, PSH   # HTTP ë°ì´í„° ì „ì†¡
TCP Flags: ACK, FIN   # ì—°ê²° ì¢…ë£Œ
```

### **7. ì„œë¹„ìŠ¤ ì •ë³´ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k get svc
```

âœ…Â **ì¶œë ¥**

```bash
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP   57m
webpod       ClusterIP   10.96.152.212   <none>        80/TCP    19m
```

- `webpod` ì„œë¹„ìŠ¤ì˜ ClusterIP `10.96.152.212`ê°€ Hubble ë¡œê·¸ì˜ ì„œë¹„ìŠ¤ ì£¼ì†Œì™€ ì¼ì¹˜
- Ciliumì˜ ì†Œì¼“ ë ˆë²¨ ë¡œë“œë°¸ëŸ°ì„œê°€ ì„œë¹„ìŠ¤ IPë¥¼ ì‹¤ì œ Pod IPë¡œ ìë™ ë³€í™˜

### **8. ë„¤íŠ¸ì›Œí¬ íŒ¨í‚· ìº¡ì²˜ ë¶„ì„**

**(1) tcpdumpë¥¼ í†µí•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 tcp port 80 -nn
```

âœ…Â **ì¶œë ¥**

```bash
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes
15:43:14.755578 IP 10.244.0.27.41700 > 10.244.1.96.80: Flags [S], seq 501953752, win 64240, options [mss 1460,sackOK,TS val 1594519 ecr 0,nop,wscale 7], length 0
15:43:14.756290 IP 10.244.1.96.80 > 10.244.0.27.41700: Flags [S.], seq 2849751208, ack 501953753, win 65160, options [mss 1460,sackOK,TS val 3721394349 ecr 1594519,nop,wscale 7], length 0
15:43:14.756381 IP 10.244.0.27.41700 > 10.244.1.96.80: Flags [.], ack 1, win 502, options [nop,nop,TS val 1594520 ecr 3721394349], length 0
15:43:14.756622 IP 10.244.0.27.41700 > 10.244.1.96.80: Flags [P.], seq 1:71, ack 1, win 502, options [nop,nop,TS val 1594521 ecr 3721394349], length 70: HTTP: GET / HTTP/1.1
15:43:14.757363 IP 10.244.1.96.80 > 10.244.0.27.41700: Flags [.], ack 71, win 509, options [nop,nop,TS val 3721394350 ecr 1594521], length 0
15:43:14.757855 IP 10.244.1.96.80 > 10.244.0.27.41700: Flags [P.], seq 1:321, ack 71, win 509, options [nop,nop,TS val 3721394351 ecr 1594521], length 320: HTTP: HTTP/1.1 200 OK
15:43:14.757884 IP 10.244.0.27.41700 > 10.244.1.96.80: Flags [.], ack 321, win 501, options [nop,nop,TS val 1594522 ecr 3721394351], length 0
15:43:14.758124 IP 10.244.0.27.41700 > 10.244.1.96.80: Flags [F.], seq 71, ack 321, win 501, options [nop,nop,TS val 1594522 ecr 3721394351], length 0
15:43:14.758448 IP 10.244.1.96.80 > 10.244.0.27.41700: Flags [F.], seq 321, ack 72, win 509, options [nop,nop,TS val 3721394352 ecr 1594522], length 0
15:43:14.758485 IP 10.244.0.27.41700 > 10.244.1.96.80: Flags [.], ack 322, win 501, options [nop,nop,TS val 1594522 ecr 3721394352], length 0
15:43:16.770376 IP 10.244.0.27.41702 > 10.244.1.96.80: Flags [S], seq 2173259033, win 64240, options [mss 1460,sackOK,TS val 1596534 ecr 0,nop,wscale 7], length 0
15:43:16.771075 IP 10.244.1.96.80 > 10.244.0.27.41702: Flags [S.], seq 1449700480, ack 2173259034, win 65160, options [mss 1460,sackOK,TS val 3721396364 ecr 1596534,nop,wscale 7], length 0
15:43:16.771133 IP 10.244.0.27.41702 > 10.244.1.96.80: Flags [.], ack 1, win 502, options [nop,nop,TS val 1596535 ecr 3721396364], length 0
15:43:16.771167 IP 10.244.0.27.41702 > 10.244.1.96.80: Flags [P.], seq 1:71, ack 1, win 502, options [nop,nop,TS val 1596535 ecr 3721396364], length 70: HTTP: GET / HTTP/1.1
15:43:16.771658 IP 10.244.1.96.80 > 10.244.0.27.41702: Flags [.], ack 71, win 509, options [nop,nop,TS val 3721396365 ecr 1596535], length 0
15:43:16.772436 IP 10.244.1.96.80 > 10.244.0.27.41702: Flags [P.], seq 1:321, ack 71, win 509, options [nop,nop,TS val 3721396366 ecr 1596535], length 320: HTTP: HTTP/1.1 200 OK
15:43:16.772479 IP 10.244.0.27.41702 > 10.244.1.96.80: Flags [.], ack 321, win 501, options [nop,nop,TS val 1596536 ecr 3721396366], length 0
15:43:16.772648 IP 10.244.0.27.41702 > 10.244.1.96.80: Flags [F.], seq 71, ack 321, win 501, options [nop,nop,TS val 1596537 ecr 3721396366], length 0
15:43:16.773058 IP 10.244.1.96.80 > 10.244.0.27.41702: Flags [F.], seq 321, ack 72, win 509, options [nop,nop,TS val 3721396366 ecr 1596537], length 0
15:43:16.773093 IP 10.244.0.27.41702 > 10.244.1.96.80: Flags [.], ack 322, win 501, options [nop,nop,TS val 1596537 ecr 3721396366], length 0
15:43:17.778477 IP 10.244.0.27.52802 > 10.244.1.96.80: Flags [S], seq 1698202645, win 64240, options [mss 1460,sackOK,TS val 1597542 ecr 0,nop,wscale 7], length 0
15:43:17.779167 IP 10.244.1.96.80 > 10.244.0.27.52802: Flags [S.], seq 4294649790, ack 1698202646, win 65160, options [mss 1460,sackOK,TS val 3721397372 ecr 1597542,nop,wscale 7], length 0
...
```

- `10.244.0.27`: curl-podì˜ ì‹¤ì œ IP ì£¼ì†Œ
- `10.244.1.96`: webpodì˜ ì‹¤ì œ IP ì£¼ì†Œ (ì›Œì»¤ ë…¸ë“œ)
- ì„œë¹„ìŠ¤ IP(`10.96.152.212`)ëŠ” íŒ¨í‚· ë ˆë²¨ì—ì„œëŠ” ë³´ì´ì§€ ì•ŠìŒ
- eBPFê°€ ì»¤ë„ ë ˆë²¨ì—ì„œ íˆ¬ëª…í•˜ê²Œ NAT ë³€í™˜ì„ ìˆ˜í–‰

**(2) íŒ¨í‚· ìº¡ì²˜ íŒŒì¼ ìƒì„±**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 tcp port 80 -w /tmp/http.pcap
```

âœ…Â **ì¶œë ¥**

```bash
tcpdump: listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes
^C30 packets captured
30 packets received by filter
0 packets dropped by kernel
```

**(3) Termsharkë¡œ ë¶„ì„**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# termshark -r /tmp/http.pcap
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/bf8ecbbd-2ac1-4516-a465-8c7fc8879b0f/image.png)

---

## **ğŸ [Cilium] Cluster Scope & ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤ìŠµ**
- [https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/](https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/)
- [https://docs.cilium.io/en/stable/network/kubernetes/ipam-cluster-pool/](https://docs.cilium.io/en/stable/network/kubernetes/ipam-cluster-pool/)

### **1. ê°œìš”**
- **ëª©í‘œ: Kubernetes Host Scopeì—ì„œ Cilium Cluster Scope IPAM ëª¨ë“œë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜**
- **IP ëŒ€ì—­ ë³€ê²½**: 10.244.0.0/16 â†’ 172.20.0.0/16
- **ê´€ë¦¬ ì£¼ì²´ ë³€ê²½**: kube-controller-manager â†’ Cilium Operator
![](https://velog.velcdn.com/images/tlsalswls123/post/219d77ac-3250-4198-abdb-0de314e68b64/image.png)

**í†µì‹  í™•ì¸ ëª©ì , ë°˜ë³µ ìš”ì²­**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'
```

### **2. IPAM ëª¨ë“œ ë³€ê²½**

**(1) ìµœì´ˆ ë³€ê²½ ì‹œë„ (ì‹¤íŒ¨)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
--set ipam.mode="cluster-pool" --set ipam.operator.clusterPoolIPv4PodCIDRList={"172.20.0.0/16"} --set ipv4NativeRoutingCIDR=172.20.0.0/16
```

âœ…Â **ì¶œë ¥**

```bash
Error: UPGRADE FAILED: template: cilium/templates/cilium-operator/deployment.yaml:145:26: executing "cilium/templates/cilium-operator/deployment.yaml" at <.Values.k8sServiceHostRef.name>: nil pointer evaluating interface {}.name
```

**(2) ë¬¸ì œ í•´ê²°: Values ì •ì œ ğŸ’¡**

**ê¸°ì¡´ ê°’ì„ `clean-values.yaml`ë¡œ ë°±ì—…**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# helm get values cilium -n kube-system > clean-values.yaml
```

**ì˜¤ë¥˜ ìœ ë°œ í•­ëª© ì œê±° í›„ `final-values.yaml` ì‘ì„±í•˜ì—¬ ì„¤ì • ì •ì œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat > final-values.yaml << EOF
autoDirectNodeRoutes: true
bpf:
  masquerade: true
debug:
  enabled: true
endpointHealthChecking:
  enabled: false
endpointRoutes:
  enabled: true
healthChecking: false
hubble:
  enabled: true
  metrics:
    enableOpenMetrics: true
    enabled:
    - dns
    - drop
    - tcp
    - flow
    - port-distribution
    - icmp
    - httpV2:exemplars=true;labelsContext=source_ip,source_namespace,source_workload,destination_ip,destination_namespace,destination_workload,traffic_direction
  relay:
    enabled: true
  ui:
    enabled: true
    service:
      nodePort: 30003
      type: NodePort
installNoConntrackIptablesRules: true
ipam:
  mode: cluster-pool
  operator:
    clusterPoolIPv4PodCIDRList:
      - "172.20.0.0/16"
ipv4NativeRoutingCIDR: 172.20.0.0/16
k8s:
  requireIPv4PodCIDR: true
k8sServiceHost: 192.168.10.100
k8sServicePort: 6443
kubeProxyReplacement: true
operator:
  prometheus:
    enabled: true
  replicas: 1
prometheus:
  enabled: true
routingMode: native
EOF
```

**(3) ì„¤ì • ì ìš©: IPAM cluster-poolë¡œ ë³€ê²½ ì„±ê³µ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# helm upgrade cilium cilium/cilium --namespace kube-system -f final-values.yaml
```

âœ…Â **ì¶œë ¥**

```bash
Release "cilium" has been upgraded. Happy Helming!
NAME: cilium
LAST DEPLOYED: Wed Jul 30 16:26:05 2025
NAMESPACE: kube-system
STATUS: deployed
REVISION: 2
TEST SUITE: None
NOTES:
You have successfully installed Cilium with Hubble Relay and Hubble UI.

Your release version is 1.18.0.

For any further help, visit https://docs.cilium.io/en/v1.18/gettinghelp
```

### **3. Cilium êµ¬ì„± ìš”ì†Œ ì¬ì‹œì‘**

**(1) Cilium Operator ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system rollout restart deploy/cilium-operator

# ê²°ê³¼
deployment.apps/cilium-operator restarted
```

**(2) Cilium DaemonSet ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system rollout restart ds/cilium

# ê²°ê³¼
daemonset.apps/cilium restarted
```

### **4. k9s ì¶œë ¥ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k9s
```

**âœ…Â ì¶œë ¥ - default ë„¤ì„ìŠ¤í˜ì´ìŠ¤**
![](https://velog.velcdn.com/images/tlsalswls123/post/cbdb6f18-8396-4199-9b96-56e189e05c80/image.png)

**âœ…Â ì¶œë ¥ - all**
![](https://velog.velcdn.com/images/tlsalswls123/post/6c0f045c-a932-42b5-9233-8a2cd6c512a6/image.png)

### **5. IPAM ëª¨ë“œ ë³€ê²½ í™•ì¸**

**IPAM ëª¨ë“œê°€ `cluster-pool`ë¡œ ì •ìƒ ë³€ê²½ë˜ì—ˆìŒ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium config view | grep ^ipam
```

âœ…Â **ì¶œë ¥**

```bash
ipam                                              cluster-pool
ipam-cilium-node-update-rate                      15s
```

### **6. Pod CIDR ë¯¸ë°˜ì˜ í™•ì¸**

**(1) CiliumNodeì˜ ê¸°ì¡´ CIDR ìœ ì§€ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode -o json | grep podCIDRs -A2
```

âœ…Â **ì¶œë ¥**

```bash
                    "podCIDRs": [
                        "10.244.0.0/24"
                    ],
--
                    "podCIDRs": [
                        "10.244.1.0/24"
                    ],
```

**(2) CiliumEndpointì˜ Pod IP í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumendpoints.cilium.io -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
cilium-monitoring    grafana-5c69859d9-wdb82                   22795               ready            10.244.0.104   
cilium-monitoring    prometheus-6fc896bc5d-bxnd5               1213                ready            10.244.0.65    
default              curl-pod                                  5580                ready            10.244.0.27    
default              webpod-697b545f57-bpzn9                   12497               ready            10.244.0.1     
default              webpod-697b545f57-xb8fd                   12497               ready            10.244.1.96    
kube-system          coredns-674b8bbfcf-9pxvx                  28565               ready            10.244.0.199   
kube-system          coredns-674b8bbfcf-khjhq                  28565               ready            10.244.0.59    
kube-system          hubble-relay-5b48c999f9-cvjjc             17061               ready            10.244.1.67    
kube-system          hubble-ui-655f947f96-tcrrp                2452                ready            10.244.1.66    
local-path-storage   local-path-provisioner-74f9666bc9-scg4s   56893               ready            10.244.0.253
```

**ê·¸ëŸ¬ë‚˜, í†µì‹ ì€ ì˜ë˜ê³  ìˆìŒ**
![](https://velog.velcdn.com/images/tlsalswls123/post/3b56c438-55bb-46c0-a1cb-6c6e53528f93/image.png)

### **7. IPAM ë³€ê²½ ë¯¸ë°˜ì˜ ì›ì¸ íŒŒì•…**

**(1) CiliumNode ë‚´ `podCIDRs` ê°’ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode -o json | grep podCIDRs -A2
```

âœ…Â **ì¶œë ¥**

```bash
                    "podCIDRs": [
                        "10.244.0.0/24"
                    ],
--
                    "podCIDRs": [
                        "10.244.1.0/24"
                    ],
```

**(2) ê¸°ì¡´ CiliumNodeì˜ IP ìœ ì§€ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode
```

âœ…Â **ì¶œë ¥**

```bash
NAME      CILIUMINTERNALIP   INTERNALIP       AGE
k8s-ctr   10.244.0.70        192.168.10.100   130m
k8s-w1    10.244.1.175       192.168.10.101   128m
```

### **8. CiliumNode ë¦¬ì†ŒìŠ¤ ì‚­ì œ ë° ì¬ì‹œì‘**

**(1) ì›Œì»¤ ë…¸ë“œì˜ CiliumNode ì‚­ì œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl delete ciliumnode k8s-w1

# ê²°ê³¼
ciliumnode.cilium.io "k8s-w1" deleted
```

**(2) Cilium DaemonSet ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system rollout restart ds/cilium

# ê²°ê³¼
daemonset.apps/cilium restarted
```

**(3) ë³€ê²½ëœ Pod CIDRs í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode -o json | grep podCIDRs -A2
```

âœ…Â **ì¶œë ¥**

```bash
                    "podCIDRs": [
                        "10.244.0.0/24"
                    ],
--
                    "podCIDRs": [
                        "172.20.0.0/24"
                    ],
```

### **9. ì»¨íŠ¸ë¡¤í”Œë ˆì¸ ë…¸ë“œë„ CIDR ì¬ì„¤ì •**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumendpoints.cilium.io -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
cilium-monitoring    grafana-5c69859d9-wdb82                   22795               ready            10.244.0.104   
cilium-monitoring    prometheus-6fc896bc5d-bxnd5               1213                ready            10.244.0.65    
default              curl-pod                                  5580                ready            10.244.0.27    
default              webpod-697b545f57-bpzn9                   12497               ready            10.244.0.1     
kube-system          coredns-674b8bbfcf-9pxvx                  28565               ready            10.244.0.199   
kube-system          coredns-674b8bbfcf-khjhq                  28565               ready            10.244.0.59    
local-path-storage   local-path-provisioner-74f9666bc9-scg4s   56893               ready            10.244.0.253
```

**(1) ì»¨íŠ¸ë¡¤í”Œë ˆì¸ ë…¸ë“œ ì‚­ì œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl delete ciliumnode k8s-ctr

# ê²°ê³¼
ciliumnode.cilium.io "k8s-ctr" deleted
```

**(2) DaemonSet ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system rollout restart ds/cilium

# ê²°ê³¼
daemonset.apps/cilium restarted
```

**(3) ë³€ê²½ëœ Pod CIDRs í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumnode -o json | grep podCIDRs -A2
```

âœ…Â **ì¶œë ¥**

```bash
                    "podCIDRs": [
                        "172.20.1.0/24"
                    ],
--
                    "podCIDRs": [
                        "172.20.0.0/24"
                    ],
```

### **10. ì—”ë“œí¬ì¸íŠ¸ ë° ë¼ìš°íŒ… ê²½ë¡œ í™•ì¸**

**(1) ë³€ê²½ëœ Endpoint IP í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumendpoints.cilium.io -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE     NAME                       SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
kube-system   coredns-674b8bbfcf-gbnm8   28565               ready            172.20.0.186   
kube-system   coredns-674b8bbfcf-vvgfm   28565               ready            172.20.1.144  
```

**(2) ë¼ìš°íŒ… ê²½ë¡œ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# ip -c route
```

âœ…Â **ì¶œë ¥**

```bash
default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 
10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.10.0.0/16 via 192.168.10.200 dev eth1 proto static 
172.20.0.0/24 via 192.168.10.101 dev eth1 proto kernel 
172.20.1.144 dev lxcf2a822e72a6e proto kernel scope link 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100 
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# sshpass -p 'vagrant' ssh vagrant@k8s-w1 ip -c route
```

âœ…Â **ì¶œë ¥**

```bash
default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 
10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.10.0.0/16 via 192.168.10.200 dev eth1 proto static 
172.20.0.186 dev lxc80130454cb70 proto kernel scope link 
172.20.1.0/24 via 192.168.10.100 dev eth1 proto kernel 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101 
```

### **11. ê¸°ì¡´ Podì˜ IP ìœ ì§€ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -A -owide | grep 10.244.
```

âœ…Â **ì¶œë ¥**

```bash
cilium-monitoring    grafana-5c69859d9-wdb82                   0/1     Running            0              143m    10.244.0.104     k8s-ctr   <none>           <none>
cilium-monitoring    prometheus-6fc896bc5d-bxnd5               1/1     Running            0              143m    10.244.0.65      k8s-ctr   <none>           <none>
default              curl-pod                                  1/1     Running            0              105m    10.244.0.27      k8s-ctr   <none>           <none>
default              webpod-697b545f57-bpzn9                   1/1     Running            0              106m    10.244.0.1       k8s-ctr   <none>           <none>
default              webpod-697b545f57-xb8fd                   1/1     Running            0              106m    10.244.1.96      k8s-w1    <none>           <none>
kube-system          hubble-relay-5b48c999f9-cvjjc             0/1     Running            5 (28s ago)    39m     10.244.1.67      k8s-w1    <none>           <none>
kube-system          hubble-ui-655f947f96-tcrrp                1/2     CrashLoopBackOff   6 (106s ago)   39m     10.244.1.66      k8s-w1    <none>           <none>
local-path-storage   local-path-provisioner-74f9666bc9-scg4s   1/1     Running            0              143m    10.244.0.253     k8s-ctr   <none>           <none>
```

### **12. Deployment ë¦¬ì†ŒìŠ¤ ì¬ì‹œì‘**

**ì‹œìŠ¤í…œ ë° ëª¨ë‹ˆí„°ë§ íŒŒë“œ ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system rollout restart deploy/hubble-relay deploy/hubble-ui
kubectl -n cilium-monitoring rollout restart deploy/prometheus deploy/grafana
kubectl rollout restart deploy/webpod
```

âœ…Â **ì¶œë ¥**

```bash
deployment.apps/hubble-relay restarted
deployment.apps/hubble-ui restarted
deployment.apps/prometheus restarted
deployment.apps/grafana restarted
deployment.apps/webpod restarted
```

### **13. ìˆ˜ë™ ìƒì„± íŒŒë“œ ì‚­ì œ ë° ì¬ë°°í¬**

**(1) curl-pod ì‚­ì œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl delete pod curl-pod

# ì¶œë ¥
pod "curl-pod" deleted
```

**(2) curl-pod ì¬ë°°í¬**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# ê²°ê³¼
pod/curl-pod created
```

### **14. ìƒˆ IP í• ë‹¹ ìƒíƒœ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get ciliumendpoints.cilium.io -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE           NAME                           SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
cilium-monitoring   grafana-6bc98cff96-h74hv        22795               ready            172.20.0.67    
cilium-monitoring   prometheus-597ff4d4c5-hzrsx     1213                ready            172.20.0.17    
default             curl-pod                       5580                ready            172.20.1.236   
default             webpod-556878d5d7-7p8bn        12497               ready            172.20.1.40    
default             webpod-556878d5d7-r4dmh        12497               ready            172.20.0.130   
kube-system         coredns-674b8bbfcf-gbnm8       28565               ready            172.20.0.186   
kube-system         coredns-674b8bbfcf-vvgfm       28565               ready            172.20.1.144   
kube-system         hubble-relay-c8db994db-5hc26   17061               ready            172.20.0.190   
kube-system         hubble-ui-5c5855f4bf-8dkrf     2452                ready            172.20.0.162 
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k get pod -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE            NAME                                      READY   STATUS    RESTARTS   AGE
cilium-monitoring    grafana-6bc98cff96-h74hv                   1/1     Running   0          3m31s
cilium-monitoring    prometheus-597ff4d4c5-hzrsx                1/1     Running   0          3m31s
default              curl-pod                                  1/1     Running   0          110s
default              webpod-556878d5d7-7p8bn                   1/1     Running   0          3m4s
default              webpod-556878d5d7-r4dmh                   1/1     Running   0          3m30s
kube-system          cilium-8nxg4                              1/1     Running   0          8m42s
kube-system          cilium-envoy-mn4qm                        1/1     Running   0          44m
kube-system          cilium-envoy-zgsk4                        1/1     Running   0          44m
kube-system          cilium-kl2mj                              1/1     Running   0          8m42s
kube-system          cilium-operator-765ddcc649-ft64f          1/1     Running   0          38m
kube-system          coredns-674b8bbfcf-gbnm8                  1/1     Running   0          8m19s
kube-system          coredns-674b8bbfcf-vvgfm                  1/1     Running   0          8m4s
kube-system          etcd-k8s-ctr                              1/1     Running   0          149m
kube-system          hubble-relay-c8db994db-5hc26              1/1     Running   0          3m31s
kube-system          hubble-ui-5c5855f4bf-8dkrf                2/2     Running   0          3m31s
kube-system          kube-apiserver-k8s-ctr                    1/1     Running   0          149m
kube-system          kube-controller-manager-k8s-ctr           1/1     Running   0          149m
kube-system          kube-proxy-5ccc4                          1/1     Running   0          147m
kube-system          kube-proxy-mzn7t                          1/1     Running   0          149m
kube-system          kube-scheduler-k8s-ctr                    1/1     Running   0          149m
local-path-storage   local-path-provisioner-74f9666bc9-scg4s   1/1     Running   0          148m
```

### **15. curl-podì—ì„œ í†µì‹  í…ŒìŠ¤íŠ¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'
```

âœ…Â **ì¶œë ¥**

```bash
Hostname: webpod-556878d5d7-7p8bn
Hostname: webpod-556878d5d7-r4dmh
Hostname: webpod-556878d5d7-7p8bn
Hostname: webpod-556878d5d7-7p8bn
Hostname: webpod-556878d5d7-7p8bn
Hostname: webpod-556878d5d7-r4dmh
Hostname: webpod-556878d5d7-7p8bn
Hostname: webpod-556878d5d7-r4dmh
Hostname: webpod-556878d5d7-7p8bn
Hostname: webpod-556878d5d7-7p8bn
...
```

### **16. Hubble í¬íŠ¸í¬ì›Œë”© ì¶©ëŒ í•´ê²°**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium hubble port-forward&
```

âœ…Â **ì¶œë ¥**

```bash
[2] 34662
(âˆ|HomeLab:N/A) root@k8s-ctr:~# 
Error: Unable to port forward: failed to port forward: failed to port forward: unable to listen on any of the requested ports: [{4245 4245}]
```

**ê¸°ì¡´ í¬íŠ¸ ì¶©ëŒ í™•ì¸ ë° ì¢…ë£Œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# ss -tnlp | grep 4245
```

âœ…Â **ì¶œë ¥**

```bash
LISTEN 0      4096        127.0.0.1:4245       0.0.0.0:*    users:(("cilium",pid=10026,fd=7))                      
LISTEN 0      4096            [::1]:4245          [::]:*    users:(("cilium",pid=10026,fd=8))
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kill -9 10026

# ê²°ê³¼
[1]+  Killed                  cilium hubble port-forward
```

### **17. Hubble í¬íŠ¸í¬ì›Œë”© ì •ìƒ ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium hubble port-forward&
```

âœ…Â **ì¶œë ¥**

```bash
[1] 34787
(âˆ|HomeLab:N/A) root@k8s-ctr:~# â„¹ï¸  Hubble Relay is available at 127.0.0.1:4245
```

**Hubble ìƒíƒœ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# hubble status
```

âœ…Â **ì¶œë ¥**

```bash
Healthcheck (via localhost:4245): Ok
Current/Max Flows: 8,190/8,190 (100.00%)
Flows/s: 38.00
Connected Nodes: 2/2
```

**ğŸ”§ IPAM ëª¨ë“œ ë³€ê²½ì€ ì‹ ì¤‘í•˜ê²Œ**

> IPAM ëª¨ë“œë¥¼ ë³€ê²½í•˜ëŠ” ì‘ì—…ì€ ë‹¨ìˆœíˆ Pod CIDR ëŒ€ì—­ì„ ë°”ê¾¸ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ë” í° ë¦¬ìŠ¤í¬ë¥¼ ë™ë°˜í•¨. 
> ì´ˆê¸° í´ëŸ¬ìŠ¤í„° ì„¤ê³„ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  IPAM ëª¨ë“œë¥¼ ì‹ ì¤‘í•˜ê²Œ ê²°ì •í•´ì•¼ í•˜ë©°,
> í–¥í›„ í´ëŸ¬ìŠ¤í„° í™•ì¥(ìŠ¤ì¼€ì¼ì—…) ê³„íšì´ë‚˜ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê¹Œì§€ ê³ ë ¤í•´ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•¨.


---

## **ğŸ§­ Routing**
![](https://velog.velcdn.com/images/tlsalswls123/post/b11c719a-6176-43a7-9174-2a1e1194a9e9/image.png)

### **1. íŒŒë“œ ìƒíƒœ ë° IP í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES
curl-pod                  1/1     Running   0          57m   172.20.1.236   k8s-ctr   <none>           <none>
webpod-556878d5d7-7p8bn   1/1     Running   0          58m   172.20.1.40    k8s-ctr   <none>           <none>
webpod-556878d5d7-r4dmh   1/1     Running   0          59m   172.20.0.130   k8s-w1    <none>           <none>
```

**webpod 1,2 íŒŒë“œ IP**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# export WEBPODIP1=$(kubectl get -l app=webpod pods --field-selector spec.nodeName=k8s-ctr -o jsonpath='{.items[0].status.podIP}')
export WEBPODIP2=$(kubectl get -l app=webpod pods --field-selector spec.nodeName=k8s-w1  -o jsonpath='{.items[0].status.podIP}')
echo $WEBPODIP1 $WEBPODIP2
```

âœ…Â **ì¶œë ¥**

```bash
172.20.1.40 172.20.0.130
```

### **2. íŒŒë“œ ê°„ í†µì‹  í™•ì¸ (ping)**

`curl-pod` â†’ `webpod-2` ë¡œ ping ì‹œë„

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- ping $WEBPODIP2
```

âœ…Â **ì¶œë ¥**

```bash
PING 172.20.0.130 (172.20.0.130) 56(84) bytes of data.
64 bytes from 172.20.0.130: icmp_seq=1 ttl=62 time=0.433 ms
64 bytes from 172.20.0.130: icmp_seq=2 ttl=62 time=0.657 ms
64 bytes from 172.20.0.130: icmp_seq=3 ttl=62 time=0.554 ms
64 bytes from 172.20.0.130: icmp_seq=4 ttl=62 time=0.374 ms
64 bytes from 172.20.0.130: icmp_seq=5 ttl=62 time=0.990 ms
64 bytes from 172.20.0.130: icmp_seq=6 ttl=62 time=0.486 ms
64 bytes from 172.20.0.130: icmp_seq=7 ttl=62 time=0.446 ms
64 bytes from 172.20.0.130: icmp_seq=8 ttl=62 time=0.533 ms
...
```

- ICMP ì‘ë‹µ ìˆ˜ì‹  ì •ìƒ
- íŒŒë“œ ê°„ í†µì‹ ì— ë¬¸ì œ ì—†ìŒ (Native Routing ì •ìƒ ì‘ë™)

### **3. ë¼ìš°íŒ… í…Œì´ë¸” í™•ì¸ (k8s-ctr ë…¸ë“œ)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# ip -c route
```

âœ…Â **ì¶œë ¥**

```bash
default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 
10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.10.0.0/16 via 192.168.10.200 dev eth1 proto static 
172.20.0.0/24 via 192.168.10.101 dev eth1 proto kernel 
172.20.1.40 dev lxc0895f39b5225 proto kernel scope link 
172.20.1.144 dev lxcf2a822e72a6e proto kernel scope link 
172.20.1.236 dev lxcd63c3c1415ff proto kernel scope link 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100 
```

- `172.20.0.0/24 via 192.168.10.101 dev eth1 proto kernel`
    - webpod-2ê°€ ì†í•œ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ìœ¼ë¡œ ê°€ê¸° ìœ„í•´ ì›Œì»¤ë…¸ë“œ1ì˜ IP ì‚¬ìš©

### **4. ë¼ìš°íŒ… í…Œì´ë¸” í™•ì¸ (k8s-w1 ë…¸ë“œ)**

**webpod-2 (`172.20.0.130`)ëŠ” veth ì¸í„°í˜ì´ìŠ¤ì— ì§ì ‘ ì—°ê²°**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# sshpass -p 'vagrant' ssh vagrant@k8s-w1 ip -c route
```

âœ…Â **ì¶œë ¥**

```bash
default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 
10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.10.0.0/16 via 192.168.10.200 dev eth1 proto static 
172.20.0.17 dev lxce960d096d8a4 proto kernel scope link 
172.20.0.67 dev lxcd23f85153e89 proto kernel scope link 
172.20.0.130 dev lxc097ff224d206 proto kernel scope link 
172.20.0.162 dev lxc4fe9abccf909 proto kernel scope link 
172.20.0.186 dev lxc80130454cb70 proto kernel scope link 
172.20.0.190 dev lxcb2f1076877d3 proto kernel scope link 
172.20.1.0/24 via 192.168.10.100 dev eth1 proto kernel 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101
```

- `172.20.1.0/24 via 192.168.10.100 dev eth1 proto kernel`
    - curl-podê°€ ìˆëŠ” k8s-ctrë¡œì˜ ê²½ë¡œê°€ ì„¤ì •ë˜ì–´ ìˆìŒ

### **5. Hubble CLIë¡œ íŠ¸ë˜í”½ íë¦„ í™•ì¸**

```bash
hubble observe -f --pod curl-pod
```

âœ…Â **ì¶œë ¥**

```bash
Jul 30 09:15:15.857: default/curl-pod (ID:5580) -> default/webpod-556878d5d7-r4dmh (ID:12497) to-network FORWARDED (ICMPv4 EchoRequest)
Jul 30 09:15:15.858: default/curl-pod (ID:5580) <- default/webpod-556878d5d7-r4dmh (ID:12497) to-endpoint FORWARDED (ICMPv4 EchoReply)
Jul 30 09:15:16.848: default/curl-pod (ID:5580) -> default/webpod-556878d5d7-r4dmh (ID:12497) to-endpoint FORWARDED (ICMPv4 EchoRequest)
Jul 30 09:15:16.848: default/curl-pod (ID:5580) <- default/webpod-556878d5d7-r4dmh (ID:12497) to-network FORWARDED (ICMPv4 EchoReply)
...
```

![](https://velog.velcdn.com/images/tlsalswls123/post/4572c8b3-d1ed-4597-98bc-4161246048a7/image.png)
- ICMP EchoRequest / EchoReply íŠ¸ë˜í”½ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥
- Source: `curl-pod`, Destination: `webpod-2`

### **6. tcpdumpë¡œ ë„¤íŠ¸ì›Œí¬ íŒ¨í‚· ìº¡ì²˜**

`tcpdump -i eth1 icmp` ëª…ë ¹ìœ¼ë¡œ ì‹¤ì‹œê°„ ICMP íŠ¸ë˜í”½ í™•ì¸

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 icmp
```

âœ…Â **ì¶œë ¥**

```bash
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes
18:20:34.129970 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 636, length 64
18:20:34.130563 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 636, length 64
18:20:35.153607 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 637, length 64
18:20:35.154045 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 637, length 64
18:20:36.178084 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 638, length 64
18:20:36.179263 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 638, length 64
18:20:37.179611 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 639, length 64
18:20:37.179994 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 639, length 64
18:20:38.225687 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 640, length 64
18:20:38.226119 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 640, length 64
...
```

- `curl-pod (172.20.1.236)` â†’ `webpod-2 (172.20.0.130)` ì§ì ‘ í†µì‹ 
- ì˜¤ë²„ë ˆì´ í„°ë„ë§(VXLAN, Geneve) ì—†ì´ native IPë¡œ ì „ì†¡ë¨

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k get pod -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES
curl-pod                  1/1     Running   0          72m   172.20.1.236   k8s-ctr   <none>           <none>
webpod-556878d5d7-7p8bn   1/1     Running   0          73m   172.20.1.40    k8s-ctr   <none>           <none>
webpod-556878d5d7-r4dmh   1/1     Running   0          73m   172.20.0.130   k8s-w1    <none>           <none>
```

### **7. tcpdump ê²°ê³¼ ì €ì¥ ë° termshark ë¶„ì„**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 icmp -w /tmp/icmp.pcap
```

âœ…Â **ì¶œë ¥**

```bash
tcpdump: listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes
^C8 packets captured
10 packets received by filter
0 packets dropped by kernel
```

Source IPì™€ Destination IPê°€ ê·¸ëŒ€ë¡œ ë³´ì´ë©° encapsulation ì—†ìŒ

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# termshark -r /tmp/icmp.pcap
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/58e776b2-a2be-40e3-bdcd-fabe70fe0f30/image.png)

---

## **ğŸ”€ Masquerading**
![](https://velog.velcdn.com/images/tlsalswls123/post/31031291-285a-4196-ac29-88f237d27ba6/image.png)

**Masquerading ê°œìš”**

- ë‚´ë¶€ ì‚¬ì„¤ IPë¥¼ ê°€ì§„ ì¥ì¹˜ë“¤ì´ ê³µìœ ê¸°ë¥¼ í†µí•´ í•˜ë‚˜ì˜ ê³µì¸ IPë¡œ NATë˜ì–´ ì™¸ë¶€ì™€ í†µì‹ í•˜ëŠ” ë°©ì‹
- ì´ì™€ ìœ ì‚¬í•˜ê²Œ Kubernetesì—ì„œë„ Podê°€ ì™¸ë¶€ ì¸í„°ë„·ê³¼ í†µì‹ í•  ë•Œ **ë…¸ë“œì˜ IPë¡œ masquerading**ì´ í•„ìš”í•¨

**Kubernetesì—ì„œì˜ Masquerading ë™ì‘**

- Podê°€ ì¸í„°ë„·ìœ¼ë¡œ ë‚˜ê°ˆ ë•Œ, **ë…¸ë“œì˜ IPë¡œ Source NAT(Masquerade)** ë¨
- ì´ìœ : ëŒ€ë¶€ë¶„ì˜ ë…¸ë“œ IPëŠ” ì™¸ë¶€ ì¸í„°ë„·ê³¼ ì—°ê²° ê°€ëŠ¥í•¨
- ì™¸ë¶€ë¡œ ë‚˜ê°€ëŠ” íŠ¸ë˜í”½ë§Œ masquerading ëŒ€ìƒì´ë©°, **í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ í†µì‹ ì€ ì œì™¸**

**Ciliumì˜ Masquerading ë™ì‘ ë°©ì‹**

- í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ë¡œ ë‚˜ê°€ëŠ” ëª¨ë“  íŠ¸ë˜í”½ì˜ ì†ŒìŠ¤ IP â†’ ë…¸ë“œ IPë¡œ ë³€í™˜ë¨
- ë‹¨, **Pod ê°„ í†µì‹  ë˜ëŠ” í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ë…¸ë“œ IP ëŒ€ìƒ íŠ¸ë˜í”½**ì€ masquerading ë˜ì§€ ì•ŠìŒ
- ex. ë‹¤ë¥¸ ë…¸ë“œì˜ Podì™€ í†µì‹  ì‹œ, ì†ŒìŠ¤ IPê°€ ë…¸ë“œ IPë¡œ ë°”ë€Œë©´ ì•ˆë¨ â†’ **ì˜ˆì™¸ ì²˜ë¦¬ í•„ìš”**

**ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •: `ipv4-native-routing-cidr`**

- `ipv4-native-routing-cidr: 10.0.0.0/8` ì™€ ê°™ì´ ì„¤ì •
    - í•´ë‹¹ CIDR ë²”ìœ„ì˜ IPë¡œ ê°€ëŠ” íŠ¸ë˜í”½ì€ **masquerading ë˜ì§€ ì•ŠìŒ**
    - ì£¼ë¡œ í´ëŸ¬ìŠ¤í„° ë‚´ Pod CIDR ë²”ìœ„ë¥¼ ì§€ì •

### **1. Masquerading ìƒíƒœ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it -n kube-system ds/cilium -c cilium-agent  -- cilium status | grep Masquerading
```

âœ…Â **ì¶œë ¥**

```bash
Masquerading:            BPF   [eth0, eth1]   172.20.0.0/16  [IPv4: Enabled, IPv6: Disabled]
```

### **2. `ipv4-native-routing-cidr` í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium config view  | grep ipv4-native-routing-cidr
```

âœ…Â **ì¶œë ¥**

```bash
ipv4-native-routing-cidr                          172.20.0.0/16
```

- ê°™ì€ í´ëŸ¬ìŠ¤í„° ë‚´ Node IPë¡œ ê°€ëŠ” íŠ¸ë˜í”½ì€ Masquerading ì œì™¸ ëŒ€ìƒ

### **3. íŒŒë“œ ê°„ í†µì‹  ì‹œ Masquerading ì—¬ë¶€ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 icmp -nn
```

âœ…Â **ì¶œë ¥**

```bash
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes
18:46:02.125979 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 2131, length 64
18:46:02.126385 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 2131, length 64
18:46:03.153938 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 2132, length 64
18:46:03.154695 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 2132, length 64
18:46:04.154704 IP 172.20.1.236 > 172.20.0.130: ICMP echo request, id 9174, seq 2133, length 64
18:46:04.155285 IP 172.20.0.130 > 172.20.1.236: ICMP echo reply, id 9174, seq 2133, length 64
...
```

- `tcpdump`ë¥¼ í†µí•´ ICMP ìš”ì²­/ì‘ë‹µì„ í™•ì¸í•œ ê²°ê³¼, ì†ŒìŠ¤ IPê°€ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì–´ ì „ë‹¬ë¨
- **Pod ê°„ í†µì‹ ì—ì„œëŠ” Masqueradingì´ ì ìš©ë˜ì§€ ì•ŠìŒ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- ping 192.168.10.101
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 icmp -nn
```

âœ…Â **ì¶œë ¥**

```bash
64 bytes from 192.168.10.101: icmp_seq=1 ttl=63 time=0.333 ms
64 bytes from 192.168.10.101: icmp_seq=2 ttl=63 time=0.535 ms
64 bytes from 192.168.10.101: icmp_seq=3 ttl=63 time=0.499 ms
...
```

```bash
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes
18:48:32.790099 IP 172.20.1.236 > 192.168.10.101: ICMP echo request, id 9180, seq 1, length 64
18:48:32.790388 IP 192.168.10.101 > 172.20.1.236: ICMP echo reply, id 9180, seq 1, length 64
18:48:33.809718 IP 172.20.1.236 > 192.168.10.101: ICMP echo request, id 9180, seq 2, length 64
18:48:33.810202 IP 192.168.10.101 > 172.20.1.236: ICMP echo reply, id 9180, seq 2, length 64
18:48:34.833711 IP 172.20.1.236 > 192.168.10.101: ICMP echo request, id 9180, seq 3, length 64
18:48:34.834176 IP 192.168.10.101 > 172.20.1.236: ICMP echo reply, id 9180, seq 3, length 64
...
```

- ë§Œì•½ masquerading(NAT)ì´ ë˜ì—ˆë”ë¼ë©´ ì†ŒìŠ¤ IPê°€ ë…¸ë“œ IP(ì˜ˆ: `192.168.10.100`)ë¡œ ë³€í–ˆì–´ì•¼ í•¨
- ê²°ê³¼ì ìœ¼ë¡œ **ì™¸ë¶€ ë…¸ë“œë¡œì˜ íŠ¸ë˜í”½ì—ë„ Masqueradingì€ ì ìš©ë˜ì§€ ì•ŠìŒ**

---

## **ğŸ§ª Masquerading ì‹¤ìŠµ**
![](https://velog.velcdn.com/images/tlsalswls123/post/3a017d69-b6c8-4b2e-83fd-60bee85c9ed5/image.png)

### **1. Masquerading ì‹¤ìŠµ ê°œìš”**

- ì‹¤ìŠµ ëª©ì : Podì—ì„œ í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ ì„œë²„(router)ë¡œ í†µì‹  ì‹œ Masquerading ì—¬ë¶€ í™•ì¸
- ë¹„êµ ëŒ€ìƒ
    - **í´ëŸ¬ìŠ¤í„° ë‚´ ë…¸ë“œ** ê°„ í†µì‹  ì‹œ
    - **í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ ì„œë²„(router)** í†µì‹  ì‹œ
- í™˜ê²½ êµ¬ì„±
    - `curl-pod`, `webpod`, ì™¸ë¶€ ë¼ìš°í„° ì„œë²„ (`192.168.10.200`)
    - ë™ì¼ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­: `192.168.10.0/24`

### **2. í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ í†µì‹ : Masquerading ë˜ì§€ ì•ŠìŒ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- curl -s webpod | grep Hostname
Hostname: webpod-556878d5d7-r4dmh

(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- curl -s webpod | grep Hostname
Hostname: webpod-556878d5d7-7p8bn
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i eth1 icmp -nn
root@router:~# tcpdump -i eth1 icmp -nn
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/99c1eae1-0401-4a2b-9503-64e8d7bf5534/image.png)

**ì†ŒìŠ¤ IPê°€ Pod IP(`172.20.1.236`)ë¡œ ìœ ì§€ë¨**

```bash
kubectl exec -it curl-pod -- ping 192.168.10.101
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/97697b95-06e7-48f8-ac0f-0c1703d0fa2e/image.png)

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k get pod -owide
NAME                      READY   STATUS    RESTARTS   AGE    IP             NODE      NOMINATED NODE   READINESS GATES
curl-pod                  1/1     Running   0          121m   172.20.1.236   k8s-ctr   <none>           <none>
webpod-556878d5d7-7p8bn   1/1     Running   0          122m   172.20.1.40    k8s-ctr   <none>           <none>
webpod-556878d5d7-r4dmh   1/1     Running   0          123m   172.20.0.130   k8s-w1    <none>           <none>
```

### **3. í´ëŸ¬ìŠ¤í„° ì™¸ë¶€(router) í†µì‹ : Masquerading ë°œìƒ**

**ì†ŒìŠ¤ IPê°€ Pod IPê°€ ì•„ë‹ˆë¼ í•´ë‹¹ Podê°€ ìœ„ì¹˜í•œ ë…¸ë“œ IP(`192.168.10.100`)ë¡œ NAT**

```bash
kubectl exec -it curl-pod -- ping 192.168.10.200
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/5e95d6d9-4fdc-4a3e-a7c3-412d0d398c06/image.png)
- Ciliumì€ **í´ëŸ¬ìŠ¤í„° ì™¸ë¶€**ë¡œ ë‚˜ê°€ëŠ” íŠ¸ë˜í”½ì€ ìë™ìœ¼ë¡œ Masquerading ìˆ˜í–‰
- ë™ì¼ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì´ì–´ë„ **ë…¸ë“œê°€ ì•„ë‹Œ ì™¸ë¶€ ì„œë²„ì´ë¯€ë¡œ NAT ì ìš©ë¨**

### **4. `hubble observe` ëª…ë ¹ìœ¼ë¡œ ì‹¤ì‹œê°„ íŠ¸ë˜í”½ íë¦„ í™•ì¸**

```bash
hubble observe -f --pod curl-pod
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/d59ecd49-79f3-42d6-be5d-53d09631d96f/image.png)
- `curl-pod`ì—ì„œ ë°œìƒí•˜ëŠ” íŠ¸ë˜í”½ íë¦„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
- ì™¸ë¶€ ì„œë²„(router: `192.168.10.200`) í˜¸ì¶œ ì‹œ â†’ **ì†ŒìŠ¤ IPëŠ” ë…¸ë“œ IPë¡œ Masquerading ë˜ì–´ ì „ì†¡**

### **5. TCP í¬íŠ¸ 80ìœ¼ë¡œë„ Masquerading í™•ì¸**

```bash
kubectl exec -it curl-pod -- curl -s webpod
```
![](https://velog.velcdn.com/images/tlsalswls123/post/a48bff43-2aea-42fb-b2e5-775d9a39d976/image.png)

```bash
kubectl exec -it curl-pod -- curl -s 192.168.10.200
```
![](https://velog.velcdn.com/images/tlsalswls123/post/e656d48f-2c74-4429-8186-ed5148a60b47/image.png)
- ì™¸ë¶€ í†µì‹  (`192.168.10.200`) â†’ ì†ŒìŠ¤ IPëŠ” ë…¸ë“œ IP

### **6. ë¼ìš°í„°ì˜ Loopback ì¸í„°í˜ì´ìŠ¤ í™•ì¸**

**ë¼ìš°í„°(`192.168.10.200`)ì—ëŠ” 2ê°œì˜ ë”ë¯¸ ì¸í„°í˜ì´ìŠ¤ ì¡´ì¬**

```bash
root@router:~# ip -br -c -4 addr
```

âœ…Â **ì¶œë ¥**

```bash
lo               UNKNOWN        127.0.0.1/8 
eth0             UP             10.0.2.15/24 metric 100 
eth1             UP             192.168.10.200/24 
loop1            UNKNOWN        10.10.1.200/24 
loop2            UNKNOWN        10.10.2.200/24 
```

```bash
root@router:~# ip -c a
```

âœ…Â **ì¶œë ¥**

```bash
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host noprefixroute 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:6b:69:c9 brd ff:ff:ff:ff:ff:ff
    altname enp0s3
    inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 69510sec preferred_lft 69510sec
    inet6 fd17:625c:f037:2:a00:27ff:fe6b:69c9/64 scope global dynamic mngtmpaddr noprefixroute 
       valid_lft 85902sec preferred_lft 13902sec
    inet6 fe80::a00:27ff:fe6b:69c9/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:dc:00:69 brd ff:ff:ff:ff:ff:ff
    altname enp0s8
    inet 192.168.10.200/24 brd 192.168.10.255 scope global eth1
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fedc:69/64 scope link 
       valid_lft forever preferred_lft forever
4: loop1: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
    link/ether ba:83:60:b7:5a:f4 brd ff:ff:ff:ff:ff:ff
    inet 10.10.1.200/24 scope global loop1
       valid_lft forever preferred_lft forever
    inet6 fe80::9cd5:7fff:fe2e:29f7/64 scope link 
       valid_lft forever preferred_lft forever
5: loop2: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
    link/ether 9e:23:52:ad:1f:72 brd ff:ff:ff:ff:ff:ff
    inet 10.10.2.200/24 scope global loop2
       valid_lft forever preferred_lft forever
    inet6 fe80::58a6:ffff:fe7a:8424/64 scope link 
       valid_lft forever preferred_lft forever
```

### **7. k8s ë…¸ë“œì— Static Routing ì„¤ì •**

**ëª¨ë“  ë…¸ë“œì—ì„œ `10.10.0.0/16` ëŒ€ì—­ì„ ë¼ìš°í„°(`192.168.10.200`)ë¡œ ê²½ìœ í•˜ë„ë¡ static route ì„¤ì •**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# ip -c route | grep static
10.10.0.0/16 via 192.168.10.200 dev eth1 proto static
```

### **8. Loopback ì¸í„°í˜ì´ìŠ¤ë¡œì˜ í†µì‹ ë„ Masqueradingë¨**

**`curl-pod`ì—ì„œ `10.10.1.200`, `10.10.2.200`ìœ¼ë¡œ HTTP ìš”ì²­**

```bash
kubectl exec -it curl-pod -- curl -s 10.10.1.200
```
![](https://velog.velcdn.com/images/tlsalswls123/post/3ce4fab6-ca5e-42da-bb9d-9870308ef60e/image.png)

```bash
kubectl exec -it curl-pod -- curl -s 10.10.2.200
```
![](https://velog.velcdn.com/images/tlsalswls123/post/55da1ff2-4019-4420-8767-1f1cbde11439/image.png)
- ì´ IPë“¤ì€ ë¼ìš°í„°ì˜ loop1, loop2 ì¸í„°í˜ì´ìŠ¤ì— í•´ë‹¹
- Masqueradingìœ¼ë¡œ ì¸í•´ ì‘ë‹µì€ ë…¸ë“œ IPë¡œ ì „ì†¡ë¨ â†’ ì •ìƒì ì¸ í†µì‹  ê°€ëŠ¥

---

## **âš™ï¸ (Ciliumì˜ eBPF êµ¬í˜„) `ip-masq-agent` ì„¤ì •**

- Ciliumì˜ masquerading ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„ ì¤‘ í•˜ë‚˜ë¡œ, **íŠ¹ì • CIDRë¡œì˜ íŠ¸ë˜í”½ì— ëŒ€í•´ NAT(Masquerading)ë¥¼ ìƒëµ**í•  ìˆ˜ ìˆìŒ
- í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ í†µì‹  ì‹œ NATì„ í”¼í•˜ê³  **ì§ì ‘ Pod IPë¡œ í†µì‹ **í•˜ê³ ì í•  ë•Œ í™œìš©
- [https://github.com/kubernetes-sigs/ip-masq-agent](https://github.com/kubernetes-sigs/ip-masq-agent)

### **1. ipMasqAgent ì„¤ì • ë° ì ìš©**

Helm ëª…ë ¹ì„ í†µí•´ ip-masq-agent í™œì„±í™” ë° ì˜ˆì™¸ CIDR ì„¤ì •

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
--set ipMasqAgent.enabled=true --set ipMasqAgent.config.nonMasqueradeCIDRs='{10.10.1.0/24,10.10.2.0/24}'
```

âœ…Â **ì¶œë ¥**

```bash
Release "cilium" has been upgraded. Happy Helming!
NAME: cilium
LAST DEPLOYED: Wed Jul 30 22:12:33 2025
NAMESPACE: kube-system
STATUS: deployed
REVISION: 3
TEST SUITE: None
NOTES:
You have successfully installed Cilium with Hubble Relay and Hubble UI.

Your release version is 1.18.0.

For any further help, visit https://docs.cilium.io/en/v1.18/gettinghelp
```

### **2. ì„¤ì • ì ìš© í™•ì¸**

**(1) ConfigMap ìƒì„± í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get cm -n kube-system ip-masq-agent -o yaml | yq
```

âœ…Â **ì¶œë ¥**

```bash
{
  "apiVersion": "v1",
  "data": {
    "config": "{\"nonMasqueradeCIDRs\":[\"10.10.1.0/24\",\"10.10.2.0/24\"]}"
  },
  "kind": "ConfigMap",
  "metadata": {
    "annotations": {
      "meta.helm.sh/release-name": "cilium",
      "meta.helm.sh/release-namespace": "kube-system"
    },
    "creationTimestamp": "2025-07-30T13:12:35Z",
    "labels": {
      "app.kubernetes.io/managed-by": "Helm"
    },
    "name": "ip-masq-agent",
    "namespace": "kube-system",
    "resourceVersion": "38148",
    "uid": "14aaeb96-1b47-42cb-97f6-680fe73e8be6"
  }
}
```

- `nonMasqueradeCIDRs`ì— `10.10.1.0/24`, `10.10.2.0/24` í¬í•¨ë¨

**(2) ConfigMap ì¡´ì¬ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get cm -n kube-system
```

âœ…Â **ì¶œë ¥**

```bash
NAME                                                   DATA   AGE
cilium-config                                           154    7h32m
cilium-envoy-config                                     1      7h32m
coredns                                                1      7h32m
extension-apiserver-authentication                     6      7h32m
hubble-relay-config                                     1      7h32m
hubble-ui-nginx                                        1      7h32m
ip-masq-agent                                          1      104s
kube-apiserver-legacy-service-account-token-tracking   1      7h32m
kube-proxy                                             2      7h32m
kube-root-ca.crt                                       1      7h32m
kubeadm-config                                          1      7h32m
kubelet-config                                          1      7h32m
```

- `ip-masq-agent` í•­ëª© ì¶”ê°€ í™•ì¸

**(3) Cilium ì„¤ì • ì ìš© ì—¬ë¶€ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cilium config view  | grep -i ip-masq
```

âœ…Â **ì¶œë ¥**

```bash
enable-ip-masq-agent                              true
```

- `enable-ip-masq-agent: true` í™•ì¸

**(4)  BPF IPMasq ì˜ˆì™¸ CIDR í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system exec ds/cilium -c cilium-agent -- cilium-dbg bpf ipmasq list
```

âœ…Â **ì¶œë ¥**

```bash
IP PREFIX/ADDRESS   
10.10.1.0/24             
10.10.2.0/24             
169.254.0.0/16
```

### **3. NAT ì—†ì´ í†µì‹  ì‹¤íŒ¨ ì‚¬ë¡€ (ë¼ìš°í„° ë¼ìš°íŒ… ë¯¸ì„¤ì • ì‹œ)**

**`curl-pod(172.20.1.236)` â†’ `10.10.1.200` ìš”ì²­**
![](https://velog.velcdn.com/images/tlsalswls123/post/e3cd24a2-43f9-4e92-825e-9edb68fa00b9/image.png)
- ë¼ìš°í„°ëŠ” ì‘ë‹µì„ Pod IPë¡œ ë³´ë‚´ì•¼ í•˜ëŠ”ë° ë¼ìš°íŒ… ê²½ë¡œê°€ ì—†ì–´ **ì‘ë‹µ ì‹¤íŒ¨**

**ë¬¸ì œì›ì¸**

- ë¼ìš°í„°ëŠ” `172.20.0.0/16` ëŒ€ì—­(Pod CIDR)ì— ëŒ€í•œ ê²½ë¡œë¥¼ ì•Œì§€ ëª»í•¨
- Podê°€ ì‚¬ë‚´ë§ ì„œë²„ì— ìš”ì²­ì„ ë³´ë‚´ê³ , ì‘ë‹µì´ ëŒì•„ì˜¤ì§€ ì•ŠìŒ
- TCP Handshakeì—ì„œ `SYN`ì€ ì „ì†¡ë˜ë‚˜, `SYN-ACK`ëŠ” ìˆ˜ì‹ ë˜ì§€ ì•ŠìŒ â†’ í†µì‹  ì‹¤íŒ¨

### **4. Pod IP í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k get pod -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES
curl-pod                  1/1     Running   0          5h16m   172.20.1.236   k8s-ctr   <none>           <none>
webpod-556878d5d7-7p8bn   1/1     Running   0          5h17m   172.20.1.40    k8s-ctr   <none>           <none>
webpod-556878d5d7-r4dmh   1/1     Running   0          5h17m   172.20.0.130   k8s-w1    <none>           <none>
```

- `curl-pod`: `172.20.1.236` (ì»¨íŠ¸ë¡¤í”Œë ˆì¸ ë…¸ë“œì— ìœ„ì¹˜)
- `webpod`: `172.20.0.130` (ì›Œì»¤ë…¸ë“œ 1ì— ìœ„ì¹˜)

### **5. ë¼ìš°í„° ë¼ìš°íŒ… í…Œì´ë¸” í™•ì¸**

```bash
root@router:~# ip -c route
```

âœ…Â **ì¶œë ¥**

```bash
default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 
10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.10.1.0/24 dev loop1 proto kernel scope link src 10.10.1.200 
10.10.2.0/24 dev loop2 proto kernel scope link src 10.10.2.200 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.200 
```

- ë¼ìš°í„°ëŠ” `172.20.x.x`ì— ëŒ€í•œ ê²½ë¡œê°€ ì—†ì–´ unknown destinationìœ¼ë¡œ ì¸ì‹
- í•´ë‹¹ íŒ¨í‚·ì„ default gateway (`10.0.2.2`)ë¡œ ì „ì†¡ â†’ ì¸í„°ë„·ìœ¼ë¡œ ë‚˜ê°€ê²Œ ë¨

### **6. ë…¸ë“œ ë¼ìš°íŒ… í…Œì´ë¸” í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# ip -c route
```

âœ…Â **ì¶œë ¥**

```bash
default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100 
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 
10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100 
10.10.0.0/16 via 192.168.10.200 dev eth1 proto static 
172.20.0.0/24 via 192.168.10.101 dev eth1 proto kernel 
172.20.1.40 dev lxc0895f39b5225 proto kernel scope link 
172.20.1.144 dev lxcf2a822e72a6e proto kernel scope link 
172.20.1.236 dev lxcd63c3c1415ff proto kernel scope link 
192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100 
```

### **7. ë¼ìš°í„°ì— Static Route ì„¤ì •**

```bash
root@router:~# ip route add 172.20.1.0/24 via 192.168.10.100
ip route add 172.20.0.0/24 via 192.168.10.101
```

- ë¼ìš°í„°ê°€ í•´ë‹¹ Pod CIDR íŠ¸ë˜í”½ì„ í•´ë‹¹ ë…¸ë“œë¡œ ì •í™•íˆ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
- `172.20.1.0/24` â†’ ì»¨íŠ¸ë¡¤í”Œë ˆì¸ ë…¸ë“œ, `172.20.0.0/24` â†’ ì›Œì»¤ë…¸ë“œ 1

### **8. Static Route ë°˜ì˜ í™•ì¸**

```bash
root@router:~# ip -c route | grep 172.20
```

âœ…Â **ì¶œë ¥**

```bash
172.20.0.0/24 via 192.168.10.101 dev eth1 
172.20.1.0/24 via 192.168.10.100 dev eth1 
```

- ì´ì œ ë¼ìš°í„°ëŠ” Pod IPë¡œ ë“¤ì–´ì˜¨ ì‘ë‹µ íŠ¸ë˜í”½ì„ ì˜¬ë°”ë¥´ê²Œ ë¼ìš°íŒ… ê°€ëŠ¥

### **9. í†µì‹  ì •ìƒ ì‘ë™ í™•ì¸**

NAT ì—†ì´ ì‚¬ë‚´ë§ê³¼ ì§ì ‘ í†µì‹  ì„±ê³µ

```bash
kubectl exec -it curl-pod -- curl -s 10.10.1.200
```
![](https://velog.velcdn.com/images/tlsalswls123/post/2db8b4f2-75d6-4331-835e-d34295562b75/image.png)

```bash
kubectl exec -it curl-pod -- curl -s 10.10.2.200
```
![](https://velog.velcdn.com/images/tlsalswls123/post/9ef9b5a5-cd72-4d85-84bf-ad2a8f580a4b/image.png)

---

## **ğŸ“¡ CoreDNS, NodeLocalDNS**

### **1. íŒŒë“œ ë‚´ `/etc/resolv.conf` í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- cat /etc/resolv.conf
```

âœ…Â **ì¶œë ¥**

```bash
search default.svc.cluster.local svc.cluster.local cluster.local Davolink
nameserver 10.96.0.10
options ndots:5
```

### **2. kubelet DNS ì„¤ì • í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat /var/lib/kubelet/config.yaml | grep cluster -A1
```

âœ…Â **ì¶œë ¥**

```bash
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerRuntimeEndpoint: ""
```

### **3. CoreDNS ì„œë¹„ìŠ¤ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get svc,ep -n kube-system kube-dns
```

âœ…Â **ì¶œë ¥**

```bash
Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
service/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   8h

NAME                 ENDPOINTS                                                     AGE
endpoints/kube-dns   172.20.0.186:53,172.20.1.144:53,172.20.0.186:53 + 3 more...   8h
```

### **4. CoreDNS Pod í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -n kube-system -l k8s-app=kube-dns
```

âœ…Â **ì¶œë ¥**

```bash
NAME                       READY   STATUS    RESTARTS   AGE
coredns-674b8bbfcf-gbnm8   1/1     Running   0          6h12m
coredns-674b8bbfcf-vvgfm   1/1     Running   0          6h12m
```

- CoreDNSëŠ” `kube-system` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ 2ê°œì˜ replicaë¡œ ë™ì‘
- íŒŒë“œ ë¼ë²¨ `k8s-app=kube-dns`ë¡œ í•„í„°ë§ ê°€ëŠ¥

### **5. CoreDNS Pod ìƒì„¸ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kc describe pod -n kube-system -l k8s-app=kube-dns
```

âœ…Â **ì¶œë ¥**

```bash
...
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns
    Optional:  false
...
```

### **6. CoreDNS Corefile í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kc describe cm -n kube-system coredns
```

âœ…Â **ì¶œë ¥**

```bash
Name:         coredns
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Data
====
Corefile:
----
.:53 {
    errors
    health {
       lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    cache 30 {
       disable success cluster.local
       disable denial cluster.local
    }
    loop
    reload
    loadbalance
}

BinaryData
====

Events:  <none>
```

### **7. ë…¸ë“œì˜ `/etc/resolv.conf` í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat /etc/resolv.conf
```

âœ…Â **ì¶œë ¥**

```bash
# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
# Do not edit.
#
# This file might be symlinked as /etc/resolv.conf. If you're looking at
# /etc/resolv.conf and seeing this text, you have followed the symlink.
#
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
#
# Run "resolvectl status" to see details about the uplink DNS servers
# currently in use.
#
# Third party programs should typically not access this file directly, but only
# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
# different way, replace this symlink by a static file or a different symlink.
#
# See man:systemd-resolved.service(8) for details about the supported modes of
# operation for /etc/resolv.conf.

nameserver 127.0.0.53
options edns0 trust-ad
search Davolink
```

- ë…¸ë“œ ìì²´ëŠ” systemd-resolvedì— ì˜í•´ ê´€ë¦¬ë˜ëŠ” stub resolver ì‚¬ìš© ì¤‘
- ì‹¤ì œ ì§ˆì˜ëŠ” `127.0.0.53`ë¡œ ê°€ë©°, ì´ëŠ” ë¡œì»¬ DNS í”„ë¡ì‹œ ì—­í• 

### **8. ë…¸ë“œì˜ ìƒìœ„ DNS í™•ì¸ (`resolvectl`)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# resolvectl 
```

âœ…Â **ì¶œë ¥**

```bash
Global
         Protocols: -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported
  resolv.conf mode: stub

Link 2 (eth0)
    Current Scopes: DNS
         Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported
Current DNS Server: 10.0.2.3
       DNS Servers: 10.0.2.3
        DNS Domain: Davolink

Link 3 (eth1)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported

Link 4 (cilium_net)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported

Link 5 (cilium_host)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported

Link 9 (lxcfeeee14aa766)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported

Link 25 (lxcf2a822e72a6e)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported

Link 27 (lxc0895f39b5225)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported

Link 29 (lxcd63c3c1415ff)
    Current Scopes: none
         Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported
```

- ìƒìœ„ DNSëŠ” `10.0.2.3`ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŒ (ex. VirtualBox NAT DNS)
- ì´ëŠ” VM ê²ŒìŠ¤íŠ¸ì˜ ì™¸ë¶€ ë„¤ì„ì„œë²„ ì—­í• ì„ í•˜ë©°, upstream ì§ˆì˜ë¥¼ ë‹´ë‹¹

---

## **ğŸ” íŒŒë“œì—ì„œ DNS ì§ˆì˜ í™•ì¸**

### **1. íŒŒë“œ ë° CoreDNS IP í™•ì¸**

`curl-pod`ê³¼ `webpod`ë“¤ì˜ Pod IP ë° ë…¸ë“œ ìœ„ì¹˜ í™•ì¸

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES
curl-pod                  1/1     Running   0          6h17m   172.20.1.236   k8s-ctr   <none>           <none>
webpod-556878d5d7-7p8bn   1/1     Running   0          6h18m   172.20.1.40    k8s-ctr   <none>           <none>
webpod-556878d5d7-r4dmh   1/1     Running   0          6h19m   172.20.0.130   k8s-w1    <none>           <none>
```

CoreDNS íŒŒë“œ 2ê°œê°€ `k8s-ctr`, `k8s-w1` ë…¸ë“œì— ê°ê° ì¡´ì¬í•¨

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -n kube-system -l k8s-app=kube-dns -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                       READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES
coredns-674b8bbfcf-gbnm8   1/1     Running   0          6h24m   172.20.0.186   k8s-w1    <none>           <none>
coredns-674b8bbfcf-vvgfm   1/1     Running   0          6h24m   172.20.1.144   k8s-ctr   <none>           <none>
```

### **2. CoreDNS íŒŒë“œ ìˆ˜ ì¶•ì†Œ (ì‹¤ìŠµ í¸ì˜ ëª©ì )**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl scale deployment -n kube-system coredns --replicas 1

# ê²°ê³¼
deployment.apps/coredns scaled
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -n kube-system -l k8s-app=kube-dns -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                       READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES
coredns-674b8bbfcf-vvgfm   1/1     Running   0          6h25m   172.20.1.144   k8s-ctr   <none>           <none>
```

### **3. CoreDNS ë©”íŠ¸ë¦­ í™•ì¸ (ì§ˆì˜ ì „)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- curl kube-dns.kube-system.svc:9153/metrics | grep coredns_cache_ | grep -v ^#
```

âœ…Â **ì¶œë ¥**

```bash
coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 1
coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 0
coredns_cache_misses_total{server="dns://:53",view="",zones="."} 3170
coredns_cache_requests_total{server="dns://:53",view="",zones="."} 3170
```

### **4. ë‚´ë¶€ DNS ì§ˆì˜ í…ŒìŠ¤íŠ¸ (`webpod`)**

- `nslookup webpod` ìˆ˜í–‰ â†’ ë‚´ë¶€ DNS ì •ìƒ ë™ì‘
- `webpod.default.svc.cluster.local` â†’ `10.96.152.212` IP ë°˜í™˜

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- nslookup webpod
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/85bbe14e-254d-4512-ac9d-89237a050b69/image.png)

### **5. ì§ˆì˜ ë””ë²„ê¹… (`nslookup -debug`)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- nslookup -debug webpod
```

âœ…Â **ì¶œë ¥**

```bash
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

------------
    QUESTIONS:
	webpod.default.svc.cluster.local, type = A, class = IN
    ANSWERS:
    ->  webpod.default.svc.cluster.local
	internet address = 10.96.152.212
	ttl = 30
    AUTHORITY RECORDS:
    ADDITIONAL RECORDS:
------------
Name:	webpod.default.svc.cluster.local
Address: 10.96.152.212
;; Got recursion not available from 10.96.0.10
------------
    QUESTIONS:
	webpod.default.svc.cluster.local, type = AAAA, class = IN
    ANSWERS:
    AUTHORITY RECORDS:
    ->  cluster.local
	origin = ns.dns.cluster.local
	mail addr = hostmaster.cluster.local
	serial = 1753885699
	refresh = 7200
	retry = 1800
	expire = 86400
	minimum = 30
	ttl = 30
    ADDITIONAL RECORDS:
------------
```

- A/AAAA ë ˆì½”ë“œ ì§ˆì˜ íë¦„ ë° TTL, Authority ì˜ì—­ ì‘ë‹µ í™•ì¸

### **6. ì™¸ë¶€ ë„ë©”ì¸ ì§ˆì˜ í…ŒìŠ¤íŠ¸ (`google.com`)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- nslookup -debug google.com
```

âœ…Â **ì¶œë ¥**

```bash
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

------------
    QUESTIONS:
	google.com.default.svc.cluster.local, type = A, class = IN
    ANSWERS:
    AUTHORITY RECORDS:
    ->  cluster.local
	origin = ns.dns.cluster.local
	mail addr = hostmaster.cluster.local
	serial = 1753885699
	refresh = 7200
	retry = 1800
	expire = 86400
	minimum = 30
	ttl = 30
    ADDITIONAL RECORDS:
------------
** server can't find google.com.default.svc.cluster.local: NXDOMAIN
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

------------
    QUESTIONS:
	google.com.svc.cluster.local, type = A, class = IN
    ANSWERS:
    AUTHORITY RECORDS:
    ->  cluster.local
	origin = ns.dns.cluster.local
	mail addr = hostmaster.cluster.local
	serial = 1753885699
	refresh = 7200
	retry = 1800
	expire = 86400
	minimum = 30
	ttl = 30
    ADDITIONAL RECORDS:
------------
** server can't find google.com.svc.cluster.local: NXDOMAIN
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

------------
    QUESTIONS:
	google.com.cluster.local, type = A, class = IN
    ANSWERS:
    AUTHORITY RECORDS:
    ->  cluster.local
	origin = ns.dns.cluster.local
	mail addr = hostmaster.cluster.local
	serial = 1753885699
	refresh = 7200
	retry = 1800
	expire = 86400
	minimum = 30
	ttl = 30
    ADDITIONAL RECORDS:
------------
** server can't find google.com.cluster.local: NXDOMAIN
Server:		10.96.0.10
Address:	10.96.0.10#53

------------
    QUESTIONS:
	google.com.Davolink, type = A, class = IN
    ANSWERS:
    AUTHORITY RECORDS:
    ->  .
	origin = a.root-servers.net
	mail addr = nstld.verisign-grs.com
	serial = 2025073000
	refresh = 1800
	retry = 900
	expire = 604800
	minimum = 86400
	ttl = 30
    ADDITIONAL RECORDS:
------------
** server can't find google.com.Davolink: NXDOMAIN
Server:		10.96.0.10
Address:	10.96.0.10#53

------------
    QUESTIONS:
	google.com, type = A, class = IN
    ANSWERS:
    ->  google.com
	internet address = 142.251.222.14
	ttl = 30
    AUTHORITY RECORDS:
    ADDITIONAL RECORDS:
------------
Non-authoritative answer:
Name:	google.com
Address: 142.251.222.14
------------
    QUESTIONS:
	google.com, type = AAAA, class = IN
    ANSWERS:
    ->  google.com
	has AAAA address 2404:6800:4005:813::200e
	ttl = 30
    AUTHORITY RECORDS:
    ADDITIONAL RECORDS:
------------
Name:	google.com
Address: 2404:6800:4005:813::200e

command terminated with exit code 1
```

`google.com` ì§ˆì˜ ì‹œ search ë„ë©”ì¸ì„ ë”°ë¼ ìˆœì°¨ ì§ˆì˜ë¨

- `google.com.default.svc.cluster.local` â†’ `NXDOMAIN`
- `google.com` â†’ ì •ìƒ ì‘ë‹µ (A/AAAA ëª¨ë‘ ìˆ˜ì‹ )

**`curl-pod`ì—ì„œ ìˆ˜í–‰í•œ DNS ì§ˆì˜ì— ëŒ€í•´ CoreDNSê°€ A ë ˆì½”ë“œë¡œ ì‘ë‹µí•œ ê²ƒì„ ë¡œê·¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŒ**
![](https://velog.velcdn.com/images/tlsalswls123/post/120c35b6-6cc6-4ebd-8683-65a96ad13038/image.png)

### **7. CoreDNS ë©”íŠ¸ë¦­ í™•ì¸ (ì§ˆì˜ í›„)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- curl kube-dns.kube-system.svc:9153/metrics | grep coredns_cache_ | grep -v ^#
```

âœ…Â **ì¶œë ¥**

```bash
coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 2
coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 2
coredns_cache_misses_total{server="dns://:53",view="",zones="."} 3188
coredns_cache_requests_total{server="dns://:53",view="",zones="."} 3188
```

### **8. CoreDNS ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system logs -l k8s-app=kube-dns -f
```

âœ…Â **ì¶œë ¥**

```bash
maxprocs: Leaving GOMAXPROCS=2: CPU quota undefined
.:53
[INFO] plugin/reload: Running configuration SHA512 = 1b226df79860026c6a52e67daa10d7f0d57ec5b023288ec00c5e05f93523c894564e15b91770d3a07ae1cfbe861d15b37d4a0027e69c546ab112970993a3b03b
CoreDNS-1.12.0
linux/amd64, go1.23.3, 51e11f1
```

### **9. k9s CoreDNS í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k9s
```
![](https://velog.velcdn.com/images/tlsalswls123/post/855fb96b-2eb2-4e28-9ab0-eedf227a58d1/image.png)

### **10. ë‚´ë¶€ ë„ë©”ì¸ ì§ˆì˜ í…ŒìŠ¤íŠ¸ (`webpod`)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- nslookup webpod
```

âœ…Â **ì¶œë ¥**

```bash
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

Name:	webpod.default.svc.cluster.local
Address: 10.96.152.212
;; Got recursion not available from 10.96.0.10
```

### **11. Hubbleë¡œ ë‚´ë¶€ DNS ì§ˆì˜ íë¦„ ì¶”ì **

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --port 53
```

âœ…Â **ì¶œë ¥**

```bash
Jul 30 14:56:15.979: 10.0.2.15:44999 (host) -> 10.0.2.3:53 (world) to-network FORWARDED (UDP)
Jul 30 14:57:36.751: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 14:57:36.751: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 14:57:36.751: default/curl-pod:32772 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 14:57:36.752: default/curl-pod:32772 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 14:57:36.752: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 14:57:36.752: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
Jul 30 14:57:36.754: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 14:57:36.754: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 14:57:36.754: default/curl-pod:57903 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 14:57:36.754: default/curl-pod:57903 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 14:57:36.754: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 14:57:36.754: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
```

- `curl-pod` â†’ `10.96.0.10:53` ìš”ì²­
- ì§ˆì˜ ë° ì‘ë‹µ íë¦„ì´ Ciliumì—ì„œ í¬ì›Œë”© ë° ë³€í™˜ ê³¼ì •ì„ ê±°ì³ í™•ì¸ë¨

### **12. tcpdumpë¡œ ë‚´ë¶€ DNS íŒ¨í‚· í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i any udp port 53 -nn
tcpdump: data link type LINUX_SLL2
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
23:57:36.751572 lxcd63c3c1415ff In  IP 172.20.1.236.32772 > 172.20.1.144.53: 19286+ A? webpod.default.svc.cluster.local. (50)
23:57:36.752160 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.32772: 19286*- 1/0/0 A 10.96.152.212 (98)
23:57:36.754268 lxcd63c3c1415ff In  IP 172.20.1.236.57903 > 172.20.1.144.53: 5377+ AAAA? webpod.default.svc.cluster.local. (50)
23:57:36.754408 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.57903: 5377*- 0/1/0 (143)
```

- `A?`, `AAAA?` ì§ˆì˜ê°€ CoreDNS íŒŒë“œì— ë„ë‹¬í•˜ëŠ”ì§€ í™•ì¸
- ì‘ë‹µì— IP `10.96.152.212` ë°˜í™˜ë˜ëŠ” ê²ƒ í™•ì¸

### **13. ì™¸ë¶€ ë„ë©”ì¸ ì§ˆì˜ í…ŒìŠ¤íŠ¸ (`google.com`)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- nslookup google.com
```

âœ…Â **ì¶œë ¥**

```bash
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

Non-authoritative answer:
Name:	google.com
Address: 142.250.196.110
Name:	google.com
Address: 2404:6800:4004:825::200e
```

- "recursion not available" ë©”ì‹œì§€ ì—¬ëŸ¬ ë²ˆ ì¶œë ¥ë˜ë‚˜
- ìµœì¢…ì ìœ¼ë¡œ A ë ˆì½”ë“œ (`142.250.196.110`), AAAA ë ˆì½”ë“œ (`2404:6800:4004:825::200e`) ì •ìƒ ë°˜í™˜

### **14. Hubbleë¡œ ì™¸ë¶€ ë„ë©”ì¸ ì§ˆì˜ íë¦„ ì¶”ì **

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --port 53
```

âœ…Â **ì¶œë ¥**

```bash
Jul 30 15:01:56.982: 10.0.2.15:58614 (host) -> 10.0.2.3:53 (world) to-network FORWARDED (UDP)
Jul 30 15:02:20.444: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 15:02:20.444: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 15:02:20.444: default/curl-pod:46923 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.446: default/curl-pod:46923 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.446: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.446: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
Jul 30 15:02:20.446: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 15:02:20.446: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 15:02:20.446: default/curl-pod:42237 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.446: default/curl-pod:42237 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.446: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.446: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
Jul 30 15:02:20.448: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 15:02:20.448: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 15:02:20.449: default/curl-pod:50175 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.449: default/curl-pod:50175 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.449: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.449: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
Jul 30 15:02:20.450: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 15:02:20.450: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 15:02:20.450: default/curl-pod:58567 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.450: 10.0.2.3:53 (world) <> kube-system/coredns-674b8bbfcf-vvgfm (ID:28565) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.450: 10.0.2.3:53 (world) <> kube-system/coredns-674b8bbfcf-vvgfm (ID:28565) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.450: 10.0.2.3:53 (world) <> kube-system/coredns-674b8bbfcf-vvgfm (ID:28565) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.450: kube-system/coredns-674b8bbfcf-vvgfm:57647 (ID:28565) -> 10.0.2.3:53 (world) to-network FORWARDED (UDP)
Jul 30 15:02:20.450: 10.0.2.3:53 (world) <> kube-system/coredns-674b8bbfcf-vvgfm (ID:28565) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.450: 10.0.2.3:53 (world) <> kube-system/coredns-674b8bbfcf-vvgfm (ID:28565) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.455: kube-system/coredns-674b8bbfcf-vvgfm:57647 (ID:28565) <- 10.0.2.3:53 (world) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.455: default/curl-pod:58567 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.455: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.455: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
Jul 30 15:02:20.456: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 15:02:20.456: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 15:02:20.456: default/curl-pod:35291 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.461: default/curl-pod:35291 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.461: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.461: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
Jul 30 15:02:20.463: default/curl-pod (ID:5580) <> 10.96.0.10:53 (world) pre-xlate-fwd TRACED (UDP)
Jul 30 15:02:20.463: default/curl-pod (ID:5580) <> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) post-xlate-fwd TRANSLATED (UDP)
Jul 30 15:02:20.463: default/curl-pod:47474 (ID:5580) -> kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.475: default/curl-pod:47474 (ID:5580) <- kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) to-endpoint FORWARDED (UDP)
Jul 30 15:02:20.476: kube-system/coredns-674b8bbfcf-vvgfm:53 (ID:28565) <> default/curl-pod (ID:5580) pre-xlate-rev TRACED (UDP)
Jul 30 15:02:20.476: 10.96.0.10:53 (world) <> default/curl-pod (ID:5580) post-xlate-rev TRANSLATED (UDP)
```

- `curl-pod` â†’ `CoreDNS` â†’ ì™¸ë¶€ ë„¤ì„ì„œë²„ (`10.0.2.3`) íë¦„ í™•ì¸
- CoreDNSê°€ ì¬ê·€ ì§ˆì˜ë¥¼ ìœ„í•´ ì™¸ë¶€ DNSë¡œ íŠ¸ë˜í”½ ì „ë‹¬
- CoreDNS â†’ `10.0.2.3`ë¡œ UDP í¬ì›Œë”© í™•ì¸ë¨

### **15. tcpdumpë¡œ ì™¸ë¶€ DNS ì§ˆì˜ íŒ¨í‚· ë¶„ì„**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# tcpdump -i any udp port 53 -nn
```

âœ…Â **ì¶œë ¥**

```bash
tcpdump: data link type LINUX_SLL2
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
00:02:20.444113 lxcd63c3c1415ff In  IP 172.20.1.236.46923 > 172.20.1.144.53: 7116+ A? google.com.default.svc.cluster.local. (54)
00:02:20.444467 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.46923: 7116 NXDomain*- 0/1/0 (147)
00:02:20.446052 lxcd63c3c1415ff In  IP 172.20.1.236.42237 > 172.20.1.144.53: 5495+ A? google.com.svc.cluster.local. (46)
00:02:20.446537 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.42237: 5495 NXDomain*- 0/1/0 (139)
00:02:20.448803 lxcd63c3c1415ff In  IP 172.20.1.236.50175 > 172.20.1.144.53: 9828+ A? google.com.cluster.local. (42)
00:02:20.448969 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.50175: 9828 NXDomain*- 0/1/0 (135)
00:02:20.450674 lxcd63c3c1415ff In  IP 172.20.1.236.58567 > 172.20.1.144.53: 41730+ A? google.com.Davolink. (37)
00:02:20.450858 lxcf2a822e72a6e In  IP 172.20.1.144.57647 > 10.0.2.3.53: 7727+ A? google.com.Davolink. (37)
00:02:20.450875 eth0  Out IP 10.0.2.15.57647 > 10.0.2.3.53: 7727+ A? google.com.Davolink. (37)
00:02:20.455142 eth0  In  IP 10.0.2.3.53 > 10.0.2.15.57647: 7727 NXDomain 0/1/0 (112)
00:02:20.455305 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.58567: 41730 NXDomain 0/1/0 (112)
00:02:20.456958 lxcd63c3c1415ff In  IP 172.20.1.236.35291 > 172.20.1.144.53: 23450+ A? google.com. (28)
00:02:20.457191 lxcf2a822e72a6e In  IP 172.20.1.144.57647 > 10.0.2.3.53: 12952+ A? google.com. (28)
00:02:20.457204 eth0  Out IP 10.0.2.15.57647 > 10.0.2.3.53: 12952+ A? google.com. (28)
00:02:20.460993 eth0  In  IP 10.0.2.3.53 > 10.0.2.15.57647: 12952 1/0/0 A 142.250.196.110 (44)
00:02:20.461181 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.35291: 23450 1/0/0 A 142.250.196.110 (54)
00:02:20.463949 lxcd63c3c1415ff In  IP 172.20.1.236.47474 > 172.20.1.144.53: 49159+ AAAA? google.com. (28)
00:02:20.464413 lxcf2a822e72a6e In  IP 172.20.1.144.57647 > 10.0.2.3.53: 52829+ AAAA? google.com. (28)
00:02:20.464427 eth0  Out IP 10.0.2.15.57647 > 10.0.2.3.53: 52829+ AAAA? google.com. (28)
00:02:20.473156 eth0  In  IP 10.0.2.3.53 > 10.0.2.15.57647: 52829 1/0/0 AAAA 2404:6800:4004:825::200e (56)
00:02:20.473605 lxcf2a822e72a6e In  IP 172.20.1.144.53 > 172.20.1.236.47474: 49159 1/0/0 AAAA 2404:6800:4004:825::200e (66)
```

- `google.com.default.svc.cluster.local.` ë“± search ë„ë©”ì¸ ì ìš© í›„ ìˆœì°¨ì  ì‹¤íŒ¨ (`NXDOMAIN`)
- ìµœì¢…ì ìœ¼ë¡œ `google.com.`ì— ëŒ€í•´ A, AAAA ì§ˆì˜ ì„±ê³µ
- ì™¸ë¶€ DNS ì„œë²„ì¸ `10.0.2.3`ë¡œ ìš”ì²­ ì „ë‹¬ë˜ë©° ì‘ë‹µ ìˆ˜ì‹ 

### **16. CoreDNS ìºì‹œ ë©”íŠ¸ë¦­ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- curl kube-dns.kube-system.svc:9153/metrics | grep coredns_cache_ | grep -v ^#
```

âœ…Â **ì¶œë ¥**

```bash
coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 2
coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 2
coredns_cache_hits_total{server="dns://:53",type="denial",view="",zones="."} 1
coredns_cache_hits_total{server="dns://:53",type="success",view="",zones="."} 2
coredns_cache_misses_total{server="dns://:53",view="",zones="."} 3223
coredns_cache_requests_total{server="dns://:53",view="",zones="."} 3226
```

---

## **ğŸ§  `NodeLocalDNS` ì‹¤ìŠµ + Cilium `Local Redirect Policy`**

### **1. iptables ìƒíƒœ ë°±ì—… (ì„¤ì¹˜ ì „)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# iptables-save | tee before.txt
```

### **2. NodeLocal DNS ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# wget https://github.com/kubernetes/kubernetes/raw/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml
```

âœ…Â **ì¶œë ¥**

```bash
--2025-07-31 00:17:53--  https://github.com/kubernetes/kubernetes/raw/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml
Resolving github.com (github.com)... 20.200.245.247
Connecting to github.com (github.com)|20.200.245.247|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml [following]
--2025-07-31 00:17:53--  https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 5377 (5.3K) [text/plain]
Saving to: â€˜nodelocaldns.yamlâ€™

nodelocaldns.yaml       100%[==============================>]   5.25K  --.-KB/s    in 0s      

2025-07-31 00:17:53 (61.7 MB/s) - â€˜nodelocaldns.yamlâ€™ saved [5377/5377]
```

### **3. í™˜ê²½ ë³€ìˆ˜ ì…‹íŒ…**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubedns=`kubectl get svc kube-dns -n kube-system -o jsonpath={.spec.clusterIP}`
domain='cluster.local'
localdns='169.254.20.10'
echo $kubedns $domain $localdns
```

âœ…Â **ì¶œë ¥**

```bash
10.96.0.10 cluster.local 169.254.20.10
```

### **4. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‚´ ë³€ìˆ˜ ì¹˜í™˜**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# sed -i "s/__PILLAR__LOCAL__DNS__/$localdns/g; s/__PILLAR__DNS__DOMAIN__/$domain/g; s/__PILLAR__DNS__SERVER__/$kubedns/g" nodelocaldns.yaml
```

### **5. NodeLocalDNS ì„¤ì¹˜**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl apply -f nodelocaldns.yaml

# ê²°ê³¼
serviceaccount/node-local-dns created
service/kube-dns-upstream created
configmap/node-local-dns created
daemonset.apps/node-local-dns created
service/node-local-dns created
```

### **6. ì„¤ì¹˜ í™•ì¸ (Pod í™•ì¸)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get pod -n kube-system -l k8s-app=node-local-dns -owide
```

âœ…Â **ì¶œë ¥**

```bash
NAME                   READY   STATUS    RESTARTS   AGE   IP               NODE      NOMINATED NODE   READINESS GATES
node-local-dns-ggjmt   1/1     Running   0          30s   192.168.10.100   k8s-ctr   <none>           <none>
node-local-dns-kzthr   1/1     Running   0          30s   192.168.10.101   k8s-w1    <none>           <none>
```

### **7. ë¡œê·¸ ì„¤ì • ì¶”ê°€ (ConfigMap ìˆ˜ì •)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl edit cm -n kube-system node-local-dns
```

âœ…Â **ì¶œë ¥**

```bash
...
    cluster.local:53 {
        log
        errors
        cache {
                success 9984 30
                denial 9984 5
        }
        reload
        loop
        bind 169.254.20.10 10.96.0.10
        forward . __PILLAR__CLUSTER__DNS__ {
                force_tcp
        }
        prometheus :9253
        health 169.254.20.10:8080
        }
...
    .:53 {
        log
        errors
        cache 30
        reload
        loop
        bind 169.254.20.10 10.96.0.10
        forward . __PILLAR__UPSTREAM__SERVERS__
        prometheus :9253
        }

configmap/node-local-dns edited
```

- Corefile ë‚´ `cluster.local:53` ë° `.:53` ë¸”ë¡ì— `log` ì¶”ê°€

### **8. ë°ëª¬ì…‹ ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system rollout restart ds node-local-dns

# ê²°ê³¼
daemonset.apps/node-local-dns restarted
```

### **9. ì ìš©ëœ ConfigMap í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl describe cm -n kube-system node-local-dns
```

âœ…Â **ì¶œë ¥**

```bash
Name:         node-local-dns
Namespace:    kube-system
Labels:       addonmanager.kubernetes.io/mode=Reconcile
Annotations:  <none>

Data
====
Corefile:
----
cluster.local:53 {
    log
    errors
    cache {
            success 9984 30
            denial 9984 5
    }
    reload
    loop
    bind 169.254.20.10 10.96.0.10
    forward . __PILLAR__CLUSTER__DNS__ {
            force_tcp
    }
    prometheus :9253
    health 169.254.20.10:8080
    }
in-addr.arpa:53 {
    errors
    cache 30
    reload
    loop
    bind 169.254.20.10 10.96.0.10
    forward . __PILLAR__CLUSTER__DNS__ {
            force_tcp
    }
    prometheus :9253
    }
ip6.arpa:53 {
    errors
    cache 30
    reload
    loop
    bind 169.254.20.10 10.96.0.10
    forward . __PILLAR__CLUSTER__DNS__ {
            force_tcp
    }
    prometheus :9253
    }
.:53 {
    log
    errors
    cache 30
    reload
    loop
    bind 169.254.20.10 10.96.0.10
    forward . __PILLAR__UPSTREAM__SERVERS__
    prometheus :9253
    }

BinaryData
====

Events:  <none>
```

- `169.254.20.10`ìœ¼ë¡œ ì§ˆì˜ê°€ ë“¤ì–´ì˜¤ë©´ node-local-dnsê°€ ì‘ë‹µ
- `cluster.local` ë„ë©”ì¸ì€ ë‚´ë¶€ DNSë¡œ ì²˜ë¦¬í•˜ê³ , ì™¸ë¶€ ë„ë©”ì¸ì€ upstreamìœ¼ë¡œ ì „ë‹¬ë¨

### **10. iptables ìƒíƒœ ë°±ì—… (ì„¤ì¹˜ í›„)**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# iptables-save | tee after.txt
```

### **11. iptables diff ë¹„êµ**

**NodeLocalDNS ì„¤ì¹˜ ì „í›„ì˜ iptables ì°¨ì´ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# diff before.txt after.txt 
```

âœ…Â **ì¶œë ¥**

```bash
1c1
< # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:16:21 2025
---
> # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:35:13 2025
19,20c19,20
< # Completed on Thu Jul 31 00:16:21 2025
< # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:16:21 2025
---
> # Completed on Thu Jul 31 00:35:13 2025
> # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:35:13 2025
25a26,29
> -A PREROUTING -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A PREROUTING -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A PREROUTING -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A PREROUTING -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
26a31,42
> -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -s 10.96.0.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -s 169.254.20.10/32 -p tcp -m tcp --sport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -d 169.254.20.10/32 -p tcp -m tcp --dport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -s 169.254.20.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
> -A OUTPUT -s 169.254.20.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK
38,39c54,55
< # Completed on Thu Jul 31 00:16:21 2025
< # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:16:21 2025
---
> # Completed on Thu Jul 31 00:35:13 2025
> # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:35:13 2025
41c57
< :INPUT ACCEPT [6292389:2731707993]
---
> :INPUT ACCEPT [6565229:2825821888]
43c59
< :OUTPUT ACCEPT [6187388:1591005004]
---
> :OUTPUT ACCEPT [6451665:1655130253]
54a71,74
> -A INPUT -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
> -A INPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
> -A INPUT -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
> -A INPUT -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
64a85,88
> -A OUTPUT -s 10.96.0.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
> -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
> -A OUTPUT -s 169.254.20.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
> -A OUTPUT -s 169.254.20.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT
84,85c108,109
< # Completed on Thu Jul 31 00:16:21 2025
< # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:16:21 2025
---
> # Completed on Thu Jul 31 00:35:13 2025
> # Generated by iptables-save v1.8.10 (nf_tables) on Thu Jul 31 00:35:13 2025
105a130
> :KUBE-SEP-6O2WVHQLDKFLZQRS - [0:0]
110a136
> :KUBE-SEP-IG5OB37KH2LEQCBN - [0:0]
114a141
> :KUBE-SVC-BRK3P4PPQWCLKOAN - [0:0]
118a146
> :KUBE-SVC-FXR4M2CWOGAZGGYD - [0:0]
136a165,166
> -A KUBE-NODEPORTS -d 127.0.0.0/8 -p tcp -m comment --comment "kube-system/hubble-ui:http" -m tcp --dport 30003 -m nfacct --nfacct-name  localhost_nps_accepted_pkts -j KUBE-EXT-ZGWW2L4XLRSDZ3EF
> -A KUBE-NODEPORTS -p tcp -m comment --comment "kube-system/hubble-ui:http" -m tcp --dport 30003 -j KUBE-EXT-ZGWW2L4XLRSDZ3EF
141,142d170
< -A KUBE-NODEPORTS -d 127.0.0.0/8 -p tcp -m comment --comment "kube-system/hubble-ui:http" -m tcp --dport 30003 -m nfacct --nfacct-name  localhost_nps_accepted_pkts -j KUBE-EXT-ZGWW2L4XLRSDZ3EF
< -A KUBE-NODEPORTS -p tcp -m comment --comment "kube-system/hubble-ui:http" -m tcp --dport 30003 -j KUBE-EXT-ZGWW2L4XLRSDZ3EF
153a182,183
> -A KUBE-SEP-6O2WVHQLDKFLZQRS -s 172.20.1.144/32 -m comment --comment "kube-system/kube-dns-upstream:dns" -j KUBE-MARK-MASQ
> -A KUBE-SEP-6O2WVHQLDKFLZQRS -p udp -m comment --comment "kube-system/kube-dns-upstream:dns" -m udp -j DNAT --to-destination 172.20.1.144:53
163a194,195
> -A KUBE-SEP-IG5OB37KH2LEQCBN -s 172.20.1.144/32 -m comment --comment "kube-system/kube-dns-upstream:dns-tcp" -j KUBE-MARK-MASQ
> -A KUBE-SEP-IG5OB37KH2LEQCBN -p tcp -m comment --comment "kube-system/kube-dns-upstream:dns-tcp" -m tcp -j DNAT --to-destination 172.20.1.144:53
167a200,201
> -A KUBE-SERVICES -d 10.96.152.212/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA
> -A KUBE-SERVICES -d 10.96.206.199/32 -p tcp -m comment --comment "kube-system/hubble-ui:http cluster IP" -m tcp --dport 80 -j KUBE-SVC-ZGWW2L4XLRSDZ3EF
170a205,206
> -A KUBE-SERVICES -d 10.96.31.170/32 -p udp -m comment --comment "kube-system/kube-dns-upstream:dns cluster IP" -m udp --dport 53 -j KUBE-SVC-FXR4M2CWOGAZGGYD
> -A KUBE-SERVICES -d 10.96.31.170/32 -p tcp -m comment --comment "kube-system/kube-dns-upstream:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-SVC-BRK3P4PPQWCLKOAN
176,177d211
< -A KUBE-SERVICES -d 10.96.152.212/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA
< -A KUBE-SERVICES -d 10.96.206.199/32 -p tcp -m comment --comment "kube-system/hubble-ui:http cluster IP" -m tcp --dport 80 -j KUBE-SVC-ZGWW2L4XLRSDZ3EF
180a215,216
> -A KUBE-SVC-BRK3P4PPQWCLKOAN ! -s 10.244.0.0/16 -d 10.96.31.170/32 -p tcp -m comment --comment "kube-system/kube-dns-upstream:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-MARK-MASQ
> -A KUBE-SVC-BRK3P4PPQWCLKOAN -m comment --comment "kube-system/kube-dns-upstream:dns-tcp -> 172.20.1.144:53" -j KUBE-SEP-IG5OB37KH2LEQCBN
189a226,227
> -A KUBE-SVC-FXR4M2CWOGAZGGYD ! -s 10.244.0.0/16 -d 10.96.31.170/32 -p udp -m comment --comment "kube-system/kube-dns-upstream:dns cluster IP" -m udp --dport 53 -j KUBE-MARK-MASQ
> -A KUBE-SVC-FXR4M2CWOGAZGGYD -m comment --comment "kube-system/kube-dns-upstream:dns -> 172.20.1.144:53" -j KUBE-SEP-6O2WVHQLDKFLZQRS
201c239
< # Completed on Thu Jul 31 00:16:21 2025
---
> # Completed on Thu Jul 31 00:35:13 2025
```

**ì£¼ìš” ì¶”ê°€ ë‚´ìš©**

- `169.254.20.10`ì— ëŒ€í•œ DNS íŠ¸ë˜í”½ì€ conntrack ì œì™¸ (`NOTRACK`)
- DNS í¬íŠ¸ (`53`)ì— ëŒ€í•œ `ACCEPT` ê·œì¹™ ì¶”ê°€ë¨

### **12. íŒŒë“œ ë‚´ DNS ì„¤ì • í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- cat /etc/resolv.conf
```

âœ…Â **ì¶œë ¥**

```bash
search default.svc.cluster.local svc.cluster.local cluster.local Davolink
nameserver 10.96.0.10
options ndots:5
```

### **13. DNS ë¡œê·¸ í™•ì¸**

```bash
kubectl -n kube-system logs -l k8s-app=kube-dns -f
kubectl -n kube-system logs -l k8s-app=node-local-dns -f
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl delete pod curl-pod

# ê²°ê³¼
pod "curl-pod" deleted
```

### **14. curl-pod ì¬ë°°í¬**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# ê²°ê³¼
pod/curl-pod created
```

---

## **ğŸ“ Cilium Local Redirect Policy : `--set localRedirectPolicy=true`**

### **1. Cilium LocalRedirectPolicy ê¸°ëŠ¥ ì„¤ëª…**

- `localRedirectPolicy=true`ë¥¼ í†µí•´ Ciliumì´ eBPF ê¸°ë°˜ìœ¼ë¡œ DNS ìš”ì²­ì„ ë…¸ë“œ ë‚´ì˜ `node-local-dns` íŒŒë“œë¡œ ì§ì ‘ ì „ë‹¬í•˜ë„ë¡ êµ¬ì„±
- Kubernetes ê¸°ë³¸ ë°©ì‹(IPVS/iptables)ì„ ìš°íšŒí•˜ì—¬ Ciliumì´ ì§ì ‘ íŠ¸ë˜í”½ì„ ì²˜ë¦¬í•¨
- [https://docs.cilium.io/en/stable/network/kubernetes/local-redirect-policy/](https://docs.cilium.io/en/stable/network/kubernetes/local-redirect-policy/)

### **2. Cilium ì„¤ì • ì—…ë°ì´íŠ¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
  --set localRedirectPolicy=true
```

âœ…Â **ì¶œë ¥**

```bash
Release "cilium" has been upgraded. Happy Helming!
NAME: cilium
LAST DEPLOYED: Thu Jul 31 00:52:32 2025
NAMESPACE: kube-system
STATUS: deployed
REVISION: 4
TEST SUITE: None
NOTES:
You have successfully installed Cilium with Hubble Relay and Hubble UI.

Your release version is 1.18.0.

For any further help, visit https://docs.cilium.io/en/v1.18/gettinghelp
```

### **3. Cilium ì¬ì‹œì‘**

**(1) `cilium-operator` ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl rollout restart deploy cilium-operator -n kube-system

# ê²°ê³¼
deployment.apps/cilium-operator restarted
```

**(2) `cilium` DaemonSet ì¬ì‹œì‘**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl rollout restart ds cilium -n kube-system

# ê²°ê³¼
daemonset.apps/cilium restarted
```

### **4. Local Redirect ì—°ë™ìš© NodeLocal DNS ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ë° ìˆ˜ì •**

**(1) Ciliumì—ì„œ ì œê³µí•˜ëŠ” NodeLocal DNS ì„¤ì • íŒŒì¼ ë‹¤ìš´ë¡œë“œ**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# wget https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns.yaml
```

âœ…Â **ì¶œë ¥**

```bash
--2025-07-31 00:54:30--  https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns.yaml
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3493 (3.4K) [text/plain]
Saving to: â€˜node-local-dns.yamlâ€™

node-local-dns.yaml     100%[==============================>]   3.41K  --.-KB/s    in 0s      

2025-07-31 00:54:31 (51.1 MB/s) - â€˜node-local-dns.yamlâ€™ saved [3493/3493]
```

**(2) ê¸°ì¡´ `kube-dns` ClusterIPë¡œ forward í•˜ë„ë¡ ì¹˜í™˜**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubedns=$(kubectl get svc kube-dns -n kube-system -o jsonpath={.spec.clusterIP})
sed -i "s/__PILLAR__DNS__SERVER__/$kubedns/g;" node-local-dns.yaml
```

**(3)`__PILLAR__DNS__SERVER__` ê°’ ì¹˜í™˜ í›„ `vi -d`ë¡œ ê¸°ì¡´ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì™€ ë¹„êµ í™•ì¸**

```bash
vi -d nodelocaldns.yaml node-local-dns.yaml
```

âœ…Â **ì¶œë ¥**
![](https://velog.velcdn.com/images/tlsalswls123/post/12bcad1b-2a8e-4ed4-adf9-d79c78e4beff/image.png)

### **5. ìˆ˜ì •ëœ NodeLocal DNS ë°°í¬**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl apply -f node-local-dns.yaml

# ê²°ê³¼
serviceaccount/node-local-dns configured
service/kube-dns-upstream configured
configmap/node-local-dns configured
daemonset.apps/node-local-dns configured
```

**ê´€ë ¨ ë¦¬ì†ŒìŠ¤ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k get cm -n kube-system
```

âœ…Â **ì¶œë ¥**

```bash
NAME                                                   DATA   AGE
cilium-config                                           155    10h
cilium-envoy-config                                     1      10h
coredns                                                1      10h
extension-apiserver-authentication                     6      10h
hubble-relay-config                                     1      10h
hubble-ui-nginx                                        1      10h
ip-masq-agent                                          1      167m
kube-apiserver-legacy-service-account-token-tracking   1      10h
kube-proxy                                             2      10h
kube-root-ca.crt                                       1      10h
kubeadm-config                                          1      10h
kubelet-config                                          1      10h
node-local-dns                                         1      39m
```

### **7. ConfigMap ìˆ˜ì • (Corefileì— ë¡œê·¸ ì¶”ê°€)**

**`k9s` ë˜ëŠ” `kubectl edit cm`ì„ ì‚¬ìš©í•˜ì—¬ Corefileì— `log` ì„¤ì • ì¶”ê°€**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# k9s
```
![](https://velog.velcdn.com/images/tlsalswls123/post/7e720fde-8407-47fc-b1db-f710913d3ddf/image.png)

### **8. Corefile í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl describe cm -n kube-system node-local-dns
```

âœ…Â **ì¶œë ¥**

```bash
Name:         node-local-dns
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Data
====
Corefile:
----
cluster.local:53 {
    log
    errors
    cache {
            success 9984 30
            denial 9984 5
    }
    reload
    loop
    bind 0.0.0.0
    forward . __PILLAR__CLUSTER__DNS__ {
            force_tcp
    }
    prometheus :9253
    health
    }
in-addr.arpa:53 {
    errors
    cache 30
    reload
    loop
    bind 0.0.0.0
    forward . __PILLAR__CLUSTER__DNS__ {
            force_tcp
    }
    prometheus :9253
    }
ip6.arpa:53 {
    errors
    cache 30
    reload
    loop
    bind 0.0.0.0
    forward . __PILLAR__CLUSTER__DNS__ {
            force_tcp
    }
    prometheus :9253
    }
.:53 {
    log
    errors
    cache 30
    reload
    loop
    bind 0.0.0.0
    forward . __PILLAR__UPSTREAM__SERVERS__
    prometheus :9253
    }

BinaryData
====

Events:  <none>
```

### **9. LocalRedirectPolicy ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ ë° ì ìš©**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# wget https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml
```

âœ…Â **ì¶œë ¥**

```bash
--2025-07-31 01:04:50--  https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 452 [text/plain]
Saving to: â€˜node-local-dns-lrp.yamlâ€™

node-local-dns-lrp.yaml                       100%[===============================================================================================>]     452  --.-KB/s    in 0s      

2025-07-31 01:04:50 (35.5 MB/s) - â€˜node-local-dns-lrp.yamlâ€™ saved [452/452]
```

`node-local-dns-lrp.yaml` ë‹¤ìš´ë¡œë“œ ë° ë‚´ë¶€ êµ¬ì¡° í™•ì¸

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# cat node-local-dns-lrp.yaml | yq
```

âœ…Â **ì¶œë ¥**

```bash
{
  "apiVersion": "cilium.io/v2",
  "kind": "CiliumLocalRedirectPolicy",
  "metadata": {
    "name": "nodelocaldns",
    "namespace": "kube-system"
  },
  "spec": {
    "redirectFrontend": {
      "serviceMatcher": {
        "serviceName": "kube-dns",
        "namespace": "kube-system"
      }
    },
    "redirectBackend": {
      "localEndpointSelector": {
        "matchLabels": {
          "k8s-app": "node-local-dns"
        }
      },
      "toPorts": [
        {
          "port": "53",
          "name": "dns",
          "protocol": "UDP"
        },
        {
          "port": "53",
          "name": "dns-tcp",
          "protocol": "TCP"
        }
      ]
    }
  }
}
```

- `kube-system` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ `kube-dns`ë¡œ ë“¤ì–´ì˜¤ëŠ” íŠ¸ë˜í”½ì„
- ë™ì¼ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ `node-local-dns` ë¼ë²¨ì„ ê°€ì§„ íŒŒë“œì˜ 53ë²ˆ í¬íŠ¸(UDP/TCP)ë¡œ ë¦¬ë‹¤ì´ë ‰ì…˜

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml

# ê²°ê³¼
ciliumlocalredirectpolicy.cilium.io/nodelocaldns created
```

### **10. ì •ì±… ì ìš© ì—¬ë¶€ í™•ì¸**

**(1) ìƒì„±ëœ LRP í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl get CiliumLocalRedirectPolicy -A
```

âœ…Â **ì¶œë ¥**

```bash
NAMESPACE     NAME           AGE
kube-system   nodelocaldns   29s
```

**(2) ì‹¤ì œ ë¦¬ë‹¤ì´ë ‰ì…˜ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium-dbg service list | grep LocalRedirect
17   10.96.0.10:53/UDP       LocalRedirect   1 => 172.20.0.211:53/UDP (active)       
18   10.96.0.10:53/TCP       LocalRedirect   1 => 172.20.0.211:53/TCP (active) 
```

### **11. í…ŒìŠ¤íŠ¸ ë° ë¡œê·¸ í™•ì¸**

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl -n kube-system logs -l k8s-app=node-local-dns -f
```

```bash
(âˆ|HomeLab:N/A) root@k8s-ctr:~# kubectl exec -it curl-pod -- nslookup www.google.com
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

Non-authoritative answer:
Name:	www.google.com
Address: 172.217.161.36
Name:	www.google.com
Address: 2404:6800:4005:81a::2004
```

```bash
    loop
    bind 0.0.0.0
    forward . /etc/resolv.conf
    prometheus :9253
    }
[INFO] Reloading
[INFO] plugin/reload: Running configuration MD5 = a9f86d268572cb5d3a3b2400ed98aff3
[INFO] Reloading complete
[INFO] 127.0.0.1:40579 - 43725 "HINFO IN 1286845318690505901.8683751169514593307.cluster.local. udp 71 false 512" NXDOMAIN qr,aa,rd 164 0.001900209s
[INFO] 127.0.0.1:56654 - 7833 "HINFO IN 2926695405806933559.8651839986208145762. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.009552781s
[INFO] 172.20.0.69:37103 - 36022 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.002148806s
[INFO] 172.20.0.69:45793 - 8828 "A IN www.google.com.davolink. udp 41 false 512" NXDOMAIN qr,rd,ra 116 0.006312427s
[INFO] 172.20.0.69:41214 - 60955 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.004218626s
[INFO] 172.20.0.69:47527 - 57259 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.004593533s
[INFO] 172.20.0.69:33415 - 17625 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.001869527s
[INFO] 172.20.0.69:35698 - 26190 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001329426s
[INFO] 172.20.0.69:44150 - 38926 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000965516s
[INFO] 172.20.0.69:58440 - 55923 "A IN www.google.com.davolink. udp 41 false 512" NXDOMAIN qr,rd,ra 116 0.006998827s
[INFO] 172.20.0.69:59737 - 33042 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.004193042s
[INFO] 172.20.0.69:39931 - 18384 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.003735194s
```
![](https://velog.velcdn.com/images/tlsalswls123/post/38c370c0-0017-4f1c-8430-d4f164e5e3ed/image.png)

